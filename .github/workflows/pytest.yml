name: tests

on:
  pull_request:
    branches: [main]
  merge_group:
    types: [checks_requested]
  schedule:
    - cron: "24 1 * * 2"  # Tuesday at 01:24 UTC
  workflow_dispatch:
    inputs:
      enable_tmate:
        type: boolean
        description: 'Enable SSH debugging with tmate'
        required: false
        default: false
      run_on_all_platforms:
        type: boolean
        description: 'Run on all platforms (including expensive ones)'
        required: false
        default: false

env:
  PXTTEST_IN_CI: 1
  PIXELTABLE_ENABLE_MPS: false  # Disable MPS on MacOS runners until/unless we find a way to cope with memory limits
  UV_VERSION: 0.8.2
  # The llama-cpp-python build fails in CI with LLaVA support enabled. If we ever want to test specific LLaVA
  # functionality in CI, we'll need to investigate further (it's likely due to a missing compiler dependency).
  # We also disable Metal (GPU) support on MacOS, which doesn't seem to work properly in CI.
  CMAKE_ARGS: '-DLLAVA_BUILD=OFF -DGGML_METAL=OFF -DGGML_METAL_EMBED_LIBRARY=OFF'
  # This is required to build onnxsim on Ubuntu / Python 3.12+ configurations.
  CMAKE_POLICY_VERSION_MINIMUM: 3.5
  # API keys for various services. In a PR, these secrets will be empty.
  ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_DEFAULT_REGION: us-west-2
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
  DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
  FIREWORKS_API_KEY: ${{ secrets.FIREWORKS_API_KEY }}
  GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
  GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
  HF_AUTH_TOKEN: ${{ secrets.HF_AUTH_TOKEN }}
  MISTRAL_API_KEY: ${{ secrets.MISTRAL_API_KEY }}
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  REPLICATE_API_TOKEN: ${{ secrets.REPLICATE_API_TOKEN }}
  TOGETHER_API_KEY: ${{ secrets.TOGETHER_API_KEY }}

jobs:
  tests:
    strategy:
      fail-fast: false
      matrix:
        # Test with Python 3.10 and 3.13 (minimum and maximum supported versions) on every platform.
        # In most cases, test only the basic (free) platforms: ubuntu-22.04, macos-15, windows-2022.
        # On a scheduled run, also test ubuntu-x64-t4 (which costs money). ubuntu-arm64 is disabled
        # for now; it just has too many problems.
        # A workflow_dispatch trigger can (optionally) also be used to trigger a full run on all platforms.
        test-category: ["py"]
        uv-options: [""]
        os: ${{ (github.event_name == 'schedule' || (github.event_name == 'workflow_dispatch' && inputs.run_on_all_platforms))
                && fromJSON('["ubuntu-22.04", "macos-15", "windows-2022", "ubuntu-x64-t4"]')
                || fromJSON('["ubuntu-22.04", "macos-15", "windows-2022"]') }}
        python-version: ["3.10", "3.13"]
        # Add some additional matrix configurations that are run only on linux, to test
        # additional scenarios/compatibilities that are unlikely to be platform-sensitive.
        include:
          # Python 3.11
          - test-category: "py"
            uv-options: ""
            os: ubuntu-22.04
            python-version: "3.11"
          # Python 3.12
          - test-category: "py"
            uv-options: ""
            os: ubuntu-22.04
            python-version: "3.12"
          # Minimal installation of pixeltable
          - test-category: "py"
            uv-options: "--no-dev"
            os: ubuntu-22.04
            python-version: "3.10"
          # Notebook tests
          - test-category: "ipynb"
            uv-options: ""
            os: ubuntu-22.04
            python-version: "3.10"
          # Linting, type-checking, docstrings validation, etc.
          - test-category: "lint"
            uv-options: ""
            os: ubuntu-22.04
            python-version: "3.10"
          # Random table ops
          - test-category: "random-tbl-ops"
            uv-options: "--no-dev"
            os: ubuntu-22.04
            python-version: "3.10"

    runs-on: ${{ matrix.os }}
    defaults:
      run:
        shell: bash -el {0}  # Needed for conda to work
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
      - name: Set up tmate session
        if: ${{ github.event_name == 'workflow_dispatch' && inputs.enable_tmate }}
        uses: mxschmitt/action-tmate@v3
        with:
          detached: true
      - name: Delete unnecessary files
        if: ${{ !startsWith(matrix.os, 'windows') }}
        run: |
          df -h
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf "$AGENT_TOOLSDIRECTORY"
          sudo rm -rf /opt/hostedtoolcache
          df -h
      - name: Install conda
        uses: conda-incubator/setup-miniconda@v3
        with:
          miniconda-version: latest
          activate-environment: pxt
          use-only-tar-bz2: true  # Needed to use conda with cache action
      - name: Install python
        run: |
          conda install -y python=${{ matrix.python-version }} pip=25.0
          conda info
      - name: Install tools
        # cmake is needed for certain CI environments where it is not preinstalled.
        # libiconv and ffmpeg are needed by WhisperX.
        if: ${{ matrix.uv-options == '' }}
        run: ./scripts/retry.sh 3 30 conda install -c conda-forge 'cmake>=3.22' libiconv 'ffmpeg>=6,<7'
      - name: Install ollama
        if: ${{ matrix.uv-options == '' && matrix.os == 'ubuntu-22.04' }}
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          sleep 10  # Wait for the ollama server to start
          # Pull the model used for testing now, with retries, to safeguard against connection issues
          ./scripts/retry.sh 3 30 ollama pull 'qwen2.5:0.5b'
      - name: Install uv
        run: |
          python -m pip install --upgrade pip
          python -m pip install "uv==$UV_VERSION"
      - name: Define a venv cache
        uses: actions/cache@v4
        if: false
        with:
          # The cache is keyed to the following:
          # - Matrix parameters
          # - uv.lock and related .toml files and Makefile (so that if the
          #   dependencies or uv config change, the cache will be invalidated)
          path: ${{ env.CONDA }}/envs
          key: venv-${{ matrix.os }}-${{ matrix.python-version }}-${{ matrix.uv-options }}-${{
            hashFiles('.github/workflows/pytest.yml', 'uv.lock', 'pyproject.toml', 'Makefile') }}
      - name: Install the project dependencies
        # Retry 3 times to be resilient against transient connectivity issues.
        run: |
          export VIRTUAL_ENV="$CONDA_PREFIX"
          ./scripts/retry.sh 3 60 uv sync --active ${{ matrix.uv-options }}
      - name: Clean the uv cache
        run: uv cache clean
      - name: Run the unit tests
        if: ${{ matrix.test-category == 'py' }}
        env:
          PXTTEST_CI_OS: ${{ matrix.os }}
        # Run the tests with the 'expensive' marker only once, on ubuntu-22.04 with Python 3.10. The other tests
        # (including tests with the 'remote_api' marker that are not also marked 'expensive') will run on all matrix
        # configurations.
        run: |
          PYTEST_MARKERS="${{ (matrix.os != 'ubuntu-22.04' || matrix.python-version != '3.10') && 'not expensive' || '' }}"
          echo "Running tests with markers: $PYTEST_MARKERS"
          coverage run -m --source=pixeltable pytest -v -m "$PYTEST_MARKERS" --strict-markers
          coverage report -m
      - name: Run the notebook tests
        if: ${{ matrix.test-category == 'ipynb' }}
        run: |
          ./scripts/prepare-nb-tests.sh --no-pip docs/notebooks tests
          pytest -v -m '' --nbmake --nbmake-timeout=1800 target/nb-tests/*.ipynb
      - name: Run random table ops
        if: ${{ matrix.test-category == 'random-tbl-ops' }}
        run: python tool/worker_harness.py 12 1800 tool/random_tbl_ops.py 2>&1 | tee random-tbl-ops-${{ matrix.os }}.log
      - name: Type check
        if: ${{ matrix.test-category == 'lint' }}
        run: mypy pixeltable tests tool
      - name: Validate docstrings
        if: ${{ matrix.test-category == 'lint' }}
        run: mkdocs build --strict
      - name: Lint
        if: ${{ matrix.test-category == 'lint' }}
        run: ruff check pixeltable tests tool
      - name: Validate links in notebooks
        if: ${{ matrix.test-category == 'lint' }}
        run: ./scripts/lint-notebooks.sh
      - name: Formatter check
        if: ${{ matrix.test-category == 'lint' }}
        run: |
          ruff format --check
          ruff check --select I
      - name: Archive log files
        # Archive the log files even if a preceding step failed. Currently we do this only on ubuntu runners.
        if: ${{ always() && startsWith(matrix.os, 'ubuntu') }}
        uses: actions/upload-artifact@v4
        with:
          name: pixeltable-pytest-logs-${{ matrix.os }}-${{ matrix.python-version }}-${{
            matrix.test-category }}${{ matrix.uv-options }}
          path: /tmp/pytest-of-runner/pytest-0/base0/.pixeltable/logs
      - name: Print utilization info
        if: ${{ startsWith(matrix.os, 'ubuntu') }}
        run: |
          df -h
          du -h -d3 /home/runner
          du -h -d3 /home/runner/.cache
      - name: Print utilization info
        if: ${{ !startsWith(matrix.os, 'ubuntu') }}
        run: df -h
