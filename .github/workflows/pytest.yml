name: tests

# On PR updates, the basic test configurations are run:
#   - Python 3.10 on ubuntu-24.04, macos-15, and windows-2022 runners.
#   - A minimal installation of Pixeltable (--no-dev) with Python 3.10 on ubuntu-24.04.
#   - Notebook tests.
#   - Linting, type-checking, docstring validation, etc.
#   - Random ops (for 30 minutes).
#
# In merge queue, all of the above configurations are run, and additionally:
#   - Python 3.13 on ubuntu-24.04, macos-15, and windows-2022 runners.
#   - Python 3.11 and 3.12 on ubuntu-24.04.
#   - Minimal Pixeltable with Python 3.13 on ubuntu-24.04.
#   - Minimal Pixeltable with Python 3.10 on ubuntu-24.04-arm and macos-15-intel.
#
# On a weekly schedule, all of the above configurations are run (against branch 'main'), and additionally:
#   - Python 3.10 on ubuntu-x64-t4 (equipped with an NVIDIA T4 GPU).
#
# A workflow_dispatch trigger will emulate the merge queue tests by default, but can be optionally
#     selected to run all configurations including ubuntu-x64-t4.
#
# Github Actions secrets are unavailable on PRs; hence any tests that require API keys will be skipped.
# Secrets are available on all other triggers.

on:
  pull_request:
    branches: [main]
  merge_group:
    types: [checks_requested]
  schedule:
    - cron: "24 1 * * 2"  # Tuesday at 01:24 UTC
  workflow_dispatch:
    inputs:
      enable_tmate:
        type: boolean
        description: 'Enable SSH debugging with tmate'
        required: false
        default: false
      run_on_all_platforms:
        type: boolean
        description: 'Run on all platforms (including expensive ones)'
        required: false
        default: false

env:
  PIXELTABLE_B2_PROFILE: b2_profile
  PIXELTABLE_ENABLE_MPS: false  # Disable MPS on MacOS runners until/unless we find a way to cope with memory limits
  PIXELTABLE_R2_PROFILE: r2_profile
  PXTTEST_IN_CI: 1
  UV_VERSION: 0.9.3

  # The llama-cpp-python build fails in CI with LLaVA support enabled. If we ever want to test specific LLaVA
  # functionality in CI, we'll need to investigate further (it's likely due to a missing compiler dependency).
  # We also disable Metal (GPU) support on MacOS, which doesn't seem to work properly in CI.
  CMAKE_ARGS: '-DLLAVA_BUILD=OFF -DGGML_METAL=OFF -DGGML_METAL_EMBED_LIBRARY=OFF'
  # This is required to build onnxsim on Ubuntu / Python 3.12+ configurations.
  CMAKE_POLICY_VERSION_MINIMUM: 3.5

  # API keys for various services. In a PR, these secrets will be empty.
  ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_DEFAULT_REGION: us-west-2
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
  B2_ACCESS_KEY_ID: ${{ secrets.B2_ACCESS_KEY_ID }}
  B2_SECRET_ACCESS_KEY: ${{ secrets.B2_SECRET_ACCESS_KEY }}
  DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
  FIREWORKS_API_KEY: ${{ secrets.FIREWORKS_API_KEY }}
  GCS_SERVICE_ACCOUNT_KEY: ${{ secrets.GCS_SERVICE_ACCOUNT_KEY }}
  GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
  GOOGLE_APPLICATION_CREDENTIALS: '/tmp/gcs-key.json'
  GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
  HF_AUTH_TOKEN: ${{ secrets.HF_AUTH_TOKEN }}
  MISTRAL_API_KEY: ${{ secrets.MISTRAL_API_KEY }}
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
  R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
  R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
  REPLICATE_API_TOKEN: ${{ secrets.REPLICATE_API_TOKEN }}
  TOGETHER_API_KEY: ${{ secrets.TOGETHER_API_KEY }}

jobs:
  generate-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
      - name: Install python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      - name: Generate test matrix
        id: set-matrix
        run: |
          ARGS=${{ github.event_name == 'workflow_dispatch' && inputs.run_on_all_platforms && '--force-all' || '' }}
          python tool/ci_tool.py generate-matrix "$GITHUB_OUTPUT" ${{ github.event_name }} $ARGS

  tests:
    name: ${{ matrix.display-name }}
    needs: generate-matrix
    runs-on: ${{ matrix.os }}

    strategy:
      fail-fast: false
      matrix: ${{ fromJSON(needs.generate-matrix.outputs.matrix) }}

    defaults:
      run:
        shell: bash -el {0}  # Needed for conda to work

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
      - name: Set up tmate session
        if: ${{ github.event_name == 'workflow_dispatch' && inputs.enable_tmate }}
        uses: mxschmitt/action-tmate@v3
        with:
          detached: true
      - name: Google cloud auth
        if: ${{ env.GCS_SERVICE_ACCOUNT_KEY != '' }}
        uses: google-github-actions/auth@v3
        with:
          credentials_json: ${{ env.GCS_SERVICE_ACCOUNT_KEY }}
      - name: Delete unnecessary files
        if: ${{ !startsWith(matrix.os, 'windows') }}
        run: |
          df -h
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf "$AGENT_TOOLSDIRECTORY"
          sudo rm -rf /opt/hostedtoolcache
          df -h
      - name: Install conda
        uses: conda-incubator/setup-miniconda@v3
        with:
          miniconda-version: latest
          activate-environment: pxt
      - name: Install python
        run: |
          conda install -y python=${{ matrix.python-version }} pip=25.0
          conda info
      - name: Install tools and libraries
        # cmake is needed for certain CI environments where it is not preinstalled.
        # libiconv and ffmpeg are needed by WhisperX.
        run: ./scripts/retry.sh 3 30 conda install -c conda-forge 'cmake>=3.22' libiconv 'ffmpeg==6.1.1=gpl*'
      - name: Install ollama
        if: ${{ matrix.uv-options == '' && matrix.os == 'ubuntu-24.04' }}
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          sleep 10  # Wait for the ollama server to start
          # Pull the model used for testing now, with retries, to safeguard against connection issues
          ./scripts/retry.sh 3 30 ollama pull 'qwen2.5:0.5b'
      - name: Install uv
        run: |
          python -m pip install --upgrade pip
          python -m pip install "uv==$UV_VERSION"
      - name: Define a venv cache
        uses: actions/cache@v4
        if: false
        with:
          # The cache is keyed to the following:
          # - Matrix parameters
          # - uv.lock and related .toml files and Makefile (so that if the
          #   dependencies or uv config change, the cache will be invalidated)
          path: ${{ env.CONDA }}/envs
          key: venv-${{ matrix.os }}-${{ matrix.python-version }}-${{ matrix.uv-options }}-${{
            hashFiles('.github/workflows/pytest.yml', 'uv.lock', 'pyproject.toml', 'Makefile') }}
      - name: Install the project dependencies
        # Retry 3 times to be resilient against transient connectivity issues.
        run: |
          export VIRTUAL_ENV="$CONDA_PREFIX"
          ./scripts/retry.sh 3 60 uv sync --active ${{ matrix.uv-options }}
      - name: Clean the uv cache
        run: uv cache clean
      - name: Set up credentials
        run: ./scripts/set-up-ci-credentials.sh
      - name: Run the unit tests
        if: ${{ matrix.test-category == 'py' }}
        env:
          PXTTEST_CI_OS: ${{ matrix.os }}
        # Run the tests with the 'expensive' marker only once, on ubuntu-24.04 with Python 3.10. The other tests
        # (including tests with the 'remote_api' marker that are not also marked 'expensive') will run on all matrix
        # configurations.
        run: |
          PYTEST_MARKERS="${{ (matrix.os != 'ubuntu-24.04' || matrix.python-version != '3.10') && 'not expensive' || '' }}"
          echo "Running tests with markers: $PYTEST_MARKERS"
          echo "Extra environment variables: ${{ matrix.extra-env }}"
          ${{ matrix.extra-env }} coverage run -m --source=pixeltable pytest -v -m "$PYTEST_MARKERS" --strict-markers
          coverage report -m
      - name: Run the notebook tests
        if: ${{ matrix.test-category == 'ipynb' }}
        run: |
          ./scripts/prepare-nb-tests.sh --no-pip tests/target/nb-tests docs/notebooks tests
          set +e  # don't exit immediately on error, so that we can retry
          pytest -v -m '' --nbmake --nbmake-timeout=1800 tests/target/nb-tests/*.ipynb
          pytest -v -m '' --nbmake --nbmake-timeout=1800 --lf --lfnf=none  # retry failed tests once
          if [[ $? != 0 && $? != 5 ]]; then  # exit code 5 = no tests collected on 2nd run
            exit 1
          fi
      - name: Run random table ops
        if: ${{ matrix.test-category == 'random-ops' }}
        run: python tool/worker_harness.py 12 1800 tool/random_tbl_ops.py 2>&1 | tee random-tbl-ops-${{ matrix.os }}.log
      - name: Type check
        if: ${{ matrix.test-category == 'lint' }}
        run: mypy pixeltable tests tool
      - name: Validate docstrings
        if: ${{ matrix.test-category == 'lint' }}
        run: |
          mkdocs build --strict
          pydoclint pixeltable tests tool
      - name: Lint
        if: ${{ matrix.test-category == 'lint' }}
        run: ruff check pixeltable tests tool
      - name: Validate links in notebooks
        if: ${{ matrix.test-category == 'lint' }}
        run: ./scripts/lint-notebooks.sh
      - name: Formatter check
        if: ${{ matrix.test-category == 'lint' }}
        run: |
          ruff format --check
          ruff check --select I
      - name: Archive log files
        # Archive the log files even if a preceding step failed. Currently we do this only on ubuntu runners.
        if: ${{ always() && startsWith(matrix.os, 'ubuntu') }}
        uses: actions/upload-artifact@v4
        with:
          name: pixeltable-pytest-logs-${{ matrix.os }}-${{ matrix.python-version }}-${{
            matrix.test-category }}${{ matrix.uv-options }}
          path: /tmp/pytest-of-runner/pytest-0/base0/.pixeltable/logs
      - name: Print utilization info
        if: ${{ startsWith(matrix.os, 'ubuntu') }}
        run: |
          df -h
          du -h -d3 /home/runner || true
          du -h -d3 /home/runner/.cache || true
      - name: Print utilization info
        if: ${{ !startsWith(matrix.os, 'ubuntu') }}
        run: df -h

  validate:
    needs: tests
    runs-on: ubuntu-latest
    if: failure()
    steps:
      - name: Fail on error
        run: exit 1
