{
  "@context": "https://pixeltable.com/learn",
  "@type": "Tutorial",
  "@id": "using-label-studio",
  "github_url": "https://github.com/pixeltable/pixeltable/blob/release/docs/notebooks/integrations/using-label-studio-with-pixeltable.ipynb",
  "title": "Using Label Studio for Annotations with Pixeltable",
  "objective": "Master Label Studio integration for seamless annotation workflows with automated preannotations and bidirectional sync",
  "difficulty": "advanced",
  "categories": ["annotations", "integrations", "labeling", "machine_learning", "human_in_loop"],
  "prerequisites": ["pixeltable-basics", "working-with-views", "frame-extraction"],
  "imports_required": ["import subprocess", "import getpass", "import os", "import pixeltable as pxt", "from datetime import datetime", "from pixeltable.iterators import FrameIterator", "from pixeltable.functions.video import get_metadata", "from pixeltable.functions.huggingface import detr_for_object_detection, detr_to_coco"],
  "performance_notes": {
    "typical_runtime": "5-10 minutes including Label Studio setup",
    "resource_requirements": "Local Label Studio server, network connectivity, GPU for ML models",
    "bottlenecks": ["Label Studio startup", "Model inference", "Frame extraction", "Annotation sync"]
  },
  "key_learnings": [
    "Label Studio projects link bidirectionally with Pixeltable views",
    "Preannotations generated via ML models reduce manual labeling",
    "Annotation workflows support incremental data updates",
    "External stores provide persistent annotation management",
    "Column mapping enables flexible data field configuration",
    "Media import methods optimize for different deployment scales",
    "Frame extraction enables video annotation at frame level"
  ],
  "relationships": {
    "builds_on": ["view_creation", "computed_columns", "frame_extraction"],
    "enables": ["human_in_loop_ml", "annotation_pipelines", "data_labeling_workflows"],
    "see_also": ["working-with-fiftyone", "object-detection"],
    "contrasts_with": ["programmatic_only_labeling"]
  },
  "steps": [
    {
      "number": 1,
      "section_title": "Install Dependencies",
      "intent": "Install all required packages for Label Studio integration",
      "code": "%pip install -qU pixeltable label-studio label-studio-sdk torch transformers",
      "imports_used": [],
      "explanation": "Installs Pixeltable, Label Studio server and SDK, plus ML libraries for automated preannotations",
      "actual_output": "[Installation output]",
      "output_summary": "All annotation workflow dependencies installed",
      "output_type": "text", 
      "learns": [],
      "reinforces": ["installation", "ml_dependencies"],
      "gotchas": ["Label Studio installation can be complex", "Requires local server capabilities"],
      "performance": {"execution_time": "1-3 minutes", "scaling": "O(1)", "optimization": "demo"},
      "alternatives": {"description": "Use existing Label Studio installation", "when_to_use": "Already running Label Studio"},
      "state_after": {"tables": [], "views": [], "variables": [], "models_loaded": []},
      "pattern_refs": ["annotation_environment_setup"]
    },
    {
      "number": 2,
      "section_title": "Start Label Studio Server",
      "intent": "Launch local Label Studio server for annotation interface",
      "code": "import subprocess\nls_process = subprocess.Popen(['label-studio'], stderr=subprocess.PIPE)",
      "imports_used": ["import subprocess"],
      "explanation": "Starts Label Studio server as background process. Opens browser window for user interface access",
      "actual_output": "Performing system checks...\n\nSystem check identified no issues (1 silenced).\nAugust 14, 2024 - 04:24:46\nDjango version 3.2.25, using settings 'label_studio.core.settings.label_studio'\nStarting development server at http://0.0.0.0:8080/\nQuit the server with CONTROL-C.",
      "output_summary": "Label Studio server started on localhost:8080",
      "output_type": "text",
      "learns": ["label_studio_server_management"],
      "reinforces": ["process_management"],
      "gotchas": ["Server takes time to start", "Need to create account on first run", "Browser window may not open automatically"],
      "performance": {"execution_time": "30-60s", "scaling": "O(1)", "optimization": "demo"},
      "alternatives": {"description": "Use existing Label Studio server URL", "when_to_use": "Shared or production Label Studio instance"},
      "state_after": {"tables": [], "views": [], "variables": ["ls_process"], "models_loaded": []},
      "pattern_refs": ["annotation_server_setup"]
    },
    {
      "number": 3,
      "section_title": "Configure API Access",
      "intent": "Set up authentication for Pixeltable-Label Studio communication",
      "code": "import getpass\nimport os\n\nif 'LABEL_STUDIO_URL' not in os.environ:\n    os.environ['LABEL_STUDIO_URL'] = 'http://localhost:8080/'\n\nif 'LABEL_STUDIO_API_KEY' not in os.environ:\n    os.environ['LABEL_STUDIO_API_KEY'] = getpass.getpass('Label Studio API key: ')",
      "imports_used": ["import getpass", "import os"],
      "explanation": "Configures URL and API key for secure communication. User must obtain API key from Label Studio interface",
      "actual_output": "Label Studio API key:  路路路路路路路路",
      "output_summary": "API credentials configured securely",
      "output_type": "text",
      "learns": ["api_authentication"],
      "reinforces": ["environment_configuration", "secure_credential_handling"],
      "gotchas": ["API key must be copied from Label Studio UI", "Keys are session-specific"],
      "performance": {"execution_time": "User interaction time", "scaling": "O(1)", "optimization": "production"},
      "alternatives": {"description": "Set environment variables in deployment config", "when_to_use": "Production environments"},
      "state_after": {"tables": [], "views": [], "variables": ["ls_process", "LABEL_STUDIO_URL", "LABEL_STUDIO_API_KEY"], "models_loaded": []},
      "pattern_refs": ["api_authentication_setup"]
    },
    {
      "number": 4,
      "section_title": "Create Video Table",
      "intent": "Set up master table for videos to be annotated",
      "code": "import pixeltable as pxt\n\nschema = {\n    'video': pxt.Video,\n    'date': pxt.Timestamp\n}\n\n# Before creating the table, we drop the `ls_demo` dir and all its contents,\n# in order to ensure a clean environment for the demo.\npxt.drop_dir('ls_demo', force=True)\npxt.create_dir('ls_demo')\nvideos_table = pxt.create_table('ls_demo.videos', schema)",
      "imports_used": ["import pixeltable as pxt"],
      "explanation": "Creates master video table with timestamp for filtering. Clean environment ensures reproducible demo",
      "actual_output": "Connected to Pixeltable database at: postgresql://postgres:@/pixeltable?host=/Users/asiegel/.pixeltable/pgdata\nCreated directory `ls_demo`.\nCreated table `videos`.",
      "output_summary": "Video table created with video and timestamp columns",
      "output_type": "text",
      "learns": ["annotation_table_schema"],
      "reinforces": ["table_creation", "schema_design"],
      "gotchas": [],
      "performance": {"execution_time": "100-500ms", "scaling": "O(1)", "optimization": "demo"},
      "alternatives": {"description": "Use existing video table", "when_to_use": "Working with production data"},
      "state_after": {"tables": ["ls_demo.videos"], "views": [], "variables": ["videos_table"], "models_loaded": []},
      "pattern_refs": ["annotation_data_setup"]
    },
    {
      "number": 5,
      "section_title": "Populate with Video Data",
      "intent": "Insert sample videos for annotation workflow demonstration",
      "code": "from datetime import datetime\n\nurl_prefix = 'http://multimedia-commons.s3-website-us-west-2.amazonaws.com/data/videos/mp4/'\nfiles = [\n    '122/8ff/1228ff94bf742242ee7c88e4769ad5d5.mp4',\n    '2cf/a20/2cfa205eae979b31b1144abd9fa4e521.mp4',\n    'ffe/ff3/ffeff3c6bf57504e7a6cecaff6aefbc9.mp4',\n]\ntoday = datetime(2024, 4, 22)\nvideos_table.insert({'video': url_prefix + file, 'date': today} for file in files)",
      "imports_used": ["from datetime import datetime"],
      "explanation": "Populates table with multimedia commons videos and fixed date for filtering demonstrations",
      "actual_output": "Inserting rows into `videos`: 3 rows [00:00, 993.05 rows/s]\nInserted 3 rows with 0 errors.\n\nUpdateStatus(num_rows=3, num_computed_values=0, num_excs=0, updated_cols=[], cols_with_excs=[])",
      "output_summary": "Three video files inserted successfully",
      "output_type": "text",
      "learns": [],
      "reinforces": ["data_insertion", "external_file_handling"],
      "gotchas": ["Videos are cached locally on access", "Fixed date simplifies filtering"],
      "performance": {"execution_time": "1-3s", "scaling": "O(n) downloads", "optimization": "demo"},
      "alternatives": {"description": "Use local video files", "when_to_use": "Offline development"},
      "state_after": {"tables": ["ls_demo.videos"], "views": [], "variables": ["videos_table", "today"], "models_loaded": []},
      "pattern_refs": ["annotation_data_insertion"]
    },
    {
      "number": 6,
      "section_title": "Create Filtered View for Annotation",
      "intent": "Create view filtering by date to link with Label Studio project",
      "code": "# Create a view to filter on the specified date\n\nv = pxt.create_view(\n    'ls_demo.videos_2024_04_22',\n    videos_table.where(videos_table.date == today)\n)\n\n# Create a new Label Studio project and link it to the view. The\n# configuration uses Label Studio's standard XML format. This only\n# needs to be done once: after the view and project are linked,\n# the relationship is stored indefinitely in Pixeltable's metadata.\n\nlabel_config = '''\n    <View>\n      <Video name=\"video\" value=\"$video\"/>\n      <Choices name=\"video-category\" toName=\"video\" showInLine=\"true\">\n        <Choice value=\"city\"/>\n        <Choice value=\"food\"/>\n        <Choice value=\"sports\"/>\n      </Choices>\n    </View>\n    '''\n\npxt.io.create_label_studio_project(v, label_config)",
      "imports_used": [],
      "explanation": "Creates filtered view and links to Label Studio with XML configuration for video classification. Relationship persists in metadata",
      "actual_output": "Inserting rows into `videos_2024_04_22`: 3 rows [00:00, 1864.69 rows/s]\nCreated view `videos_2024_04_22` with 3 rows, 0 exceptions.\nAdded 3 column values with 0 errors.\nComputing cells: 100%|| 3/3 [00:00<00:00, 857.44 cells/s]\nLinked external store `ls_project_0` to table `videos_2024_04_22`.\nCreated 3 new task(s) in LabelStudioProject `videos_2024_04_22`.\n\nSyncStatus(external_rows_created=3, external_rows_deleted=0, external_rows_updated=0, pxt_rows_updated=0, num_excs=0)",
      "output_summary": "View created, linked to Label Studio, and 3 annotation tasks created automatically",
      "output_type": "text",
      "learns": ["label_studio_project_creation", "xml_annotation_config", "external_store_linking"],
      "reinforces": ["view_creation", "integration_setup"],
      "gotchas": ["XML config defines annotation interface", "Tasks created automatically on sync", "Column names must match XML field names"],
      "performance": {"execution_time": "1-2s", "scaling": "O(n) tasks", "optimization": "production"},
      "alternatives": {"description": "Use col_mapping parameter for different field names", "when_to_use": "Existing schemas don't match XML"},
      "state_after": {"tables": ["ls_demo.videos"], "views": ["ls_demo.videos_2024_04_22"], "variables": ["v", "label_config"], "models_loaded": []},
      "pattern_refs": ["label_studio_project_setup", "annotation_view_creation"]
    },
    {
      "number": 7,
      "section_title": "Inspect Annotation View",
      "intent": "Examine view structure after Label Studio integration",
      "code": "v",
      "imports_used": [],
      "explanation": "Shows view schema including automatically added annotations column for storing Label Studio results",
      "actual_output": "view 'videos_2024_04_22'\n\nColumn Name      Type Computed With\nannotations      json              \n      video     video              \n       date timestamp",
      "output_summary": "View contains original columns plus annotations column for Label Studio data",
      "output_type": "text",
      "learns": ["automatic_annotation_column"],
      "reinforces": ["view_inspection"],
      "gotchas": ["annotations column added automatically", "Column name configurable via col_mapping"],
      "performance": {"execution_time": "<1ms", "scaling": "O(1)", "optimization": "demo"},
      "alternatives": {"description": "Custom annotation column name", "when_to_use": "Naming conflicts or preferences"},
      "state_after": {"tables": ["ls_demo.videos"], "views": ["ls_demo.videos_2024_04_22"], "variables": ["v"], "models_loaded": []},
      "pattern_refs": ["annotation_column_inspection"]
    },
    {
      "number": 8,
      "section_title": "Manual Annotation in Label Studio",
      "intent": "Perform manual annotations in Label Studio UI",
      "code": "# Manual step: Go to Label Studio UI and annotate videos",
      "imports_used": [],
      "explanation": "Human-in-the-loop step where users manually categorize videos in Label Studio interface",
      "actual_output": "[User performs manual annotations in Label Studio UI]",
      "output_summary": "Videos manually annotated with category labels",
      "output_type": "none",
      "learns": ["human_annotation_workflow"],
      "reinforces": ["annotation_interface_usage"],
      "gotchas": ["Must complete annotations before sync", "Annotations stored in Label Studio until synced"],
      "performance": {"execution_time": "Variable by user", "scaling": "O(human_time)", "optimization": "human"},
      "alternatives": {"description": "Skip manual step and sync preannotations only", "when_to_use": "Fully automated workflows"},
      "state_after": {"tables": ["ls_demo.videos"], "views": ["ls_demo.videos_2024_04_22"], "variables": ["v"], "models_loaded": []},
      "pattern_refs": ["manual_annotation_step"]
    },
    {
      "number": 9,
      "section_title": "Sync Annotations Back to Pixeltable",
      "intent": "Import completed annotations from Label Studio",
      "code": "v = pxt.get_table('ls_demo.videos_2024_04_22')\nv.sync()",
      "imports_used": [],
      "explanation": "Syncs annotations from Label Studio back to Pixeltable view, updating annotation column with results",
      "actual_output": "Created 0 new task(s) in LabelStudioProject `videos_2024_04_22`.\nUpdated annotation(s) from 1 task(s) in LabelStudioProject `videos_2024_04_22`.\n\nSyncStatus(external_rows_created=0, external_rows_deleted=0, external_rows_updated=0, pxt_rows_updated=1, num_excs=0)",
      "output_summary": "One annotation synced from Label Studio to Pixeltable",
      "output_type": "text",
      "learns": ["bidirectional_sync", "annotation_import"],
      "reinforces": ["sync_operations"],
      "gotchas": ["Only completed annotations synced", "Sync status shows update counts"],
      "performance": {"execution_time": "500ms-2s", "scaling": "O(n) annotations", "optimization": "production"},
      "alternatives": {"description": "Automated sync on schedule", "when_to_use": "Production annotation pipelines"},
      "state_after": {"tables": ["ls_demo.videos"], "views": ["ls_demo.videos_2024_04_22"], "variables": ["v"], "models_loaded": []},
      "pattern_refs": ["annotation_sync_back"]
    },
    {
      "number": 10,
      "section_title": "View Synced Annotations",
      "intent": "Inspect imported annotation data in Pixeltable",
      "code": "v.select(v.video, v.annotations).head()",
      "imports_used": [],
      "explanation": "Shows annotation results imported from Label Studio as JSON structure with metadata",
      "actual_output": "                                               video  \\\n0  /Users/asiegel/.pixeltable/file_cache/faebc341...   \n1  /Users/asiegel/.pixeltable/file_cache/faebc341...   \n2  /Users/asiegel/.pixeltable/file_cache/faebc341...   \n\n                                         annotations  \n0  [{'id': 35, 'task': 141, 'result': [{'id': 'E_...  \n1                                               None  \n2                                               None",
      "output_summary": "One video has annotation data, others remain None (not yet annotated)",
      "output_type": "table",
      "learns": ["annotation_json_structure"],
      "reinforces": ["query_operations", "json_data_handling"],
      "gotchas": ["Annotations are complex JSON structures", "Unannotated items show None"],
      "performance": {"execution_time": "10-50ms", "scaling": "O(n)", "optimization": "demo"},
      "alternatives": {"description": "Filter for only annotated items", "when_to_use": "Large datasets with partial annotations"},
      "state_after": {"tables": ["ls_demo.videos"], "views": ["ls_demo.videos_2024_04_22"], "variables": ["v"], "models_loaded": []},
      "pattern_refs": ["annotation_data_inspection"]
    },
    {
      "number": 11,
      "section_title": "Parse Annotations with Computed Column",
      "intent": "Extract annotation values from complex JSON structure",
      "code": "v.add_computed_column(\n    video_category=v.annotations[0].result[0].value.choices[0]\n)\nv.select(v.video, v.annotations, v.video_category).head()",
      "imports_used": [],
      "explanation": "Uses JSON path navigation to extract specific annotation values into typed column",
      "actual_output": "Computing cells: 100%|| 3/3 [00:00<00:00, 394.63 cells/s]\nAdded 3 column values with 0 errors.\n\n                                               video  \\\n0  /Users/asiegel/.pixeltable/file_cache/faebc341...   \n1  /Users/asiegel/.pixeltable/file_cache/faebc341...   \n2  /Users/asiegel/.pixeltable/file_cache/faebc341...   \n\n                                         annotations video_category  \n0  [{'id': 35, 'task': 141, 'result': [{'id': 'E_...         sports  \n1                                               None           None  \n2                                               None           None",
      "output_summary": "Extracted 'sports' category from first annotation, others remain None",
      "output_type": "table",
      "learns": ["json_path_extraction", "annotation_parsing"],
      "reinforces": ["computed_columns", "json_navigation"],
      "gotchas": ["Path must match Label Studio JSON structure", "Null handling for missing annotations"],
      "performance": {"execution_time": "100-500ms", "scaling": "O(n)", "optimization": "demo"},
      "alternatives": {"description": "Create UDF for complex annotation parsing", "when_to_use": "Complex annotation structures"},
      "state_after": {"tables": ["ls_demo.videos"], "views": ["ls_demo.videos_2024_04_22"], "variables": ["v"], "models_loaded": []},
      "pattern_refs": ["annotation_value_extraction"]
    },
    {
      "number": 12,
      "section_title": "Add Video Metadata Column", 
      "intent": "Demonstrate additional computed columns alongside annotations",
      "code": "from pixeltable.functions.video import get_metadata\n\nv.add_computed_column(video_metadata=get_metadata(v.video))\nv.select(v.video, v.annotations, v.video_category, v.video_metadata).head()",
      "imports_used": ["from pixeltable.functions.video import get_metadata"],
      "explanation": "Adds video metadata extraction alongside annotation data for comprehensive analysis",
      "actual_output": "Computing cells: 100%|| 3/3 [00:00<00:00, 138.97 cells/s]\nAdded 3 column values with 0 errors.\n\n                                               video  \\\n0  /Users/asiegel/.pixeltable/file_cache/faebc341...   \n1  /Users/asiegel/.pixeltable/file_cache/faebc341...   \n2  /Users/asiegel/.pixeltable/file_cache/faebc341...   \n\n                                         annotations video_category  \\\n0  [{'id': 35, 'task': 141, 'result': [{'id': 'E_...         sports   \n1                                               None           None   \n2                                               None           None   \n\n                                      video_metadata  \n0  {'size': 815026, 'streams': [{'type': 'video',...  \n1  {'size': 1558736, 'streams': [{'type': 'video'...  \n2  {'size': 2099014, 'streams': [{'type': 'video'...",
      "output_summary": "Video metadata added with size, streams, and codec information",
      "output_type": "table", 
      "learns": ["annotation_metadata_combination"],
      "reinforces": ["computed_columns", "media_metadata"],
      "gotchas": [],
      "performance": {"execution_time": "500ms-2s", "scaling": "O(n)", "optimization": "demo"},
      "alternatives": {"description": "Add metadata before annotation workflow", "when_to_use": "Metadata-driven annotation filtering"},
      "state_after": {"tables": ["ls_demo.videos"], "views": ["ls_demo.videos_2024_04_22"], "variables": ["v"], "models_loaded": []},
      "pattern_refs": ["metadata_annotation_integration"]
    },
    {
      "number": 13,
      "section_title": "Create Frames View for Preannotation",
      "intent": "Extract video frames for object detection preannotations",
      "code": "from datetime import datetime\nfrom pixeltable.iterators import FrameIterator\n\ntoday = datetime(2024, 4, 22)\nvideos_table = pxt.get_table('ls_demo.videos')\n\n# Create the view, using a `FrameIterator` to extract frames with a sample rate\n# of `fps=0.25`, or 1 frame per 4 seconds of video. Setting `fps=0` would use the\n# native framerate of the video, extracting every frame.\n\nframes = pxt.create_view(\n    'ls_demo.frames_2024_04_22',\n    videos_table.where(videos_table.date == today),\n    iterator=FrameIterator.create(video=videos_table.video, fps=0.25)\n)",
      "imports_used": ["from datetime import datetime", "from pixeltable.iterators import FrameIterator"],
      "explanation": "Creates frame-level view using FrameIterator to extract frames at 4-second intervals for object detection",
      "actual_output": "Inserting rows into `frames_2024_04_22`: 13 rows [00:00, 5434.66 rows/s]\nCreated view `frames_2024_04_22` with 13 rows, 0 exceptions.",
      "output_summary": "13 frames extracted from 3 videos at 0.25 fps sampling rate",
      "output_type": "text",
      "learns": ["frame_extraction_for_annotation"],
      "reinforces": ["frame_iteration", "view_creation_with_iterators"],
      "gotchas": ["fps parameter controls sampling rate", "Higher fps creates more frames"],
      "performance": {"execution_time": "1-3s", "scaling": "O(video_length * fps)", "optimization": "demo"},
      "alternatives": {"description": "Use fps=0 for all frames", "when_to_use": "Detailed frame-by-frame annotation"},
      "state_after": {"tables": ["ls_demo.videos"], "views": ["ls_demo.videos_2024_04_22", "ls_demo.frames_2024_04_22"], "variables": ["frames"], "models_loaded": []},
      "pattern_refs": ["frame_extraction_annotation"]
    },
    {
      "number": 14,
      "section_title": "Generate Object Detection Preannotations",
      "intent": "Use DETR model to create automated bounding box preannotations",
      "code": "from pixeltable.functions.huggingface import detr_for_object_detection\n\n# Run the Resnet-50 object detection model against each frame to generate bounding boxes\nframes.add_computed_column(detections=detr_for_object_detection(\n    frames.frame,\n    model_id='facebook/detr-resnet-50',\n    threshold=0.95\n))\nframes.select(frames.frame, frames.detections).head(3)",
      "imports_used": ["from pixeltable.functions.huggingface import detr_for_object_detection"],
      "explanation": "Applies DETR object detection model to generate bounding boxes for preannotation at high confidence threshold",
      "actual_output": "Computing cells: 100%|| 13/13 [00:06<00:00,  2.10 cells/s]\nAdded 13 column values with 0 errors.\n\n                                               frame  \\\n0  <PIL.Image.Image image mode=RGB size=640x480 a...   \n1  <PIL.Image.Image image mode=RGB size=640x480 a...   \n2  <PIL.Image.Image image mode=RGB size=640x480 a...   \n\n                                          detections  \n0  {'boxes': [[584.916259765625, 0.74955940246582...  \n1  {'boxes': [[562.8792724609375, 196.99993896484...  \n2  {'boxes': [[387.7949523925781, 196.15356445312...",
      "output_summary": "Object detections generated for each frame with bounding boxes and confidence scores",
      "output_type": "table",
      "learns": ["automated_preannotation_generation"],
      "reinforces": ["huggingface_integration", "object_detection"],
      "gotchas": ["High threshold reduces false positives", "Model download on first use", "GPU recommended for performance"],
      "performance": {"execution_time": "30s-2min", "scaling": "O(n_frames)", "optimization": "demo"},
      "alternatives": {"description": "Use different detection models", "when_to_use": "Domain-specific detection needs"},
      "state_after": {"tables": ["ls_demo.videos"], "views": ["ls_demo.videos_2024_04_22", "ls_demo.frames_2024_04_22"], "variables": ["frames"], "models_loaded": ["facebook/detr-resnet-50"]},
      "pattern_refs": ["ml_preannotation_generation"]
    },
    {
      "number": 15,
      "section_title": "Convert to COCO Format for Label Studio",
      "intent": "Transform DETR output to COCO format expected by Label Studio",
      "code": "from pixeltable.functions.huggingface import detr_to_coco\n\nframes.add_computed_column(\n    preannotations=detr_to_coco(frames.frame, frames.detections)\n)\nframes.select(frames.frame, frames.detections, frames.preannotations).head(3)",
      "imports_used": ["from pixeltable.functions.huggingface import detr_to_coco"],
      "explanation": "Converts DETR format to COCO format required by Label Studio for bounding box preannotations",
      "actual_output": "Computing cells: 100%|| 13/13 [00:00<00:00, 42.79 cells/s]\nAdded 13 column values with 0 errors.\n\n                                               frame  \\\n0  <PIL.Image.Image image mode=RGB size=640x480 a...   \n1  <PIL.Image.Image image mode=RGB size=640x480 a...   \n2  <PIL.Image.Image image mode=RGB size=640x480 a...   \n\n                                          detections  \\\n0  {'boxes': [[584.916259765625, 0.74955940246582...   \n1  {'boxes': [[562.8792724609375, 196.99993896484...   \n2  {'boxes': [[387.7949523925781, 196.15356445312...   \n\n                                      preannotations  \n0  {'image': {'width': 640, 'height': 480}, 'anno...  \n1  {'image': {'width': 640, 'height': 480}, 'anno...  \n2  {'image': {'width': 640, 'height': 480}, 'anno...",
      "output_summary": "COCO format annotations generated with image dimensions and normalized bounding boxes",
      "output_type": "table",
      "learns": ["annotation_format_conversion"],
      "reinforces": ["data_transformation", "format_standardization"],
      "gotchas": ["COCO format required for Label Studio", "Coordinates are normalized"],
      "performance": {"execution_time": "500ms-2s", "scaling": "O(n)", "optimization": "demo"},
      "alternatives": {"description": "Custom format conversion UDF", "when_to_use": "Non-standard annotation formats"},
      "state_after": {"tables": ["ls_demo.videos"], "views": ["ls_demo.videos_2024_04_22", "ls_demo.frames_2024_04_22"], "variables": ["frames"], "models_loaded": ["facebook/detr-resnet-50"]},
      "pattern_refs": ["coco_format_conversion"]
    },
    {
      "number": 16,
      "section_title": "Create Label Studio Project for Frames",
      "intent": "Set up object detection annotation project with preannotations",
      "code": "frames_config = '''\n    <View>\n      <Image name=\"frame\" value=\"$frame\"/>\n      <RectangleLabels name=\"preannotations\" toName=\"frame\">\n        <Label value=\"car\" background=\"blue\"/>\n        <Label value=\"person\" background=\"red\"/>\n        <Label value=\"train\" background=\"green\"/>\n      </RectangleLabels>\n    </View>\n    '''\n\npxt.io.create_label_studio_project(frames, frames_config)",
      "imports_used": [],
      "explanation": "Creates Label Studio project for frame annotation with rectangle labels mapping to preannotations column",
      "actual_output": "Added 13 column values with 0 errors.\nComputing cells: 100%|| 13/13 [00:00<00:00, 42.09 cells/s]\nLinked external store `ls_project_0` to table `frames_2024_04_22`.\nCreated 13 new task(s) in LabelStudioProject `frames_2024_04_22`.\n\nSyncStatus(external_rows_created=13, external_rows_deleted=0, external_rows_updated=0, pxt_rows_updated=0, num_excs=0)",
      "output_summary": "Label Studio project created with 13 frame annotation tasks including preannotations",
      "output_type": "text",
      "learns": ["object_detection_annotation_setup"],
      "reinforces": ["label_studio_project_creation", "xml_configuration"],
      "gotchas": ["RectangleLabels name must match preannotations column", "COCO categories must match label values"],
      "performance": {"execution_time": "2-5s", "scaling": "O(n) tasks", "optimization": "production"},
      "alternatives": {"description": "Add more object categories", "when_to_use": "Comprehensive object detection"},
      "state_after": {"tables": ["ls_demo.videos"], "views": ["ls_demo.videos_2024_04_22", "ls_demo.frames_2024_04_22"], "variables": ["frames", "frames_config"], "models_loaded": ["facebook/detr-resnet-50"]},
      "pattern_refs": ["object_detection_annotation_project"]
    },
    {
      "number": 17,
      "section_title": "Demonstrate Incremental Updates",
      "intent": "Show how new data automatically propagates through annotation pipeline",
      "code": "videos_table.insert(\n    video=url_prefix + '22a/948/22a9487a92956ac453a9c15e0fc4dd4.mp4',\n    date=today\n)",
      "imports_used": [],
      "explanation": "Adding new video triggers incremental updates through all dependent views and computed columns",
      "actual_output": "Inserting rows into `videos`: 1 rows [00:00, 808.31 rows/s]\nInserting rows into `videos_2024_04_22`: 1 rows [00:00, 849.57 rows/s]\nInserting rows into `frames_2024_04_22`: 5 rows [00:00, 3225.89 rows/s]\nInserted 7 rows with 0 errors.\n\nUpdateStatus(num_rows=7, num_computed_values=0, num_excs=0, updated_cols=[], cols_with_excs=[])",
      "output_summary": "New video cascades to views: 1 video row, 5 frame rows, automatic computation",
      "output_type": "text",
      "learns": ["incremental_annotation_updates"],
      "reinforces": ["incremental_computation", "dependency_propagation"],
      "gotchas": ["Updates propagate automatically", "Computation time scales with pipeline complexity"],
      "performance": {"execution_time": "5-30s", "scaling": "O(pipeline_complexity)", "optimization": "production"},
      "alternatives": {"description": "Batch updates for large datasets", "when_to_use": "Large-scale data ingestion"},
      "state_after": {"tables": ["ls_demo.videos"], "views": ["ls_demo.videos_2024_04_22", "ls_demo.frames_2024_04_22"], "variables": ["frames"], "models_loaded": ["facebook/detr-resnet-50"]},
      "pattern_refs": ["incremental_annotation_pipeline"]
    },
    {
      "number": 18,
      "section_title": "Sync New Tasks to Label Studio",
      "intent": "Update Label Studio projects with new annotation tasks",
      "code": "v.sync()\nframes.sync()",
      "imports_used": [],
      "explanation": "Explicit sync creates tasks only for newly added data, not existing annotations",
      "actual_output": "Created 1 new task(s) in LabelStudioProject `videos_2024_04_22`.\nCreated 5 new task(s) in LabelStudioProject `frames_2024_04_22`.\n\nSyncStatus(external_rows_created=5, external_rows_deleted=0, external_rows_updated=0, pxt_rows_updated=0, num_excs=0)",
      "output_summary": "6 new annotation tasks created (1 video + 5 frames) from incremental update",
      "output_type": "text",
      "learns": ["incremental_sync_behavior"],
      "reinforces": ["sync_operations", "incremental_processing"],
      "gotchas": ["Sync only affects new/changed data", "Both views must be synced separately"],
      "performance": {"execution_time": "1-3s", "scaling": "O(new_data)", "optimization": "production"},
      "alternatives": {"description": "Automated sync triggers", "when_to_use": "Real-time annotation workflows"},
      "state_after": {"tables": ["ls_demo.videos"], "views": ["ls_demo.videos_2024_04_22", "ls_demo.frames_2024_04_22"], "variables": ["v", "frames"], "models_loaded": ["facebook/detr-resnet-50"]},
      "pattern_refs": ["incremental_sync"]
    },
    {
      "number": 19,
      "section_title": "Clean Up Label Studio Project",
      "intent": "Demonstrate project deletion and cleanup procedures",
      "code": "v.external_stores  # Get a list of all external stores for `v`",
      "imports_used": [],
      "explanation": "Shows external store identifiers before deletion for cleanup operations",
      "actual_output": "['ls_project_0']",
      "output_summary": "One external store linked to the view",
      "output_type": "text",
      "learns": ["external_store_management"],
      "reinforces": ["resource_management"],
      "gotchas": [],
      "performance": {"execution_time": "<1ms", "scaling": "O(1)", "optimization": "demo"},
      "alternatives": {"description": "Keep projects for continued use", "when_to_use": "Production workflows"},
      "state_after": {"tables": ["ls_demo.videos"], "views": ["ls_demo.videos_2024_04_22", "ls_demo.frames_2024_04_22"], "variables": ["v", "frames"], "models_loaded": ["facebook/detr-resnet-50"]},
      "pattern_refs": ["project_lifecycle_management"]
    },
    {
      "number": 20,
      "section_title": "Unlink and Delete Label Studio Project",
      "intent": "Complete cleanup by removing Label Studio integration",
      "code": "v.unlink_external_stores('ls_project_0', delete_external_data=True)",
      "imports_used": [],
      "explanation": "Unlinks and deletes Label Studio project and all annotation data (irreversible)",
      "actual_output": "Deleted Label Studio project: videos_2024_04_22\nUnlinked external store from table `videos_2024_04_22`: ls_project_0",
      "output_summary": "Label Studio project deleted and external store unlinked",
      "output_type": "text",
      "learns": ["project_deletion", "data_cleanup"],
      "reinforces": ["resource_cleanup"],
      "gotchas": ["delete_external_data=True is irreversible", "Set False to keep Label Studio project"],
      "performance": {"execution_time": "1-3s", "scaling": "O(1)", "optimization": "demo"},
      "alternatives": {"description": "Keep external project with delete_external_data=False", "when_to_use": "Preserve annotations for other uses"},
      "state_after": {"tables": ["ls_demo.videos"], "views": ["ls_demo.videos_2024_04_22", "ls_demo.frames_2024_04_22"], "variables": ["v", "frames"], "models_loaded": ["facebook/detr-resnet-50"]},
      "pattern_refs": ["annotation_cleanup"]
    },
    {
      "number": 21,
      "section_title": "Terminate Label Studio Server",
      "intent": "Clean up by stopping the Label Studio server process",
      "code": "ls_process.kill()",
      "imports_used": [],
      "explanation": "Terminates the Label Studio server process started at beginning of tutorial",
      "actual_output": "",
      "output_summary": "Label Studio server terminated",
      "output_type": "none",
      "learns": ["process_cleanup"],
      "reinforces": ["resource_management"],
      "gotchas": ["Process continues running if not explicitly killed"],
      "performance": {"execution_time": "<1s", "scaling": "O(1)", "optimization": "demo"},
      "alternatives": {"description": "Keep server running for continued use", "when_to_use": "Multiple annotation sessions"},
      "state_after": {"tables": ["ls_demo.videos"], "views": ["ls_demo.videos_2024_04_22", "ls_demo.frames_2024_04_22"], "variables": ["v", "frames"], "models_loaded": ["facebook/detr-resnet-50"]},
      "pattern_refs": ["server_cleanup"]
    }
  ],
  "patterns": [
    {
      "name": "label_studio_project_setup",
      "description": "Create and link Label Studio annotation projects to Pixeltable views",
      "confidence": "high",
      "frequency": 2,
      "first_seen": "using-label-studio",
      "code_template": "pxt.io.create_label_studio_project(view, xml_config)",
      "parameters": {
        "view": "Pixeltable view or table to annotate",
        "xml_config": "Label Studio XML configuration string"
      },
      "variations": [
        {
          "name": "custom_column_mapping",
          "difference": "Map columns to different field names",
          "code": "pxt.io.create_label_studio_project(view, config, col_mapping={'col': 'field'})"
        },
        {
          "name": "url_media_import",
          "difference": "Use URLs instead of file uploads",
          "code": "pxt.io.create_label_studio_project(view, config, media_import_method='url')"
        }
      ],
      "prerequisites": ["label_studio_server", "api_credentials"],
      "enables": ["human_annotation_workflows", "bidirectional_sync"],
      "performance_impact": "Task creation scales with data size",
      "reusable": true,
      "production_ready": true
    },
    {
      "name": "ml_preannotation_generation",
      "description": "Generate automated preannotations using ML models",
      "confidence": "high",
      "frequency": 3,
      "first_seen": "using-label-studio",
      "code_template": "view.add_computed_column(detections=detr_for_object_detection(view.image))",
      "parameters": {
        "ml_function": "Huggingface or custom ML function",
        "model_id": "Model identifier for inference"
      },
      "variations": [
        {
          "name": "classification_preannotation",
          "difference": "Generate classification labels",
          "code": "view.add_computed_column(labels=vit_for_image_classification(view.image))"
        }
      ],
      "prerequisites": ["ml_models", "media_data"],
      "enables": ["reduced_annotation_time", "consistent_labeling"],
      "performance_impact": "Model inference time per item",
      "reusable": true,
      "production_ready": true
    },
    {
      "name": "annotation_sync_back",
      "description": "Import completed annotations from Label Studio to Pixeltable",
      "confidence": "high",
      "frequency": 2,
      "first_seen": "using-label-studio",
      "code_template": "view.sync()",
      "parameters": {},
      "variations": [
        {
          "name": "scheduled_sync",
          "difference": "Automated sync on schedule",
          "code": "# Setup cron job or scheduler to call view.sync()"
        }
      ],
      "prerequisites": ["linked_label_studio_project"],
      "enables": ["continuous_annotation_import", "data_analysis"],
      "performance_impact": "Network and JSON parsing overhead",
      "reusable": true,
      "production_ready": true
    },
    {
      "name": "annotation_value_extraction",
      "description": "Parse annotation JSON to extract specific values",
      "confidence": "high",
      "frequency": 1,
      "first_seen": "using-label-studio",
      "code_template": "view.add_computed_column(label=view.annotations[0].result[0].value.choices[0])",
      "parameters": {
        "json_path": "Path to extract specific annotation values"
      },
      "variations": [
        {
          "name": "complex_annotation_parsing",
          "difference": "Use UDF for complex parsing logic",
          "code": "@pxt.udf\ndef parse_annotations(ann: dict) -> str:\n    return extract_complex_value(ann)"
        }
      ],
      "prerequisites": ["synced_annotations"],
      "enables": ["typed_annotation_access", "downstream_analysis"],
      "performance_impact": "JSON parsing overhead",
      "reusable": true,
      "production_ready": true
    },
    {
      "name": "frame_extraction_annotation",
      "description": "Extract video frames for frame-level annotation workflows",
      "confidence": "high",
      "frequency": 2,
      "first_seen": "using-label-studio",
      "code_template": "pxt.create_view(name, table.where(condition), iterator=FrameIterator.create(video=table.video, fps=0.25))",
      "parameters": {
        "fps": "Frame extraction rate (0 for native framerate)",
        "video_column": "Video column to extract frames from"
      },
      "variations": [
        {
          "name": "all_frames_extraction",
          "difference": "Extract every frame",
          "code": "FrameIterator.create(video=col, fps=0)"
        }
      ],
      "prerequisites": ["video_data"],
      "enables": ["frame_level_annotation", "temporal_analysis"],
      "performance_impact": "Scales with video length and fps",
      "reusable": true,
      "production_ready": true
    },
    {
      "name": "coco_format_conversion",
      "description": "Convert model outputs to COCO format for Label Studio",
      "confidence": "high",
      "frequency": 1,
      "first_seen": "using-label-studio",
      "code_template": "view.add_computed_column(coco=detr_to_coco(view.image, view.detections))",
      "parameters": {
        "image_column": "Image column for dimensions",
        "detections_column": "Model detection output"
      },
      "variations": [],
      "prerequisites": ["object_detection_results"],
      "enables": ["label_studio_preannotations"],
      "performance_impact": "Format conversion overhead",
      "reusable": true,
      "production_ready": true
    },
    {
      "name": "incremental_annotation_pipeline",
      "description": "Handle incremental data updates in annotation workflows",
      "confidence": "high",
      "frequency": 1,
      "first_seen": "using-label-studio",
      "code_template": "# New data triggers automatic recomputation\ntable.insert(new_data)\nview.sync()  # Sync only new tasks",
      "parameters": {},
      "variations": [],
      "prerequisites": ["annotation_pipeline_setup"],
      "enables": ["streaming_annotation_workflows", "real_time_updates"],
      "performance_impact": "Scales with new data volume",
      "reusable": true,
      "production_ready": true
    }
  ],
  "common_errors": [
    {
      "error_type": "Label Studio connection failed",
      "frequency": "common",
      "cause": "Server not running or incorrect API credentials",
      "symptoms": ["Connection timeout", "Authentication errors", "404 responses"],
      "solution": {
        "quick_fix": "Verify Label Studio server is running and API key is correct",
        "proper_fix": "Implement proper credential management and health checks"
      },
      "prevention": "Test connection before creating projects",
      "example": "Server not started before creating project",
      "first_seen": "using-label-studio#3"
    },
    {
      "error_type": "XML configuration validation error",
      "frequency": "occasional",
      "cause": "Invalid Label Studio XML configuration syntax",
      "symptoms": ["Project creation failure", "XML parsing errors"],
      "solution": {
        "quick_fix": "Validate XML syntax and Label Studio schema",
        "proper_fix": "Use Label Studio configuration validator"
      },
      "prevention": "Test XML configuration in Label Studio UI first",
      "example": "Mismatched XML tags or invalid field references",
      "first_seen": "using-label-studio#6"
    },
    {
      "error_type": "Model download/inference failure",
      "frequency": "occasional",
      "cause": "Network issues, GPU memory, or model compatibility",
      "symptoms": ["Model loading errors", "CUDA out of memory", "Inference timeouts"],
      "solution": {
        "quick_fix": "Reduce batch size or use CPU inference",
        "proper_fix": "Provision adequate resources and implement retry logic"
      },
      "prevention": "Test model requirements in isolation",
      "example": "DETR model requires significant GPU memory",
      "first_seen": "using-label-studio#14"
    }
  ],
  "test_questions": [
    {
      "question": "What column is automatically added when linking a view to Label Studio?",
      "answer": "An 'annotations' column (name configurable via col_mapping) to store Label Studio annotation results",
      "difficulty": "beginner"
    },
    {
      "question": "How do preannotations reduce manual annotation effort?",
      "answer": "ML models generate initial annotations that users can review and correct instead of starting from scratch",
      "difficulty": "intermediate"
    },
    {
      "question": "What happens when new data is added to a table linked to Label Studio?",
      "answer": "Computed columns update automatically, but sync() must be called explicitly to create new Label Studio tasks",
      "difficulty": "intermediate"
    },
    {
      "question": "Why convert DETR output to COCO format for Label Studio?",
      "answer": "Label Studio expects preannotations in COCO format for bounding box annotations, while DETR uses its own format",
      "difficulty": "advanced"
    }
  ],
  "production_tips": [
    {
      "tip": "Use media_import_method='url' for production deployments",
      "impact": "Avoids file upload bottlenecks and supports complex data configurations",
      "implementation": "Set up S3 credentials and configure bucket access in Label Studio",
      "trade_offs": "Requires additional S3 setup and credential management",
      "example": "Large-scale annotation workflows with thousands of images"
    },
    {
      "tip": "Implement automated sync scheduling for continuous workflows",
      "impact": "Enables real-time annotation pipelines without manual intervention",
      "implementation": "Set up cron jobs or workflow orchestration to call sync() regularly",
      "trade_offs": "May create unnecessary API calls if no new annotations",
      "example": "Production annotation pipelines with multiple annotators"
    },
    {
      "tip": "Pre-validate ML model resource requirements",
      "impact": "Prevents out-of-memory errors during preannotation generation",
      "implementation": "Test models with representative data sizes before production",
      "trade_offs": "Additional setup and testing overhead",
      "example": "DETR models require 4-8GB GPU memory for large images"
    },
    {
      "tip": "Use high confidence thresholds for preannotations",
      "impact": "Reduces false positives that waste annotator time reviewing incorrect predictions",
      "implementation": "Set threshold=0.9 or higher for object detection models",
      "trade_offs": "May miss some valid objects that need manual annotation",
      "example": "threshold=0.95 for production object detection workflows"
    }
  ],
  "pattern_maturity": {
    "novel_patterns": 0,
    "established_patterns": 7,
    "total_patterns": 7
  },
  "cookies": " Label Studio integration is like having a smart cookie decorator - the machine does the initial frosting, but humans add the perfect finishing touches!"
}