{
  "@context": "https://pixeltable.com/learn",
  "@type": "Tutorial",
  "@id": "working-with-fiftyone",
  "github_url": "https://github.com/pixeltable/pixeltable/blob/release/docs/notebooks/integrations/working-with-fiftyone.ipynb",
  "title": "Working with Voxel51 in Pixeltable",
  "objective": "Master FiftyOne integration for advanced dataset visualization, exploration, and multi-model comparison",
  "difficulty": "intermediate",
  "categories": ["visualization", "dataset_exploration", "integrations", "computer_vision", "model_comparison"],
  "prerequisites": ["pixeltable-basics", "image-analysis", "object-detection"],
  "imports_required": ["import fiftyone as fo", "import pixeltable as pxt", "from pixeltable.functions.huggingface import vit_for_image_classification, detr_for_object_detection"],
  "performance_notes": {
    "typical_runtime": "3-5 minutes including model inference",
    "resource_requirements": "FiftyOne app server, GPU for ML models, network for data display",
    "bottlenecks": ["Model inference", "Image processing", "FiftyOne dataset creation", "Web app startup"]
  },
  "key_learnings": [
    "FiftyOne provides interactive dataset visualization and exploration",
    "Multiple label sets enable model comparison workflows",
    "Classification and detection labels supported natively",
    "Pixeltable data exports directly to FiftyOne format",
    "UDFs transform model outputs to FiftyOne-compatible format",
    "Dataset sessions enable interactive exploration in notebooks",
    "Multiple detection models can be compared side-by-side"
  ],
  "relationships": {
    "builds_on": ["image_processing", "object_detection", "computed_columns"],
    "enables": ["advanced_dataset_exploration", "model_comparison", "interactive_analysis"],
    "see_also": ["using-label-studio", "huggingface-integration"],
    "contrasts_with": ["static_dataset_analysis"]
  },
  "steps": [
    {
      "number": 1,
      "section_title": "Install Dependencies",
      "intent": "Install FiftyOne and ML libraries for dataset visualization",
      "code": "%pip install -qU pixeltable fiftyone torch transformers",
      "imports_used": [],
      "explanation": "Installs FiftyOne for visualization, plus ML libraries for generating labels to visualize",
      "actual_output": "[Installation output]",
      "output_summary": "FiftyOne and ML dependencies installed successfully",
      "output_type": "text",
      "learns": [],
      "reinforces": ["installation", "visualization_tools"],
      "gotchas": ["FiftyOne requires MongoDB for some features", "Web server needs available ports"],
      "performance": {"execution_time": "1-3 minutes", "scaling": "O(1)", "optimization": "demo"},
      "alternatives": {"description": "Use existing FiftyOne installation", "when_to_use": "Already configured environment"},
      "state_after": {"tables": [], "views": [], "variables": [], "models_loaded": []},
      "pattern_refs": ["visualization_environment_setup"]
    },
    {
      "number": 2,
      "section_title": "Create Image Dataset",
      "intent": "Set up Pixeltable table with sample images for visualization",
      "code": "import fiftyone as fo\nimport pixeltable as pxt\n\n# Create a Pixeltable directory for the demo. We first drop the directory if it\n# exists, in order to ensure a clean environment.\n\npxt.drop_dir('fo_demo', force=True)\npxt.create_dir('fo_demo')",
      "imports_used": ["import fiftyone as fo", "import pixeltable as pxt"],
      "explanation": "Creates clean environment for FiftyOne integration demo with fresh directory",
      "actual_output": "Connected to Pixeltable database at: postgresql+psycopg://postgres:@/pixeltable?host=/Users/asiegel/.pixeltable/pgdata\nCreated directory `fo_demo`.",
      "output_summary": "Demo directory created for FiftyOne integration",
      "output_type": "text",
      "learns": [],
      "reinforces": ["environment_setup", "directory_management"],
      "gotchas": [],
      "performance": {"execution_time": "100-500ms", "scaling": "O(1)", "optimization": "demo"},
      "alternatives": {"description": "Use existing directory", "when_to_use": "Working with existing datasets"},
      "state_after": {"tables": [], "views": [], "variables": [], "models_loaded": []},
      "pattern_refs": ["demo_environment_setup"]
    },
    {
      "number": 3,
      "section_title": "Populate Table with Images",
      "intent": "Insert sample images for visualization and analysis",
      "code": "# Create a Pixeltable table for our dataset and insert some sample images.\n\nurl_prefix = 'https://raw.githubusercontent.com/pixeltable/pixeltable/main/docs/resources/images'\n\nurls = [\n    'https://raw.githubusercontent.com/pixeltable/pixeltable/main/docs/resources/images/000000000019.jpg',\n    'https://raw.githubusercontent.com/pixeltable/pixeltable/main/docs/resources/images/000000000025.jpg',\n    'https://raw.githubusercontent.com/pixeltable/pixeltable/main/docs/resources/images/000000000030.jpg',\n    'https://raw.githubusercontent.com/pixeltable/pixeltable/main/docs/resources/images/000000000034.jpg',\n]\n\nt = pxt.create_table('fo_demo.images', {'image': pxt.Image})\nt.insert({'image': url} for url in urls)\nt.head()",
      "imports_used": [],
      "explanation": "Creates image table and populates with sample COCO-style images from Pixeltable resources",
      "actual_output": "Created table images.\nInserting rows into images: 4 rows [00:00, 2775.85 rows/s]\nInserted 4 rows with 0 errors.\n\n                                               image\n0  <PIL.JpegImagePlugin.JpegImageFile image mode=...\n1  <PIL.JpegImagePlugin.JpegImageFile image mode=...\n2  <PIL.JpegImagePlugin.JpegImageFile image mode=...\n3  <PIL.JpegImagePlugin.JpegImageFile image mode=...",
      "output_summary": "Four sample images inserted into table for visualization demo",
      "output_type": "table",
      "learns": ["sample_dataset_creation"],
      "reinforces": ["table_creation", "image_data_insertion"],
      "gotchas": ["Images are downloaded and cached on insertion"],
      "performance": {"execution_time": "1-3s", "scaling": "O(n) downloads", "optimization": "demo"},
      "alternatives": {"description": "Use local image files", "when_to_use": "Offline development or private datasets"},
      "state_after": {"tables": ["fo_demo.images"], "views": [], "variables": ["t"], "models_loaded": []},
      "pattern_refs": ["sample_dataset_setup"]
    },
    {
      "number": 4,
      "section_title": "Export to FiftyOne - Basic",
      "intent": "Create initial FiftyOne dataset from Pixeltable images",
      "code": "fo_dataset = pxt.io.export_images_as_fo_dataset(t, t.image)\nsession = fo.launch_app(fo_dataset)",
      "imports_used": [],
      "explanation": "Exports Pixeltable table to FiftyOne format and launches interactive visualization session",
      "actual_output": " 4 [20.0ms elapsed, ? remaining, 199.8 samples/s] \n\nINFO:eta.core.utils: 4 [20.0ms elapsed, ? remaining, 199.8 samples/s] \n\n<IPython.core.display.HTML object>",
      "output_summary": "FiftyOne dataset created with 4 images and interactive session launched",
      "output_type": "text",
      "learns": ["basic_fiftyone_export"],
      "reinforces": ["data_export", "visualization_setup"],
      "gotchas": ["Session opens in browser", "Web server starts automatically"],
      "performance": {"execution_time": "1-3s", "scaling": "O(n) images", "optimization": "demo"},
      "alternatives": {"description": "Export without launching session", "when_to_use": "Programmatic dataset creation"},
      "state_after": {"tables": ["fo_demo.images"], "views": [], "variables": ["t", "fo_dataset", "session"], "models_loaded": []},
      "pattern_refs": ["basic_fiftyone_export"]
    },
    {
      "number": 5,
      "section_title": "Generate Classification Labels",
      "intent": "Add image classification results using Vision Transformer",
      "code": "from pixeltable.functions.huggingface import vit_for_image_classification, detr_for_object_detection\n\nt.add_computed_column(classifications=vit_for_image_classification(\n    t.image, model_id='google/vit-base-patch16-224'\n))\nt.add_computed_column(detections=detr_for_object_detection(\n    t.image, model_id='facebook/detr-resnet-50'\n))",
      "imports_used": ["from pixeltable.functions.huggingface import vit_for_image_classification, detr_for_object_detection"],
      "explanation": "Applies ViT classification and DETR object detection models to generate labels for visualization",
      "actual_output": "Computing cells: 100%|████████████████████████████████████████████| 4/4 [00:00<00:00,  5.86 cells/s]\nAdded 4 column values with 0 errors.\nComputing cells: 100%|████████████████████████████████████████████| 4/4 [00:01<00:00,  2.15 cells/s]\nAdded 4 column values with 0 errors.\n\nUpdateStatus(num_rows=4, num_computed_values=4, num_excs=0, updated_cols=[], cols_with_excs=[])",
      "output_summary": "Classification and detection models applied successfully to all images",
      "output_type": "text",
      "learns": ["ml_label_generation"],
      "reinforces": ["computed_columns", "huggingface_integration"],
      "gotchas": ["First run downloads models", "GPU recommended for performance", "Models return raw JSON"],
      "performance": {"execution_time": "30s-2min", "scaling": "O(n) inference", "optimization": "demo"},
      "alternatives": {"description": "Use different/multiple models", "when_to_use": "Comparing model performance"},
      "state_after": {"tables": ["fo_demo.images"], "views": [], "variables": ["t"], "models_loaded": ["google/vit-base-patch16-224", "facebook/detr-resnet-50"]},
      "pattern_refs": ["ml_labeling_pipeline"]
    },
    {
      "number": 6,
      "section_title": "Inspect Model Output Format",
      "intent": "Examine raw model outputs before FiftyOne conversion", 
      "code": "t.head()",
      "imports_used": [],
      "explanation": "Shows the JSON structure of model outputs that need conversion to FiftyOne format",
      "actual_output": "                                               image  \\\n0  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n1  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n2  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n3  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n\n                                     classifications  \\\n0  {'labels': [345, 690, 912, 346, 730], 'scores'...   \n1  {'labels': [340, 353, 386, 9, 352], 'scores': ...   \n2  {'labels': [883, 738, 708, 725, 716], 'scores'...   \n3  {'labels': [340, 353, 386, 352, 9], 'scores': ...   \n\n                                          detections  \n0  {'boxes': [[335.8553771972656, 43.413597106933...  \n1  {'boxes': [[51.96046829223633, 356.18701171875...  \n2  {'boxes': [[238.07403564453125, 155.5013275146...  \n3  {'boxes': [[-0.230712890625, 19.50192070007324...",
      "output_summary": "Model outputs shown as JSON with labels, scores, and bounding boxes",
      "output_type": "table",
      "learns": ["model_output_inspection"],
      "reinforces": ["data_inspection", "json_data_handling"],
      "gotchas": ["Raw outputs need format conversion", "Different models have different output schemas"],
      "performance": {"execution_time": "10-50ms", "scaling": "O(n)", "optimization": "demo"},
      "alternatives": {"description": "Filter specific columns for focused inspection", "when_to_use": "Large tables with many columns"},
      "state_after": {"tables": ["fo_demo.images"], "views": [], "variables": ["t"], "models_loaded": ["google/vit-base-patch16-224", "facebook/detr-resnet-50"]},
      "pattern_refs": ["model_output_inspection"]
    },
    {
      "number": 7,
      "section_title": "Create Format Conversion UDFs",
      "intent": "Transform model outputs to FiftyOne-compatible format",
      "code": "@pxt.udf\ndef vit_to_fo(vit_labels: list) -> list:\n    return [\n        {'label': label, 'confidence': score}\n        for label, score in zip(vit_labels['label_text'], vit_labels['scores'])\n    ]\n\n@pxt.udf\ndef detr_to_fo(img: pxt.Image, detr_labels: dict) -> list:\n    result = []\n    for label, box, score in zip(detr_labels['label_text'], detr_labels['boxes'], detr_labels['scores']):\n        # DETR gives us bounding boxes in (x1,y1,x2,y2) absolute (pixel) coordinates.\n        # Voxel51 expects (x,y,w,h) relative (fractional) coordinates.\n        # So we need to do a conversion.\n        fo_box = [\n            box[0] / img.width,\n            box[1] / img.height,\n            (box[2] - box[0]) / img.width,\n            (box[3] - box[1]) / img.height,\n        ]\n        result.append({'label': label, 'bounding_box': fo_box, 'confidence': score})\n    return result",
      "imports_used": [],
      "explanation": "Creates UDFs to convert ViT and DETR outputs to FiftyOne format with proper coordinate transformations",
      "actual_output": "",
      "output_summary": "UDFs defined for converting model outputs to FiftyOne classification and detection formats",
      "output_type": "none",
      "learns": ["format_conversion_udfs", "coordinate_transformation"],
      "reinforces": ["udf_creation", "data_transformation"],
      "gotchas": ["DETR uses absolute coordinates, FiftyOne uses relative", "Different models require different conversions"],
      "performance": {"execution_time": "<1ms", "scaling": "O(1)", "optimization": "demo"},
      "alternatives": {"description": "Use built-in conversion functions if available", "when_to_use": "Standard model formats"},
      "state_after": {"tables": ["fo_demo.images"], "views": [], "variables": ["t", "vit_to_fo", "detr_to_fo"], "models_loaded": ["google/vit-base-patch16-224", "facebook/detr-resnet-50"]},
      "pattern_refs": ["format_conversion_udfs"]
    },
    {
      "number": 8,
      "section_title": "Test UDF Conversions",
      "intent": "Verify format conversion UDFs work correctly",
      "code": "t.select(\n    t.image,\n    t.classifications,\n    vit_to_fo(t.classifications),\n    t.detections,\n    detr_to_fo(t.image, t.detections)\n).head()",
      "imports_used": [],
      "explanation": "Tests the conversion UDFs to ensure correct format transformation before FiftyOne export",
      "actual_output": "                                               image  \\\n0  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n1  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n2  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n3  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n\n                                     classifications  \\\n0  {'labels': [345, 690, 912, 346, 730], 'scores'...   \n1  {'labels': [340, 353, 386, 9, 352], 'scores': ...   \n2  {'labels': [883, 738, 708, 725, 716], 'scores'...   \n3  {'labels': [340, 353, 386, 352, 9], 'scores': ...   \n\n                                           vit_to_fo  \\\n0  [{'label': 'ox', 'confidence': 0.7670010328292...   \n1  [{'label': 'zebra', 'confidence': 0.3253521025...   \n2  [{'label': 'vase', 'confidence': 0.63610780239...   \n3  [{'label': 'zebra', 'confidence': 0.9953896999...   \n\n                                          detections  \\\n0  {'boxes': [[335.8553771972656, 43.413597106933...   \n1  {'boxes': [[51.96046829223633, 356.18701171875...   \n2  {'boxes': [[238.07403564453125, 155.5013275146...   \n3  {'boxes': [[-0.230712890625, 19.50192070007324...   \n\n                                          detr_to_fo  \n0  [{'label': 'person', 'bounding_box': [0.524774...  \n1  [{'label': 'giraffe', 'bounding_box': [0.08118...  \n2  [{'label': 'vase', 'bounding_box': [0.37199068...  \n3  [{'label': 'zebra', 'bounding_box': [-0.000360...",
      "output_summary": "Conversions successful: classification labels with confidence, detection boxes with relative coordinates",
      "output_type": "table",
      "learns": ["conversion_validation"],
      "reinforces": ["udf_testing", "data_transformation_verification"],
      "gotchas": ["Relative coordinates must be in [0,1] range", "Some boxes may extend beyond image boundaries"],
      "performance": {"execution_time": "100-500ms", "scaling": "O(n)", "optimization": "demo"},
      "alternatives": {"description": "Test conversions on single rows first", "when_to_use": "Debugging conversion logic"},
      "state_after": {"tables": ["fo_demo.images"], "views": [], "variables": ["t", "vit_to_fo", "detr_to_fo"], "models_loaded": ["google/vit-base-patch16-224", "facebook/detr-resnet-50"]},
      "pattern_refs": ["conversion_testing"]
    },
    {
      "number": 9,
      "section_title": "Export with Labels to FiftyOne",
      "intent": "Create FiftyOne dataset with both classification and detection labels",
      "code": "fo_dataset = pxt.io.export_images_as_fo_dataset(\n    t,\n    t.image,\n    classifications=vit_to_fo(t.classifications),\n    detections=detr_to_fo(t.image, t.detections)\n)\nsession = fo.launch_app(fo_dataset)",
      "imports_used": [],
      "explanation": "Exports enhanced dataset with both label types, enabling interactive exploration of model results",
      "actual_output": " 4 [36.6ms elapsed, ? remaining, 109.4 samples/s] \n\nINFO:eta.core.utils: 4 [36.6ms elapsed, ? remaining, 109.4 samples/s] \n\n<IPython.lib.display.IFrame at 0x490100760>",
      "output_summary": "FiftyOne dataset with labels created and interactive session launched",
      "output_type": "text",
      "learns": ["labeled_dataset_export"],
      "reinforces": ["fiftyone_export", "multi_label_visualization"],
      "gotchas": ["Label format must exactly match FiftyOne expectations", "Session opens in new browser tab"],
      "performance": {"execution_time": "1-3s", "scaling": "O(n) samples", "optimization": "demo"},
      "alternatives": {"description": "Export different label combinations", "when_to_use": "Comparing different model outputs"},
      "state_after": {"tables": ["fo_demo.images"], "views": [], "variables": ["t", "fo_dataset", "session"], "models_loaded": ["google/vit-base-patch16-224", "facebook/detr-resnet-50"]},
      "pattern_refs": ["labeled_fiftyone_export"]
    },
    {
      "number": 10,
      "section_title": "Add Second Detection Model",
      "intent": "Generate detections from more powerful DETR model for comparison",
      "code": "t.add_computed_column(detections_101=detr_for_object_detection(\n    t.image, model_id='facebook/detr-resnet-101'\n))",
      "imports_used": [],
      "explanation": "Adds ResNet-101 based DETR model to compare against ResNet-50 version for model evaluation",
      "actual_output": "Computing cells: 100%|████████████████████████████████████████████| 4/4 [00:01<00:00,  2.90 cells/s]\nAdded 4 column values with 0 errors.\n\nUpdateStatus(num_rows=4, num_computed_values=4, num_excs=0, updated_cols=[], cols_with_excs=[])",
      "output_summary": "Second detection model applied, adding more comprehensive object detection results",
      "output_type": "text",
      "learns": ["multi_model_comparison"],
      "reinforces": ["computed_columns", "model_comparison"],
      "gotchas": ["Larger models take longer to run", "ResNet-101 requires more memory than ResNet-50"],
      "performance": {"execution_time": "1-3min", "scaling": "O(n) inference", "optimization": "demo"},
      "alternatives": {"description": "Use different model architectures", "when_to_use": "Systematic model evaluation"},
      "state_after": {"tables": ["fo_demo.images"], "views": [], "variables": ["t"], "models_loaded": ["google/vit-base-patch16-224", "facebook/detr-resnet-50", "facebook/detr-resnet-101"]},
      "pattern_refs": ["multi_model_pipeline"]
    },
    {
      "number": 11,
      "section_title": "Export Multi-Model Comparison Dataset",
      "intent": "Create FiftyOne dataset comparing two detection models side-by-side",
      "code": "fo_dataset = pxt.io.export_images_as_fo_dataset(\n    t,\n    t.image,\n    classifications=vit_to_fo(t.classifications),\n    detections={\n        'detections_50': detr_to_fo(t.image, t.detections),\n        'detections_101': detr_to_fo(t.image, t.detections_101)\n    }\n)\nsession = fo.launch_app(fo_dataset)",
      "imports_used": [],
      "explanation": "Creates comparative visualization with named detection sets, enabling side-by-side model evaluation",
      "actual_output": " 4 [53.9ms elapsed, ? remaining, 74.2 samples/s] \n\nINFO:eta.core.utils: 4 [53.9ms elapsed, ? remaining, 74.2 samples/s] \n\n<IPython.core.display.HTML object>",
      "output_summary": "Comparative dataset created with two detection models for interactive analysis",
      "output_type": "text",
      "learns": ["model_comparison_visualization"],
      "reinforces": ["fiftyone_export", "multi_model_analysis"],
      "gotchas": ["Dictionary keys become label set names in FiftyOne", "Can compare multiple models simultaneously"],
      "performance": {"execution_time": "1-3s", "scaling": "O(n) samples", "optimization": "demo"},
      "alternatives": {"description": "Use list format for automatic naming", "when_to_use": "Simple comparisons without custom names"},
      "state_after": {"tables": ["fo_demo.images"], "views": [], "variables": ["t", "fo_dataset", "session"], "models_loaded": ["google/vit-base-patch16-224", "facebook/detr-resnet-50", "facebook/detr-resnet-101"]},
      "pattern_refs": ["comparative_visualization"]
    }
  ],
  "patterns": [
    {
      "name": "basic_fiftyone_export",
      "description": "Export Pixeltable image data to FiftyOne for interactive visualization",
      "confidence": "high",
      "frequency": 2,
      "first_seen": "working-with-fiftyone",
      "code_template": "fo_dataset = pxt.io.export_images_as_fo_dataset(table, image_column)",
      "parameters": {
        "table": "Pixeltable table or view with images",
        "image_column": "Column reference to image data"
      },
      "variations": [
        {
          "name": "session_launch",
          "difference": "Launch interactive session immediately",
          "code": "session = fo.launch_app(fo_dataset)"
        }
      ],
      "prerequisites": ["image_data", "fiftyone_installation"],
      "enables": ["interactive_dataset_exploration"],
      "performance_impact": "Dataset creation time scales with image count",
      "reusable": true,
      "production_ready": true
    },
    {
      "name": "format_conversion_udfs",
      "description": "Convert ML model outputs to FiftyOne-compatible label formats",
      "confidence": "high",
      "frequency": 2,
      "first_seen": "working-with-fiftyone",
      "code_template": "@pxt.udf\ndef model_to_fo(model_output: dict) -> list:\n    return [{'label': ..., 'confidence': ...}]",
      "parameters": {
        "model_output": "Raw model prediction output",
        "return_format": "List of FiftyOne label dictionaries"
      },
      "variations": [
        {
          "name": "detection_conversion",
          "difference": "Convert bounding box coordinates", 
          "code": "fo_box = [x/width, y/height, w/width, h/height]"
        }
      ],
      "prerequisites": ["model_outputs", "coordinate_understanding"],
      "enables": ["model_visualization", "label_standardization"],
      "performance_impact": "Conversion overhead per prediction",
      "reusable": true,
      "production_ready": true
    },
    {
      "name": "labeled_fiftyone_export",
      "description": "Export images with ML-generated labels for analysis and exploration",
      "confidence": "high",
      "frequency": 2,
      "first_seen": "working-with-fiftyone",
      "code_template": "pxt.io.export_images_as_fo_dataset(table, image_col, classifications=class_expr, detections=det_expr)",
      "parameters": {
        "classifications": "Expression returning classification labels",
        "detections": "Expression returning detection labels"
      },
      "variations": [
        {
          "name": "multiple_label_sets",
          "difference": "Include multiple label types",
          "code": "detections={'model1': expr1, 'model2': expr2}"
        }
      ],
      "prerequisites": ["ml_labels", "format_conversion"],
      "enables": ["label_visualization", "model_evaluation"],
      "performance_impact": "Label processing and format conversion time",
      "reusable": true,
      "production_ready": true
    },
    {
      "name": "multi_model_comparison",
      "description": "Compare multiple ML models using FiftyOne visualization",
      "confidence": "high",
      "frequency": 1,
      "first_seen": "working-with-fiftyone",
      "code_template": "table.add_computed_column(model2=different_model(table.image))",
      "parameters": {
        "model_functions": "Different ML model functions to compare"
      },
      "variations": [],
      "prerequisites": ["multiple_models", "computed_columns"],
      "enables": ["systematic_model_evaluation", "performance_comparison"],
      "performance_impact": "Scales with number of models and data size",
      "reusable": true,
      "production_ready": true
    },
    {
      "name": "comparative_visualization",
      "description": "Create side-by-side model comparisons in FiftyOne",
      "confidence": "high",
      "frequency": 1,
      "first_seen": "working-with-fiftyone",
      "code_template": "detections={'model_name_1': expr1, 'model_name_2': expr2}",
      "parameters": {
        "model_names": "Dictionary keys become label set names",
        "expressions": "Model output expressions for comparison"
      },
      "variations": [],
      "prerequisites": ["multiple_model_outputs", "format_conversion"],
      "enables": ["visual_model_comparison", "evaluation_workflows"],
      "performance_impact": "Multiple label processing and visualization overhead",
      "reusable": true,
      "production_ready": true
    },
    {
      "name": "ml_labeling_pipeline",
      "description": "Apply ML models to generate labels for dataset visualization",
      "confidence": "high",
      "frequency": 3,
      "first_seen": "working-with-fiftyone",
      "code_template": "table.add_computed_column(labels=ml_function(table.image, model_id='...'))",
      "parameters": {
        "ml_function": "Huggingface or custom ML function",
        "model_id": "Model identifier for consistent results"
      },
      "variations": [
        {
          "name": "multiple_models",
          "difference": "Apply several models for comparison",
          "code": "table.add_computed_column(model1=func1(col))\ntable.add_computed_column(model2=func2(col))"
        }
      ],
      "prerequisites": ["image_data", "ml_models"],
      "enables": ["automated_labeling", "model_evaluation"],
      "performance_impact": "Model inference time dominates",
      "reusable": true,
      "production_ready": true
    }
  ],
  "common_errors": [
    {
      "error_type": "FiftyOne format validation error",
      "frequency": "common",
      "cause": "Incorrect label format or coordinate system for FiftyOne",
      "symptoms": ["Dataset creation failure", "Label rendering issues", "Coordinate out of bounds"],
      "solution": {
        "quick_fix": "Check label format matches FiftyOne expectations",
        "proper_fix": "Implement proper format conversion and validation"
      },
      "prevention": "Test conversion UDFs with sample data before full export",
      "example": "Using absolute coordinates instead of relative [0,1] range",
      "first_seen": "working-with-fiftyone#7"
    },
    {
      "error_type": "Model inference memory error",
      "frequency": "occasional",
      "cause": "Insufficient GPU memory for large models or batch sizes",
      "symptoms": ["CUDA out of memory", "Model loading failure", "Inference timeouts"],
      "solution": {
        "quick_fix": "Use smaller models or reduce batch size",
        "proper_fix": "Scale infrastructure or implement memory management"
      },
      "prevention": "Test model memory requirements before production",
      "example": "DETR ResNet-101 requires more memory than ResNet-50",
      "first_seen": "working-with-fiftyone#10"
    },
    {
      "error_type": "FiftyOne session startup failure",
      "frequency": "occasional",
      "cause": "Port conflicts or MongoDB connection issues",
      "symptoms": ["Session launch timeout", "Browser connection refused", "MongoDB errors"],
      "solution": {
        "quick_fix": "Restart FiftyOne service or use different port",
        "proper_fix": "Configure proper MongoDB and network setup"
      },
      "prevention": "Verify FiftyOne dependencies before starting sessions",
      "example": "Default port 5151 already in use",
      "first_seen": "working-with-fiftyone#4"
    }
  ],
  "test_questions": [
    {
      "question": "What coordinate system does FiftyOne use for bounding boxes?",
      "answer": "Relative coordinates in [0,1] range: [x, y, width, height] as fractions of image dimensions",
      "difficulty": "intermediate"
    },
    {
      "question": "How do you compare multiple detection models in FiftyOne?",
      "answer": "Pass a dictionary to the detections parameter with model names as keys and expressions as values",
      "difficulty": "intermediate"
    },
    {
      "question": "What format should classification labels have for FiftyOne export?",
      "answer": "List of dictionaries with 'label' and 'confidence' keys",
      "difficulty": "beginner"
    },
    {
      "question": "Why are UDFs needed for FiftyOne export?",
      "answer": "To convert model-specific output formats to FiftyOne's standardized label formats",
      "difficulty": "intermediate"
    }
  ],
  "production_tips": [
    {
      "tip": "Pre-validate label formats before large dataset exports",
      "impact": "Prevents export failures and data corruption in production pipelines",
      "implementation": "Test conversion UDFs on sample data and validate output schemas",
      "trade_offs": "Additional validation overhead during development",
      "example": "Validate bounding box coordinates are in [0,1] range"
    },
    {
      "tip": "Use named detection sets for systematic model comparison",
      "impact": "Enables clear identification of models in comparative analysis",
      "implementation": "Use dictionary format with descriptive model names as keys",
      "trade_offs": "Slightly more complex configuration than list format",
      "example": "{'yolo_v5': yolo_expr, 'detr_101': detr_expr}"
    },
    {
      "tip": "Cache model outputs to avoid recomputation during exploration",
      "impact": "Significantly reduces dataset recreation time for iterative analysis",
      "implementation": "Use Pixeltable computed columns to persist model results",
      "trade_offs": "Increased storage requirements for cached predictions",
      "example": "Model predictions stored as computed columns, not recalculated"
    },
    {
      "tip": "Monitor memory usage with multiple large models",
      "impact": "Prevents out-of-memory crashes during multi-model comparisons",
      "implementation": "Profile memory usage and implement model loading/unloading strategies",
      "trade_offs": "May require sequential processing instead of parallel",
      "example": "Load one large model at a time for inference"
    }
  ],
  "pattern_maturity": {
    "novel_patterns": 0,
    "established_patterns": 6,
    "total_patterns": 6
  },
  "cookies": "🍪 FiftyOne integration is like having a smart cookie display case - you can see all your ML cookies at once and pick the tastiest ones for analysis!"
}