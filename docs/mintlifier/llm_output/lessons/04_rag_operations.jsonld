{
  "@context": "https://pixeltable.com/learn",
  "@type": "Tutorial",
  "@id": "rag-operations",
  "github_url": "https://github.com/pixeltable/pixeltable/blob/release/docs/notebooks/use-cases/rag-operations.ipynb",
  "title": "RAG Operations in Pixeltable",
  "objective": "Learn to chunk documents, create multiple views with different strategies, and compute embeddings for RAG workflows",
  "difficulty": "intermediate",
  "categories": ["rag", "document-processing", "embeddings", "chunking", "views"],
  "prerequisites": ["pixeltable-basics", "embedding-indexes"],
  "imports_required": ["pixeltable", "sentence-transformers", "spacy", "tiktoken", "pixeltable.iterators.document.DocumentSplitter", "pixeltable.functions.huggingface"],
  "performance_notes": {
    "typical_runtime": "5-10 minutes",
    "resource_requirements": "~500MB for embedding models, minimal CPU/GPU requirements"
  },
  "key_learnings": [
    "Views are virtual tables that transform source data dynamically",
    "DocumentSplitter enables multiple chunking strategies on same source",
    "Views update incrementally as new documents arrive",
    "Multiple embedding models can be applied as computed columns",
    "Chunking strategies dramatically affect downstream performance",
    "Pixeltable handles HTML, Markdown, PDF document types"
  ],
  "steps": [
    {
      "number": 1,
      "section_title": "Set Up the Table Structure",
      "intent": "Create workspace and base table for documents",
      "code": "import pixeltable as pxt\n\n# Ensure a clean slate for the demo\npxt.drop_dir('rag_ops_demo', force=True)\n# Create the Pixeltable workspace\npxt.create_dir('rag_ops_demo')",
      "imports_used": ["pixeltable"],
      "explanation": "Clean workspace setup. drop_dir with force ensures idempotent demos.",
      "actual_output": "Created directory `rag_ops_demo`.",
      "output_type": "text",
      "learns": ["workspace creation", "clean state setup"],
      "gotchas": ["force=True deletes existing data"],
      "performance": "Instant",
      "alternatives": "Could use if_exists parameter instead"
    },
    {
      "number": 2,
      "section_title": "Creating Tables and Views",
      "intent": "Create base document table",
      "code": "docs = pxt.create_table(\n    'rag_ops_demo.docs',\n    {'source_doc': pxt.Document}\n)",
      "imports_used": ["pixeltable"],
      "explanation": "pxt.Document type handles various formats (HTML, Markdown, PDF). Simple schema with just document column.",
      "actual_output": "Created table `docs`.",
      "output_type": "text",
      "learns": ["Document type", "minimal schema design"],
      "gotchas": ["Document is abstract type, actual format determined at insert"],
      "performance": "Instant",
      "alternatives": null
    },
    {
      "number": 3,
      "intent": "Create sentence-level chunking view",
      "code": "from pixeltable.iterators.document import DocumentSplitter\n\nsentences = pxt.create_view(\n    'rag_ops_demo.sentences',  # Name of the view\n    docs,  # Table from which the view is derived\n    iterator=DocumentSplitter.create(\n        document=docs.source_doc,\n        separators='sentence',  # Chunk docs into sentences\n        metadata='title,heading,sourceline'\n    )\n)",
      "imports_used": ["pixeltable", "pixeltable.iterators.document.DocumentSplitter"],
      "explanation": "Views are virtual tables with transformations. DocumentSplitter creates one-to-many mapping. Metadata preserves document structure.",
      "actual_output": "Created view `sentences` with 0 rows, 0 exceptions.",
      "output_type": "text",
      "learns": ["view creation", "DocumentSplitter", "metadata extraction", "one-to-many transformation"],
      "gotchas": ["View empty until source table has data", "Metadata fields optional"],
      "performance": "Instant creation, lazy evaluation",
      "alternatives": "Different separators: paragraph, token_limit, char_limit"
    },
    {
      "number": 4,
      "intent": "Examine view structure before data",
      "code": "sentences",
      "imports_used": ["pixeltable"],
      "explanation": "View inherits source_doc from parent, adds pos, text, and requested metadata fields.",
      "actual_output": "View 'rag_ops_demo.sentences' (of 'rag_ops_demo.docs')\n\n Column Name              Type Computed With\n         pos     Required[Int]              \n        text  Required[String]              \n       title            String              \n     heading              Json              \n  sourceline               Int              \n  source_doc          Document",
      "output_type": "text",
      "learns": ["view schema", "inherited columns", "metadata fields"],
      "gotchas": ["pos is position in document", "heading is JSON for hierarchical structure"],
      "performance": "Instant",
      "alternatives": null
    },
    {
      "number": 5,
      "section_title": "Data Ingestion",
      "intent": "Insert first document and observe propagation",
      "code": "docs.insert([{'source_doc': 'https://en.wikipedia.org/wiki/Marc_Chagall'}])",
      "imports_used": ["pixeltable"],
      "explanation": "Single insert triggers cascade to all views. Document fetched from URL and processed.",
      "actual_output": "Computing cells: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.50 cells/s]\nInserting rows into `docs`: 1 rows\nInserting rows into `sentences`: 1460 rows\nInserted 1461 rows with 0 errors.",
      "output_type": "text",
      "learns": ["automatic view updates", "cascade propagation", "URL document loading"],
      "gotchas": ["All views update immediately", "1 doc â†’ 1460 sentences expansion"],
      "performance": "~1 second for fetch and chunk",
      "alternatives": "Could insert local files or S3 URLs"
    },
    {
      "number": 6,
      "intent": "Verify document insertion and view population",
      "code": "docs.select(docs.source_doc.fileurl).show()",
      "imports_used": ["pixeltable"],
      "explanation": "fileurl accessor shows original URL. Document cached locally.",
      "actual_output": "                           source_doc_fileurl\n0  https://en.wikipedia.org/wiki/Marc_Chagall",
      "output_type": "table",
      "learns": ["document URL access", "fileurl property"],
      "gotchas": ["Document downloaded and cached, not linked"],
      "performance": "Instant query",
      "alternatives": null
    },
    {
      "number": 7,
      "intent": "Examine sentence chunking results",
      "code": "sentences.select(sentences.text, sentences.heading).show(20)",
      "imports_used": ["pixeltable"],
      "explanation": "Each sentence preserves heading context. Navigation and metadata included.",
      "actual_output": "[Table showing 20 sentences with heading hierarchy]",
      "output_type": "table",
      "learns": ["sentence boundaries", "metadata preservation"],
      "gotchas": ["First rows often navigation/header content", "heading shows full hierarchy"],
      "performance": "Instant",
      "alternatives": null
    },
    {
      "number": 8,
      "section_title": "Experimenting with Chunking",
      "intent": "Create paragraph view with token limits",
      "code": "chunks = pxt.create_view(\n    'rag_ops_demo.chunks', docs,\n    iterator=DocumentSplitter.create(\n        document=docs.source_doc,\n        separators='paragraph,token_limit',\n        limit=2048,\n        overlap=0,\n        metadata='title,heading,sourceline'\n    )\n)",
      "imports_used": ["pixeltable", "pixeltable.iterators.document.DocumentSplitter"],
      "explanation": "Multiple separators with fallback. Respects paragraphs but splits if >2048 tokens. Populated from existing docs.",
      "actual_output": "Inserting rows into `chunks`: 205 rows\nCreated view `chunks` with 205 rows, 0 exceptions.",
      "output_type": "text",
      "learns": ["multiple separators", "token limits", "automatic population"],
      "gotchas": ["Token != character", "Order matters in separators list"],
      "performance": "~0.1 seconds",
      "alternatives": "Could use char_limit instead of token_limit"
    },
    {
      "number": 9,
      "intent": "Create short token-based chunks",
      "code": "short_chunks = pxt.create_view(\n    'rag_ops_demo.short_chunks', docs,\n    iterator=DocumentSplitter.create(\n        document=docs.source_doc,\n        separators='paragraph,token_limit',\n        limit=72,\n        overlap=0,\n        metadata='title,heading,sourceline'\n    )\n)",
      "imports_used": ["pixeltable", "pixeltable.iterators.document.DocumentSplitter"],
      "explanation": "Same strategy but 72 token limit. Creates more, smaller chunks for different use cases.",
      "actual_output": "Inserting rows into `short_chunks`: 531 rows\nCreated view `short_chunks` with 531 rows, 0 exceptions.",
      "output_type": "text",
      "learns": ["chunk size impact", "token counting"],
      "gotchas": ["Small chunks may lose context", "More chunks = more embeddings to compute"],
      "performance": "~0.1 seconds",
      "alternatives": "Adjust limit based on model context window"
    },
    {
      "number": 10,
      "intent": "Create character-based chunking for comparison",
      "code": "short_char_chunks = pxt.create_view(\n    'rag_ops_demo.short_char_chunks', docs,\n    iterator=DocumentSplitter.create(\n        document=docs.source_doc,\n        separators='paragraph,char_limit',\n        limit=72,\n        overlap=0,\n        metadata='title,heading,sourceline'\n    )\n)",
      "imports_used": ["pixeltable", "pixeltable.iterators.document.DocumentSplitter"],
      "explanation": "Character limit instead of tokens. 72 chars much smaller than 72 tokens.",
      "actual_output": "Inserting rows into `short_char_chunks`: 1764 rows\nCreated view `short_char_chunks` with 1764 rows, 0 exceptions.",
      "output_type": "text",
      "learns": ["char vs token difference", "impact on chunk count"],
      "gotchas": ["72 chars â‰ˆ 10-15 tokens", "May break mid-word"],
      "performance": "~0.1 seconds",
      "alternatives": "Could add overlap for continuity"
    },
    {
      "number": 11,
      "intent": "Add more documents and observe incremental updates",
      "code": "urls = [\n    'https://en.wikipedia.org/wiki/Pierre-Auguste_Renoir',\n    'https://en.wikipedia.org/wiki/Henri_Matisse',\n    'https://en.wikipedia.org/wiki/Marcel_Duchamp'\n]\ndocs.insert({'source_doc': url} for url in urls)",
      "imports_used": ["pixeltable"],
      "explanation": "Batch insert triggers incremental updates to ALL views. Only new documents processed.",
      "actual_output": "Inserting rows into `docs`: 3 rows\nInserting rows into `sentences`: 2106 rows\nInserting rows into `chunks`: 276 rows\nInserting rows into `short_chunks`: 812 rows\nInserting rows into `short_char_chunks`: 2638 rows\nInserted 5835 rows with 0 errors.",
      "output_type": "text",
      "learns": ["incremental updates", "parallel view processing", "batch efficiency"],
      "gotchas": ["All views update simultaneously", "Different chunk counts per strategy"],
      "performance": "~2 seconds for 3 docs",
      "alternatives": null
    },
    {
      "number": 12,
      "section_title": "Computing Embeddings",
      "intent": "Add sentence transformer embeddings as computed column",
      "code": "from pixeltable.functions.huggingface import sentence_transformer\n\nchunks.add_computed_column(minilm_embed=sentence_transformer(\n    chunks.text,\n    model_id='paraphrase-MiniLM-L6-v2'\n))",
      "imports_used": ["pixeltable", "pixeltable.functions.huggingface"],
      "explanation": "Computed column applies to all existing and future data. MiniLM is fast, small model (384 dims).",
      "actual_output": "Computing cells: 100%|â–ˆâ–ˆâ–ˆ| 481/481 [00:02<00:00, 222.59 cells/s]\nAdded 481 column values with 0 errors.",
      "output_type": "text",
      "learns": ["computed columns on views", "embedding generation", "automatic backfill"],
      "gotchas": ["Computes for ALL existing rows immediately", "Model downloaded on first use"],
      "performance": "~2 seconds for 481 chunks",
      "alternatives": "Different models for quality/speed tradeoff"
    },
    {
      "number": 13,
      "intent": "Verify embedding column added to view",
      "code": "chunks",
      "imports_used": ["pixeltable"],
      "explanation": "Schema shows new embedding column with dimension and computation function.",
      "actual_output": "[View schema showing minilm_embed column with Array[(384,), Float] type]",
      "output_type": "text",
      "learns": ["embedding dimensions", "column type for arrays"],
      "gotchas": ["Array dimensions must match model output"],
      "performance": "Instant",
      "alternatives": null
    },
    {
      "number": 14,
      "intent": "Add CLIP embeddings for multimodal capability",
      "code": "from pixeltable.functions.huggingface import clip\n\nchunks.add_computed_column(clip_embed=clip(\n    chunks.text, model_id='openai/clip-vit-base-patch32'\n))",
      "imports_used": ["pixeltable", "pixeltable.functions.huggingface"],
      "explanation": "CLIP enables cross-modal search. 512-dimensional embeddings. Can compare with images later.",
      "actual_output": "Computing cells: 100%|â–ˆâ–ˆâ–ˆ| 481/481 [00:05<00:00, 93.49 cells/s]\nAdded 481 column values with 0 errors.",
      "output_type": "text",
      "learns": ["multiple embeddings per view", "CLIP for text", "multimodal preparation"],
      "gotchas": ["CLIP slower than MiniLM", "Larger embeddings (512 vs 384)"],
      "performance": "~5 seconds for 481 chunks",
      "alternatives": "Could use OpenAI embeddings"
    }
  ],
  "patterns": [
    {
      "name": "multi_strategy_chunking",
      "description": "Create multiple views with different chunking strategies on same source",
      "code_template": "# Base table\ndocs = pxt.create_table('docs', {'source_doc': pxt.Document})\n\n# Strategy 1: Sentences\nsentences = pxt.create_view('sentences', docs,\n    iterator=DocumentSplitter.create(document=docs.source_doc, separators='sentence'))\n\n# Strategy 2: Large chunks\nchunks = pxt.create_view('chunks', docs,\n    iterator=DocumentSplitter.create(document=docs.source_doc, separators='paragraph,token_limit', limit=2048))\n\n# Strategy 3: Small chunks\nshort = pxt.create_view('short', docs,\n    iterator=DocumentSplitter.create(document=docs.source_doc, separators='paragraph,token_limit', limit=72))",
      "variations": ["Different limits", "With/without overlap", "Token vs character limits"],
      "reusable": true
    },
    {
      "name": "incremental_rag_pipeline",
      "description": "Documents â†’ Views â†’ Embeddings, all updating incrementally",
      "code_template": "# Insert documents\ndocs.insert({'source_doc': url} for url in urls)\n# Views auto-update\n# Add embeddings\nview.add_computed_column(embed=sentence_transformer(view.text))\n# Future inserts automatically get chunked and embedded",
      "variations": ["Different embedding models", "Multiple embedding columns"],
      "reusable": true
    },
    {
      "name": "metadata_preservation",
      "description": "Keep document structure through chunking",
      "code_template": "iterator=DocumentSplitter.create(\n    document=docs.source_doc,\n    separators='paragraph',\n    metadata='title,heading,sourceline'  # Preserve context\n)",
      "variations": ["Different metadata fields", "Custom metadata extraction"],
      "reusable": true
    },
    {
      "name": "embedding_comparison",
      "description": "Add multiple embeddings to same chunks for A/B testing",
      "code_template": "chunks.add_computed_column(embed1=model1(chunks.text))\nchunks.add_computed_column(embed2=model2(chunks.text))\n# Compare retrieval quality",
      "variations": ["Different models", "Same model different parameters"],
      "reusable": true
    }
  ],
  "common_errors": [
    {
      "error_type": "ValueError: Separator not recognized",
      "cause": "Invalid separator name in DocumentSplitter",
      "solution": "Use valid separators: sentence, paragraph, token_limit, char_limit",
      "example": "separators='sentences' should be 'sentence'"
    },
    {
      "error_type": "Memory error during embedding computation",
      "cause": "Computing embeddings for too many chunks at once",
      "solution": "Process in batches or use smaller model",
      "example": "Large documents with small chunk size"
    },
    {
      "error_type": "KeyError on metadata field",
      "cause": "Requesting metadata not available in document type",
      "solution": "Check document format supports requested metadata",
      "example": "PDF may not have 'heading' metadata"
    }
  ],
  "test_questions": [
    "How do I chunk documents differently?",
    "How do I create multiple chunking strategies?",
    "What's the difference between views and tables?",
    "How do I add embeddings to chunks?",
    "How do incremental updates work?",
    "Can I use multiple embedding models?",
    "What's the difference between token and character limits?"
  ],
  "power_tips": [
    "Views don't store data - they transform on-the-fly",
    "Multiple views on same table enable A/B testing chunking strategies",
    "Incremental updates mean no reprocessing of existing data",
    "Token limits respect model tokenization, char limits don't",
    "CLIP embeddings enable future image-text search",
    "Computed columns backfill automatically on creation",
    "DocumentSplitter handles HTML structure intelligently"
  ],
  "cookies": "ðŸª Views are like cookies - same dough, different shapes!"
}