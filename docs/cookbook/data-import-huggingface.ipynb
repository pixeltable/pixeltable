{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import data from Hugging Face datasets\n",
        "\n",
        "Load datasets from Hugging Face Hub into Pixeltable tables for processing with AI models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem\n",
        "\n",
        "You want to use a dataset from Hugging Face Hubâ€”for fine-tuning, evaluation, or analysis. You need to load it into a format where you can add computed columns, embeddings, or AI transformations.\n",
        "\n",
        "| Dataset | Size | Use case |\n",
        "|---------|------|----------|\n",
        "| imdb | 50K reviews | Sentiment analysis |\n",
        "| squad | 100K Q&A | RAG evaluation |\n",
        "| coco | 330K images | Vision model training |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solution\n",
        "\n",
        "**What's in this recipe:**\n",
        "- Import Hugging Face datasets directly into tables\n",
        "- Handle datasets with multiple splits (train/test/validation)\n",
        "- Work with image datasets\n",
        "\n",
        "You use `pxt.create_table()` with a Hugging Face dataset as the `source` parameter. Pixeltable automatically maps HF types to Pixeltable column types.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU pixeltable datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pixeltable as pxt\n",
        "from datasets import load_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a fresh directory\n",
        "pxt.drop_dir('hf_demo', force=True)\n",
        "pxt.create_dir('hf_demo')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import a single split\n",
        "\n",
        "Load a specific split from a dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a small subset for demo (first 100 rows of rotten_tomatoes)\n",
        "hf_dataset = load_dataset('rotten_tomatoes', split='train[:100]')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import into Pixeltable\n",
        "reviews = pxt.create_table(\n",
        "    'hf_demo.reviews',\n",
        "    source=hf_dataset\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View imported data\n",
        "reviews.head(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import multiple splits\n",
        "\n",
        "Load a DatasetDict with multiple splits and track which split each row came from:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset with multiple splits (small subset for demo)\n",
        "hf_dataset_dict = load_dataset(\n",
        "    'rotten_tomatoes',\n",
        "    split={'train': 'train[:50]', 'test': 'test[:50]'}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import with split tracking column\n",
        "reviews_split = pxt.create_table(\n",
        "    'hf_demo.reviews_with_splits',\n",
        "    source=hf_dataset_dict,\n",
        "    column_name_for_split='split'  # Track which split each row came from\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View data with split information\n",
        "reviews_split.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter by split\n",
        "reviews_split.where(reviews_split.split == 'test').head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Add AI-powered computed columns\n",
        "\n",
        "Enrich the dataset with AI models:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add a computed column for text length\n",
        "reviews.add_computed_column(text_length=reviews.text.apply(len))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View with computed column\n",
        "reviews.select(reviews.text, reviews.label, reviews.text_length).head(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Type mapping\n",
        "\n",
        "Pixeltable automatically maps Hugging Face types to Pixeltable types:\n",
        "\n",
        "| Hugging Face Type | Pixeltable Type |\n",
        "|-------------------|-----------------|\n",
        "| `Value('string')` | `pxt.String` |\n",
        "| `Value('int64')` | `pxt.Int` |\n",
        "| `Value('float32')` | `pxt.Float` |\n",
        "| `ClassLabel` | `pxt.String` |\n",
        "| `Image` | `pxt.Image` |\n",
        "| `Sequence` | `pxt.Array` or `pxt.Json` |\n",
        "\n",
        "Use `schema_overrides` to customize type mapping when needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explanation\n",
        "\n",
        "**Why import Hugging Face datasets into Pixeltable:**\n",
        "\n",
        "1. **Add computed columns** - Enrich data with embeddings, AI analysis, or transformations\n",
        "2. **Incremental processing** - Add new rows without reprocessing existing data\n",
        "3. **Persistent storage** - Keep processed results across sessions\n",
        "4. **Query capabilities** - Filter, aggregate, and join with other tables\n",
        "\n",
        "**Working with large datasets:**\n",
        "\n",
        "For very large datasets, consider loading in batches or using streaming mode in the `datasets` library before importing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## See also\n",
        "\n",
        "- [Import CSV files](./data-import-csv.ipynb) - For CSV and Excel imports\n",
        "- [Semantic text search](./search-semantic-text.ipynb) - Add embeddings to text data\n",
        "- [Hugging Face integration notebook](https://docs.pixeltable.com/docs/integrations/working-with-hugging-face) - Full integration guide\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
