{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Export data for ML training\n",
        "\n",
        "Convert Pixeltable data to PyTorch DataLoader format for model training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem\n",
        "\n",
        "You have prepared training data—images with labels, text with embeddings, or multimodal data—and need to export it for PyTorch model training.\n",
        "\n",
        "| Data type | Use case |\n",
        "|-----------|----------|\n",
        "| Images + labels | Image classification |\n",
        "| Text + embeddings | Fine-tuning embeddings |\n",
        "| Audio + transcripts | Speech model training |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solution\n",
        "\n",
        "**What's in this recipe:**\n",
        "- Convert query results to PyTorch Dataset\n",
        "- Use with DataLoader for batch training\n",
        "- Export to Parquet for external tools\n",
        "\n",
        "You use `query.to_pytorch_dataset()` to create an iterable dataset compatible with PyTorch DataLoader.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU pixeltable torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pixeltable as pxt\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a fresh directory\n",
        "pxt.drop_dir('pytorch_demo', force=True)\n",
        "pxt.create_dir('pytorch_demo')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create sample training data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create table with images and labels\n",
        "training_data = pxt.create_table(\n",
        "    'pytorch_demo.training_data',\n",
        "    {'image': pxt.Image, 'label': pxt.Int}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insert sample images with labels\n",
        "base_url = 'https://raw.githubusercontent.com/pixeltable/pixeltable/main/docs/resources/images'\n",
        "samples = [\n",
        "    {'image': f'{base_url}/000000000036.jpg', 'label': 0},  # cat\n",
        "    {'image': f'{base_url}/000000000090.jpg', 'label': 1},  # other\n",
        "    {'image': f'{base_url}/000000000139.jpg', 'label': 1},  # other\n",
        "]\n",
        "training_data.insert(samples)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Export to PyTorch Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to PyTorch dataset\n",
        "# 'pt' format returns images as CxHxW tensors with values in [0,1]\n",
        "pytorch_dataset = training_data.select(\n",
        "    training_data.image, \n",
        "    training_data.label\n",
        ").to_pytorch_dataset(image_format='pt')\n",
        "\n",
        "type(pytorch_dataset)  # Should be IterableDataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use with PyTorch DataLoader\n",
        "dataloader = DataLoader(pytorch_dataset, batch_size=2)\n",
        "\n",
        "# Get first batch to verify shape\n",
        "batch = next(iter(dataloader))\n",
        "batch['image'].shape, batch['label']  # (batch_size, C, H, W), labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Export to Parquet for external tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tempfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Export to Parquet for use with other ML tools\n",
        "export_path = Path(tempfile.mkdtemp()) / 'training_data'\n",
        "\n",
        "pxt.io.export_parquet(\n",
        "    training_data.select(training_data.label),  # Non-image columns\n",
        "    parquet_path=export_path\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explanation\n",
        "\n",
        "**Export methods:**\n",
        "\n",
        "| Method | Output | Use case |\n",
        "|--------|--------|----------|\n",
        "| `to_pytorch_dataset()` | PyTorch IterableDataset | Direct training |\n",
        "| `export_parquet()` | Parquet files | External tools, sharing |\n",
        "| `export_lancedb()` | LanceDB | Vector search apps |\n",
        "| `to_coco_dataset()` | COCO JSON | Object detection |\n",
        "\n",
        "**Image format options:**\n",
        "\n",
        "| Format | Shape | Values | Use |\n",
        "|--------|-------|--------|-----|\n",
        "| `'pt'` | CxHxW | [0, 1] float32 | PyTorch models |\n",
        "| `'np'` | HxWxC | [0, 255] uint8 | NumPy processing |\n",
        "\n",
        "**DataLoader tips:**\n",
        "- Data is cached to disk for efficient repeated loading\n",
        "- Use `num_workers > 0` for parallel data loading\n",
        "- Filter/transform data before export to reduce size\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## See also\n",
        "\n",
        "- [Sample data for training](./data-sampling.ipynb) - Stratified sampling\n",
        "- [Import Parquet files](./data-import-parquet.ipynb) - Parquet import/export\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pixeltable",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
