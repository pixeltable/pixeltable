{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Working with Blob Storage in Pixeltable\n",
        "\n",
        "Pixeltable is declarative data infrastructure for multimodal AI applications. It manages metadata, transformations, and workflows, while your actual media files (images, videos, audio) are stored in cloud blob storage services.\n",
        "\n",
        "Pixeltable stores structured metadata and manages your data pipeline, while blob storage (S3, R2, B2, Azure Blob, GCS, Tigris) holds the actual media files. There are three common workflows that Pixeltable supports for integrating with blob storage.\n",
        "\n",
        "1. \n",
        "2. When Pixeltable generates or processes media, those results are stored in blob storage too. Pixeltable maintains references to the files, so you can query everything together.\n",
        "3. When you insert media into Pixeltable, it can automatically upload files to your blob storage. \n",
        "\n",
        "This guide shows you three ways to store media in blob storage (per-column destinations, global output destinations, global input destinations) and how to get servable URLs for all your media files.\n",
        "\n",
        "See how [Backblaze B2](https://www.backblaze.com/blog/building-multimodal-ai-data-infrastructure-with-pixeltable/), [Tigris](https://www.tigrisdata.com/docs/quickstarts/pixeltable/), and Google Cloud Storage integrate with Pixeltable for scalable multimodal AI workflows.\n",
        "\n",
        "Key use cases for blob storage with Pixeltable:\n",
        "- Storage: Scalable, durable storage for large volumes of media files\n",
        "- Serving media: Directly serving images, videos, or documents to browsers and applications via queryable URLs\n",
        "- Integration: Seamless integration with services like Backblaze B2, Tigris, and Google Cloud Storage for multimodal AI pipelines\n",
        "\n",
        "## Overview: Storing Media in Blob Storage\n",
        "\n",
        "Pixeltable can store your media files in cloud blob storage in two scenarios:\n",
        "\n",
        "1. **Storing media you insert** - When you insert media files into a table, they can be automatically uploaded to blob storage\n",
        "2. **Storing media Pixeltable generates** - When Pixeltable computes or generates media (via computed columns), those results can be stored in blob storage\n",
        "\n",
        "This guide covers both scenarios. You'll also learn how to get servable URLs for all your media files stored in blob storage.\n",
        "\n",
        "Storing media that Pixeltable generates: When Pixeltable creates media (computed columns, image generation, video processing), you can store it in blob storage using per-column destinations or a global output destination.\n",
        "\n",
        "Storing media that you insert: When you insert media files into a table, you can configure them to automatically upload to blob storage using a global input destination.\n",
        "\n",
        "Getting servable URLs: Regardless of how your media is stored, you can query URLs that point directly to your files in blob storage for serving to browsers and applications.\n",
        "\n",
        "---\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "For cloud storage (S3/R2/B2):\n",
        "- AWS credentials with write permissions to your target bucket\n",
        "- `boto3` package installed (Pixeltable will show a helpful error message with installation instructions if it's missing)\n",
        "\n",
        "Note: Pixeltable also supports local filesystem paths, but for multimodal AI workflows at scale, you'll want to use cloud blob storage where Pixeltable manages references to files stored in your blob storage service.\n",
        "\n",
        "Important Notes:\n",
        "- Media metadata is always stored locally in Pixeltable's database\n",
        "- Cloud-stored media files still count toward storage quotas (metadata tracking)\n",
        "- Always verify bucket permissions before using cloud destinations in production\n",
        "\n",
        "Let's set up our demo environment and install the required packages.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Install Pixeltable and boto3 (required for cloud storage):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU pixeltable boto3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's create a Pixeltable directory to keep the tables for this demo separate from anything else you're working on.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pixeltable as pxt\n",
        "\n",
        "# Remove the 'blob_storage_demo' directory if it exists\n",
        "pxt.drop_dir('blob_storage_demo', force=True)\n",
        "pxt.create_dir('blob_storage_demo')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t = pxt.create_table('blob_storage_demo.media', {'source_image': pxt.Image})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Configuring Credentials for Cloud Storage\n",
        "\n",
        "Before using cloud storage destinations, you need to configure credentials:\n",
        "\n",
        "Credential requirements:\n",
        "- S3-compatible (S3, R2, B2, Tigris): AWS credentials configured (see below)\n",
        "- Azure Blob Storage: Azure storage account credentials in `~/.pixeltable/config.toml` or environment variables\n",
        "- Google Cloud Storage: Google Cloud credentials via `GOOGLE_APPLICATION_CREDENTIALS` environment variable\n",
        "\n",
        "Configuring AWS credentials (for S3, R2, B2, Tigris)\n",
        "\n",
        "Step 1: Create AWS credentials file\n",
        "\n",
        "Create `~/.aws/credentials` with your access keys:\n",
        "\n",
        "```ini\n",
        "[my-profile]\n",
        "aws_access_key_id = YOUR_ACCESS_KEY\n",
        "aws_secret_access_key = YOUR_SECRET_KEY\n",
        "```\n",
        "\n",
        "Replace `my-profile` with any name you choose, and use your real IAM keys.\n",
        "\n",
        "Step 2: (Optional) Set AWS region\n",
        "\n",
        "If your bucket is outside `us-east-1`, create `~/.aws/config`:\n",
        "\n",
        "```ini\n",
        "[profile my-profile]\n",
        "region = us-west-2  # replace with your bucket's region\n",
        "```\n",
        "\n",
        "Step 3: Tell Pixeltable which AWS profile to use\n",
        "\n",
        "Choose one:\n",
        "\n",
        "Option A: Environment variable (temporary, per shell session)\n",
        "```bash\n",
        "export PIXELTABLE_S3_PROFILE=\"my-profile\"\n",
        "```\n",
        "\n",
        "Option B: Config file (persistent)  \n",
        "Add to `~/.pixeltable/config.toml`:\n",
        "```toml\n",
        "[pixeltable]\n",
        "s3_profile = \"my-profile\"\n",
        "```\n",
        "\n",
        "For R2 and B2, use `PIXELTABLE_R2_PROFILE` / `r2_profile` or `PIXELTABLE_B2_PROFILE` / `b2_profile` instead.\n",
        "\n",
        "Step 4: Verify permissions\n",
        "\n",
        "Your IAM user needs:\n",
        "- `s3:ListBucket` on `arn:aws:s3:::your-bucket-name`\n",
        "- `s3:PutObject` on `arn:aws:s3:::your-bucket-name/your-prefix/*`\n",
        "- `s3:HeadBucket` on the bucket\n",
        "\n",
        "Test access:\n",
        "```bash\n",
        "aws s3 ls s3://your-bucket-name/your-prefix/ --profile my-profile\n",
        "```\n",
        "\n",
        "Destination URI formats for cloud storage:\n",
        "\n",
        "| **Storage Service** | **Destination URI Format** |\n",
        "|---------------------|---------------------------|\n",
        "| Amazon S3 | `s3://bucket-name/path/prefix` |\n",
        "| Cloudflare R2 | `r2://bucket-name/path/prefix` |\n",
        "| Backblaze B2 | `b2://bucket-name/path/prefix` |\n",
        "| Google Cloud Storage | `gs://bucket-name/path/prefix` |\n",
        "| Azure Blob Storage | `https://account.blob.core.windows.net/container/path` |\n",
        "| Tigris | `https://t3.storage.dev/bucket-name/path` |\n",
        "\n",
        "Example: `destination='s3://my-images/thumbnails/'` saves to the `thumbnails/` prefix in the `my-images` S3 bucket.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Per-Column Destinations\n",
        "\n",
        "Specify where each computed column stores its media files by adding a `destination` parameter. This gives you fine-grained control over where each column's media files are stored.\n",
        "\n",
        "The `destination` parameter accepts blob storage URIs or local paths. See the table above for cloud storage URI formats. For local filesystem paths, use `/path/to/directory` or `file:///path/to/directory` (mainly for development/testing).\n",
        "\n",
        "Data flow with per-column destinations:\n",
        "\n",
        "```mermaid\n",
        "flowchart TD\n",
        "    A[Computed Column 1<br/>destination='s3://bucket/path1/'] --> B[File stored in<br/>s3://bucket/path1/]\n",
        "    C[Computed Column 2<br/>destination='s3://bucket/path2/'] --> D[File stored in<br/>s3://bucket/path2/]\n",
        "    \n",
        "    B --> E[Pixeltable Database<br/>Metadata + References]\n",
        "    D --> E\n",
        "    \n",
        "    E --> F[Query returns<br/>.fileurl pointing to blob storage]\n",
        "    \n",
        "    style B fill:#e1f5ff\n",
        "    style D fill:#e1f5ff\n",
        "    style E fill:#fff4e1\n",
        "    style F fill:#e1f5ff\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this demo: We'll use a local directory so you can run the example without cloud credentials. In production, replace these with cloud storage URIs from the table above.\n",
        "\n",
        "Create a local directory for this demo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "local_dest = Path.home() / 'Desktop' / 'pixeltable_outputs'\n",
        "local_dest.mkdir(parents=True, exist_ok=True)\n",
        "local_dest\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insert a sample image:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insert a sample image from the repo\n",
        "sample_image = 'https://raw.githubusercontent.com/pixeltable/pixeltable/main/docs/resources/images/000000000036.jpg'\n",
        "t.insert(source_image=sample_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add a computed column with a destination parameter\n",
        "# Format: destination='s3://bucket-name/path' for cloud storage\n",
        "# For this demo, using a local path (replace with cloud URI in production)\n",
        "t.add_computed_column(\n",
        "    rotated_local=t.source_image.rotate(90),\n",
        "    destination=str(local_dest),  # In production: destination='s3://my-bucket/rotated/'\n",
        ")\n",
        "\n",
        "# Check the results\n",
        "t.select(t.source_image, t.rotated_local).show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Add another computed column with a different destination\n",
        "# Each column can have its own destination\n",
        "t.add_computed_column(\n",
        "    flipped=t.source_image.flip('horizontal'),\n",
        "    destination=str(local_dest / 'flipped'),  # In production: destination='s3://my-bucket/flipped/'\n",
        ")\n",
        "\n",
        "# View the results\n",
        "t.select(t.source_image, t.rotated_local, t.flipped).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add another computed column with a different destination\n",
        "# Each column can have its own destination\n",
        "t.add_computed_column(\n",
        "    flipped=t.source_image.flip('horizontal'),\n",
        "    destination=str(local_dest / 'flipped'),  # In production: destination='s3://my-bucket/flipped/'\n",
        ")\n",
        "\n",
        "# View the results\n",
        "t.select(t.source_image, t.rotated_local, t.flipped).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify where our files are stored\n",
        "t.select(\n",
        "    t.source_image.fileurl,\n",
        "    t.rotated_local.fileurl,\n",
        "    t.flipped.fileurl,\n",
        ").collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Global Output Destination\n",
        "\n",
        "Instead of specifying a destination for each computed column, you can set a global default for all generated/computed media. This is configured in `~/.pixeltable/config.toml`.\n",
        "\n",
        "Data flow with global output destination:\n",
        "\n",
        "```mermaid\n",
        "flowchart TD\n",
        "    A[Computed Column 1<br/>no destination specified] --> B[All computed files]\n",
        "    C[Computed Column 2<br/>no destination specified] --> B\n",
        "    D[Computed Column 3<br/>no destination specified] --> B\n",
        "    \n",
        "    B --> E[Stored in<br/>Global Output Destination<br/>s3://bucket/computed-media/]\n",
        "    \n",
        "    E --> F[Pixeltable Database<br/>Metadata + References]\n",
        "    \n",
        "    F --> G[Query returns<br/>.fileurl pointing to blob storage]\n",
        "    \n",
        "    style E fill:#e1f5ff\n",
        "    style F fill:#fff4e1\n",
        "    style G fill:#e1f5ff\n",
        "```\n",
        "\n",
        "When to use this\n",
        "\n",
        "Use a global output destination when:\n",
        "- You want all computed media (rotated images, generated videos, etc.) to go to the same place\n",
        "- You're managing costs by storing computed results in cheaper cloud storage\n",
        "- You want a \"set and forget\" configuration\n",
        "\n",
        "Configuration\n",
        "\n",
        "Add this to your `~/.pixeltable/config.toml`:\n",
        "\n",
        "```toml\n",
        "[pixeltable]\n",
        "output_media_dest = \"s3://your-bucket-name/computed-media/\"\n",
        "```\n",
        "\n",
        "Or set via environment variable:\n",
        "```bash\n",
        "export PIXELTABLE_OUTPUT_MEDIA_DEST=\"s3://your-bucket-name/computed-media/\"\n",
        "```\n",
        "\n",
        "How it works\n",
        "\n",
        "Once configured:\n",
        "- Any computed column without an explicit `destination` parameter will use this global destination\n",
        "- Computed columns with an explicit `destination` parameter will use that specific destination instead\n",
        "- Input media (what you insert) is unaffected and follows normal storage rules\n",
        "\n",
        "Example\n",
        "\n",
        "```python\n",
        "# With global output_media_dest configured to S3:\n",
        "\n",
        "# This computed column will go to S3 (uses global default)\n",
        "t.add_computed_column(thumbnail=t.source_image.resize((100, 100)))\n",
        "\n",
        "# This computed column will go to the specified local path (overrides global default)\n",
        "t.add_computed_column(\n",
        "    preview=t.source_image.resize((300, 300)),\n",
        "    destination='/path/to/local/folder'\n",
        ")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check current global output destination (if any)\n",
        "from pixeltable.env import Env\n",
        "\n",
        "env = Env.get()\n",
        "if env.default_output_media_dest:\n",
        "    print(f\"Global output destination is set to: {env.default_output_media_dest}\")\n",
        "else:\n",
        "    print(\"No global output destination configured (using default local storage)\")\n",
        "\n",
        "# To set a global output destination, edit ~/.pixeltable/config.toml:\n",
        "# [pixeltable]\n",
        "# output_media_dest = \"s3://your-bucket-name/computed-media/\"\n",
        "#\n",
        "# Then restart Pixeltable or run: pxt.init()\n",
        "#\n",
        "# After that, any computed column without an explicit destination will use this default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check current global input destination (if any)\n",
        "env = Env.get()\n",
        "if env.default_input_media_dest:\n",
        "    print(f\"Global input destination is set to: {env.default_input_media_dest}\")\n",
        "    print(\"\\nWith this configured, all inserted media will be copied to this location.\")\n",
        "else:\n",
        "    print(\"No global input destination configured\")\n",
        "    print(\"Inserted media will be stored in Pixeltable's default local storage.\")\n",
        "\n",
        "# To set a global input destination, edit ~/.pixeltable/config.toml:\n",
        "# [pixeltable]\n",
        "# input_media_dest = \"s3://your-bucket-name/input-media/\"\n",
        "#\n",
        "# Then restart Pixeltable or run: pxt.init()\n",
        "#\n",
        "# After that, any media you insert will be automatically copied to this destination\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Global Input Destination\n",
        "\n",
        "When you insert media files into a table (via `t.insert()`), you can configure them to automatically upload to blob storage. This is how Pixeltable integrates with blob storage services like Backblaze B2, Tigris, and Google Cloud Storage—when you insert a local file or URL, it's automatically uploaded to blob storage and a reference is stored in the table.\n",
        "\n",
        "Data flow with global input destination:\n",
        "\n",
        "```mermaid\n",
        "flowchart TD\n",
        "    A[Insert: Local file<br/>./my-video.mp4] --> B[Automatic upload]\n",
        "    C[Insert: URL<br/>https://example.com/image.jpg] --> B\n",
        "    \n",
        "    B --> D[File stored in<br/>Global Input Destination<br/>s3://bucket/input-media/]\n",
        "    \n",
        "    D --> E[Pixeltable Database<br/>Metadata + References]\n",
        "    \n",
        "    E --> F[Query returns<br/>.fileurl pointing to blob storage]\n",
        "    \n",
        "    style D fill:#e1f5ff\n",
        "    style E fill:#fff4e1\n",
        "    style F fill:#e1f5ff\n",
        "```\n",
        "\n",
        "When to use this\n",
        "\n",
        "Use a global input destination when:\n",
        "- You want all media files inserted into Pixeltable to automatically upload to your blob storage service\n",
        "- You're building a multimodal AI pipeline where source media should live in blob storage\n",
        "- You're using Pixeltable with services like Backblaze B2, Tigris, or Google Cloud Storage and want automatic uploads\n",
        "- You want Pixeltable to manage the entire data lifecycle, from ingestion to storage\n",
        "\n",
        "Configuration\n",
        "\n",
        "Add this to your `~/.pixeltable/config.toml`:\n",
        "\n",
        "```toml\n",
        "[pixeltable]\n",
        "input_media_dest = \"s3://your-bucket-name/input-media/\"\n",
        "# For Tigris:\n",
        "# input_media_dest = \"https://t3.storage.dev/your-bucket/input\"\n",
        "# For Backblaze B2:\n",
        "# input_media_dest = \"b2://your-bucket-name/input-media/\"\n",
        "```\n",
        "\n",
        "Or set via environment variable:\n",
        "```bash\n",
        "export PIXELTABLE_INPUT_MEDIA_DEST=\"s3://your-bucket-name/input-media/\"\n",
        "```\n",
        "\n",
        "How it works\n",
        "\n",
        "Once configured:\n",
        "- When you insert media (images, videos, audio) into a table, Pixeltable automatically uploads those files to your configured blob storage\n",
        "- Pixeltable maintains references to the files in the table—the actual files live in blob storage\n",
        "- This happens automatically during insert operations—no manual upload code needed\n",
        "- Computed columns still follow their own destination rules (either per-column or global output destination)\n",
        "\n",
        "Example\n",
        "\n",
        "```python\n",
        "# With global input_media_dest configured to Tigris, Backblaze B2, or Google Cloud Storage:\n",
        "\n",
        "# Create a table\n",
        "videos = pxt.create_table('content', {\n",
        "    'video': pxt.Video,\n",
        "    'title': pxt.String\n",
        "})\n",
        "\n",
        "# When you insert, the video is automatically uploaded to blob storage\n",
        "videos.insert({\n",
        "    'video': './my-video.mp4',\n",
        "    'title': 'My Video'\n",
        "})\n",
        "\n",
        "# Pixeltable maintains a reference to the file in blob storage\n",
        "# The actual file is stored in your configured blob storage service\n",
        "```\n",
        "\n",
        "Important notes\n",
        "\n",
        "- This enables seamless integration with blob storage services—files are automatically uploaded when inserted\n",
        "- Pixeltable manages references, so you can query and work with the data as if it were local\n",
        "- Works seamlessly with services like [Backblaze B2](https://www.backblaze.com/blog/building-multimodal-ai-data-infrastructure-with-pixeltable/), [Tigris](https://www.tigrisdata.com/docs/quickstarts/pixeltable/), and Google Cloud Storage\n",
        "- The upload happens automatically—no additional code needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Getting URLs for Serving Media\n",
        "\n",
        "One of the key benefits of storing media in blob storage is that you can serve files directly to browsers and applications. Pixeltable provides queryable URLs through the `.fileurl` property that point to your files in blob storage.\n",
        "\n",
        "After configuring destinations and computing columns, you can get the URLs where files are stored:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Serving Media from Blob Storage\n",
        "\n",
        "When your media is stored in blob storage, query URLs using `.fileurl` in your select statements:\n",
        "\n",
        "```python\n",
        "# Query media with their blob storage URLs\n",
        "t.select(\n",
        "    t.source_image,\n",
        "    t.source_image.fileurl,\n",
        "    t.rotated_local,\n",
        "    t.rotated_local.fileurl\n",
        ").collect()\n",
        "\n",
        "# Filter and get URLs for specific rows\n",
        "t.where(t.some_condition).select(\n",
        "    t.source_image.fileurl,\n",
        "    t.processed_image.fileurl\n",
        ").collect()\n",
        "```\n",
        "\n",
        "Benefits:\n",
        "- Direct serving: URLs point directly to your blob storage, no proxy needed\n",
        "- Scalable: Blob storage services handle the traffic and bandwidth\n",
        "- CDN-ready: Many blob storage services offer CDN integration for fast global delivery\n",
        "- Queryable: Get URLs through Pixeltable queries, filter by metadata, then serve the results\n",
        "\n",
        "This makes it easy to build applications that serve media directly from blob storage while using Pixeltable to manage and query your data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get queryable URLs for serving media from blob storage\n",
        "# Query with .fileurl to get URLs that can be used directly in HTML, APIs, or applications\n",
        "t.select(\n",
        "    t.source_image,\n",
        "    t.source_image.fileurl,\n",
        "    t.rotated_local,\n",
        "    t.rotated_local.fileurl,\n",
        "    t.flipped,\n",
        "    t.flipped.fileurl\n",
        ").collect()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary: Choosing the Right Configuration\n",
        "\n",
        "Here's a quick decision guide organized by what you're trying to store:\n",
        "\n",
        "Storing Media That Pixeltable Generates\n",
        "\n",
        "| **Scenario** | **Recommended Approach** |\n",
        "|-------------|----------------------|\n",
        "| Different computed columns need different storage locations | Per-column destinations |\n",
        "| All computed columns should go to the same blob storage service | Global output destination |\n",
        "| You want fine-grained control over each column's storage | Per-column destinations |\n",
        "\n",
        "Storing Media That You Insert\n",
        "\n",
        "| **Scenario** | **Recommended Approach** |\n",
        "|-------------|----------------------|\n",
        "| You want all inserted media to automatically upload to blob storage | Global input destination |\n",
        "| You're building a system where source media should live in blob storage | Global input destination |\n",
        "\n",
        "Using Both\n",
        "\n",
        "| **Scenario** | **Recommended Approach** |\n",
        "|-------------|----------------------|\n",
        "| You want all media (input and computed) in the same blob storage service | Global input + Global output destinations |\n",
        "\n",
        "Key Takeaways\n",
        "\n",
        "1. Pixeltable manages metadata and workflows; blob storage holds the actual media files - This is an integrated system, not just storage\n",
        "2. Per-column destinations (`destination=` parameter) give you fine-grained control over where computed results are stored\n",
        "3. Global output destination (`output_media_dest` in config) automatically stores all generated/computed media in your blob storage service\n",
        "4. Global input destination (`input_media_dest` in config) automatically uploads inserted media to blob storage—this is how Pixeltable integrates with services like Backblaze B2, Tigris, and Google Cloud Storage\n",
        "5. Per-column destinations always override global settings when specified\n",
        "\n",
        "---\n",
        "\n",
        "## Learn More\n",
        "\n",
        "- [Pixeltable Configuration](https://docs.pixeltable.com/overview/configuration)\n",
        "- [Working with External Files](https://docs.pixeltable.com/notebooks/feature-guides/working-with-external-files)\n",
        "- [API Reference: add_computed_column](https://docs.pixeltable.com/api/pixeltable/table#pixeltable.Table.add_computed_column)\n",
        "\n",
        "If you have questions about blob storage destinations, reach out on our [Discord community](https://pixeltable.com/discord)!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
