{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "983yjns496tx"
   },
   "source": [
    "[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/pixeltable/pixeltable/blob/master/docs/tutorials/fireworks-demo.ipynb)&nbsp;&nbsp;\n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pixeltable/pixeltable/blob/master/docs/release/tutorials/fireworks-demo.ipynb)\n",
    "\n",
    "# Using the Fireworks API with Pixeltable\n",
    "\n",
    "Pixeltable's Fireworks integration enables you to access advanced large language models (LLMs) hosted on the Fireworks platform.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- A Fireworks account with an API key (https://fireworks.ai/api-keys)\n",
    "\n",
    "## Important Notes\n",
    "\n",
    "Fireworks usage may incur costs based on your Fireworks plan.\n",
    "Be mindful of sensitive data and consider security measures when integrating with external services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9pckrD01ik-e",
    "outputId": "060b8b32-48a6-48a0-e720-4eacf94d83ef"
   },
   "outputs": [],
   "source": [
    "%pip install -q pixeltable fireworks-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brtjK-88tTSS",
    "outputId": "55d08c91-438a-4c3e-c217-3cea72faca11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Pixeltable database at: postgresql://postgres:@/pixeltable?host=/Users/asiegel/.pixeltable/pgdata\n"
     ]
    }
   ],
   "source": [
    "import pixeltable as pxt\n",
    "\n",
    "pxt.create_dir('demo', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNtVb7Hw-Ojh"
   },
   "source": [
    "Securely store your Fireworks API key by not hardcoding it into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AQ6_Py7_7d0r",
    "outputId": "f82cfe36-be9e-4d43-f13e-9f6f5b680e8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fireworks API Key:··········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "if 'FIREWORKS_API_KEY' not in os.environ:\n",
    "    os.environ['FIREWORKS_API_KEY'] = getpass.getpass('Fireworks API Key:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97A0XhuR-YMB"
   },
   "source": [
    "Create a Table: In Pixeltable, create a table with columns to  represent your input data and the columns where you want to store the results from Fireworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hgy_gXmIu7jM",
    "outputId": "64b73be5-73bd-44bd-f7f3-80f74f4b6df3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table `table_firework`.\n",
      "Added 0 column values with 0 errors.\n"
     ]
    }
   ],
   "source": [
    "from pixeltable.functions.fireworks import chat_completions\n",
    "\n",
    "# Create a table in Pixeltable and pick a model hosted on Fireworks\n",
    "t = pxt.create_table('demo.fireworks', {'input': pxt.StringType()})\n",
    "messages = [{'role': 'user', 'content': t.input}]\n",
    "t['response'] = chat_completions(messages=messages, model='accounts/fireworks/models/llama-v2-7b-chat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kmjJoDq9Oqe"
   },
   "source": [
    "## Customization\n",
    "\n",
    "The `chat_completions` function provides several parameters to tune the LLM's output:\n",
    "\n",
    "- `model`: Select the specific Fireworks model that best suits your needs.\n",
    "- `max_tokens`: Control the maximum length of the generated response.\n",
    "- `top_k`, `top_p`, `temperature`: Fine-tune the diversity and creativity of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ti10tXu5m3X",
    "outputId": "30848066-1e9b-4efd-aad7-b2271a031ec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 0 column values with 0 errors.\n"
     ]
    }
   ],
   "source": [
    "# Set function parameters and define the column that stores the results from Fireworks\n",
    "t['bot_response'] = chat_completions(\n",
    "    messages=messages,\n",
    "    model='accounts/fireworks/models/llama-v2-7b-chat',\n",
    "    # These parameters are optional and can be used to tune model behavior:\n",
    "    max_tokens=300,\n",
    "    top_k=40,\n",
    "    top_p=0.9,\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mePjoku95iUn",
    "outputId": "07c3f8f0-5301-44ba-ba33-25d10c3c26fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 0 column values with 0 errors.\n"
     ]
    }
   ],
   "source": [
    "# Parse the bot_response into a new column\n",
    "t['response'] = t.bot_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "IkMM7OYb5rQ_",
    "outputId": "8e94af3e-485c-49f2-d7ba-b5490ec83af9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing cells: 100%|████████████████████████████████████████████| 3/3 [00:01<00:00,  2.89 cells/s]\n",
      "Inserting rows into `table_firework`: 1 rows [00:00, 326.63 rows/s]\n",
      "Computing cells: 100%|████████████████████████████████████████████| 3/3 [00:01<00:00,  2.86 cells/s]\n",
      "Inserted 1 row with 0 errors.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>input</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>How are you?</td>\n",
       "      <td>Hello! I'm just an AI, I don't have feelings or emotions like humans do, but I'm here to help you with any questions or tasks you may have. I'm here to provide helpful and respectful responses, while being safe and socially unbiased. Is there anything specific you would like to know or discuss?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>What can you help me with?</td>\n",
       "      <td>Hello! I'm here to assist you in any way I can, while adhering to ethical and moral standards. I'm glad you asked! I can help you with a wide range of topics, including but not limited to:\\n\\n1. General knowledge and information on various subjects, such as history, science, technology, and more.\\n2. Assistance with tasks and projects, such as writing, research, and organization.\\n3. Support and guidance on personal issues, such as mental health, relationships, and self-improvement.\\n4. Help with language-related tasks, such as language translation, grammar correction, and language learning.\\n5. Advice and recommendations on various topics, such as career choices, education, and personal development.\\n\\nPlease feel free to ask me anything, and I will do my best to provide you with helpful and responsible responses.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Are you remembering the question I just asked you?</td>\n",
       "      <td>Of course, I apologize for any confusion earlier. I'm here to help you with any questions you may have, and I'll do my best to provide respectful and accurate responses. Please feel free to ask your question again, and I'll do my best to assist you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ok remember the number 2</td>\n",
       "      <td>Of course! I'm happy to help you with the number 2. Is there something specific you would like to know or learn about the number 2? Please let me know and I will do my best to assist you in a safe and respectful manner.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>What number did I just tell you about?</td>\n",
       "      <td>I'm just an AI, I don't have access to any personal information or previous conversations, so I'm not able to recall the number you mentioned. Could you please provide more context or clarify which number you are referring to? I'm here to help and provide assistance in a responsible and respectful manner.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>This is the last message I'll ever sent you!</td>\n",
       "      <td>Thank you for your kind words! I'm here to help you with any questions or concerns you may have. However, I must inform you that I'm just an AI and not a real person, so I can't provide any personal or sensitive information. Additionally, I must follow ethical guidelines and ensure that my responses are safe, respectful, and free of any harmful or illegal content. Please feel free to ask me any questions or seek my assistance, and I will do my best to help.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Can you tell me who's the President of the US?</td>\n",
       "      <td>Of course! The President of the United States is Joe Biden. I'm glad to provide you with accurate and helpful information. It's important to stay informed and engaged in the political process, and I'm here to help you with any questions you may have. Is there anything else you'd like to know?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0                                       How are you?   \n",
       "1                         What can you help me with?   \n",
       "2  Are you remembering the question I just asked ...   \n",
       "3                           Ok remember the number 2   \n",
       "4             What number did I just tell you about?   \n",
       "5       This is the last message I'll ever sent you!   \n",
       "6     Can you tell me who's the President of the US?   \n",
       "\n",
       "                                            response  \n",
       "0  Hello! I'm just an AI, I don't have feelings o...  \n",
       "1  Hello! I'm here to assist you in any way I can...  \n",
       "2  Of course, I apologize for any confusion earli...  \n",
       "3  Of course! I'm happy to help you with the numb...  \n",
       "4  I'm just an AI, I don't have access to any per...  \n",
       "5  Thank you for your kind words! I'm here to hel...  \n",
       "6  Of course! The President of the United States ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start a conversation\n",
    "question = t.insert(input=\"Can you tell me who's the President of the US?\")\n",
    "answer = t.select(t.input, t.response).show()\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTtQcjKQAlis"
   },
   "source": [
    "### Learn More\n",
    "\n",
    "To learn more about advanced techniques like RAG operations in Pixeltable, visit: https://pixeltable.readme.io/docs/rag-operations-in-pixeltable\n",
    "\n",
    "If you have any questions, don't hesitate to reach out."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
