{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/pixeltable/pixeltable/blob/release/docs/release/tutorials/generate-social-media-post-from-video-with-gradio-ui.ipynb) [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pixeltable/pixeltable/blob/release/docs/release/tutorials/generate-social-media-post-from-video-with-gradio-ui.ipynb)\n",
        "\n",
        "# Video Analysis and Social Media Post Creation with Pixeltable and Gradio\n",
        "\n",
        "Also hosted on [Hugging Face](https://huggingface.co/spaces/Pixeltable/video-to-social-media-post-generator)."
      ],
      "metadata": {
        "id": "HqWtTPJad34S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we'll demonstrate key Pixeltable functionalities for managing and processing video data, integrating AI models, and creating an interactive interface. We'll show how Pixeltable can be used to:\n",
        "\n",
        "1. Create tables and views to store and organize video data;\n",
        "2. Extract frames and audio from videos through automated processing;\n",
        "3. Compute and store metadata, transcriptions, and AI-generated content;\n",
        "4. Utilize OpenAI's GPT and Whisper models for transcription and content generation;\n",
        "5. Define user-defined functions (UDFs) for specialized tasks like prompt construction;\n",
        "6. Store transformed data and AI outputs for easy retrieval and analysis;\n",
        "7. Create an interactive web interface using Gradio for easy user interaction with Pixeltable's functionalities.\n",
        "\n",
        "This example assumes you're already somewhat familiar with Pixeltable.\n",
        "If this is your first time using Pixeltable, the [Pixeltable Basics tutorial](https://docs.pixeltable.com/docs/pixeltable-basics) is a great place to start."
      ],
      "metadata": {
        "id": "ccK0B-bJd_Q5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8xJwcOQG-71",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%pip install -qU pixeltable gradio openai openai-whisper spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pixeltable as pxt\n",
        "import os\n",
        "import openai\n",
        "import gradio as gr\n",
        "import getpass\n",
        "from pixeltable.iterators import FrameIterator\n",
        "from pixeltable.functions.video import extract_audio\n",
        "from pixeltable.functions.audio import get_metadata\n",
        "from pixeltable.functions import openai"
      ],
      "metadata": {
        "id": "Fj69f55fNBSV"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Store OpenAI API Key"
      ],
      "metadata": {
        "id": "HNbN5bIkLHkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'OPENAI_API_KEY' not in os.environ:\n",
        "    os.environ['OPENAI_API_KEY'] = getpass.getpass('Enter your OpenAI API key:')"
      ],
      "metadata": {
        "id": "qlNa7jMJbT0a"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Table, a View, and Computed Columns"
      ],
      "metadata": {
        "id": "k80Ax-TXLLYp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJJnBg07G-73",
        "outputId": "658c6ebd-2557-46ba-fbac-445ab03c387d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created directory `directory`.\n",
            "Created table `video_table`.\n",
            "Created view `frames` with 0 rows, 0 exceptions.\n"
          ]
        }
      ],
      "source": [
        "pxt.drop_dir('directory', force=True)\n",
        "pxt.create_dir('directory')\n",
        "\n",
        "t = pxt.create_table(\n",
        "    'directory.video_table', {\n",
        "    \"video\": pxt.VideoType(nullable=True),\n",
        "    \"sm_type\": pxt.StringType(nullable=True),\n",
        "    }\n",
        ")\n",
        "\n",
        "frames_view = pxt.create_view(\n",
        "    \"directory.frames\",\n",
        "    t,\n",
        "    iterator=FrameIterator.create(video=t.video, fps=.25)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1sByexeG-74",
        "outputId": "13f7f7b6-f4e5-4260-95e3-f3c3bd8575e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 0 column values with 0 errors.\n",
            "Added 0 column values with 0 errors.\n",
            "Added 0 column values with 0 errors.\n",
            "Added 0 column values with 0 errors.\n"
          ]
        }
      ],
      "source": [
        "# Create computed columns to store transformations and persist outputs\n",
        "t['audio'] = extract_audio(t.video, format='mp3')\n",
        "t['metadata'] = get_metadata(t.audio)\n",
        "t['transcription'] = openai.transcriptions(audio=t.audio, model='whisper-1')\n",
        "t['transcription_text'] = t.transcription.text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom UDF for Generating Social Media Prompts"
      ],
      "metadata": {
        "id": "_BwIT2DsLohy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #Custom User-Defined Function (UDF) for Generating Social Media Prompts\n",
        "@pxt.udf\n",
        "def prompt(A: str, B: str) -> list[dict]:\n",
        "    system_msg = 'You are an expert in creating social media content and you generate effective post, based on user content. Respect the social media platform guidelines and constraints.'\n",
        "    user_msg = f'A: \"{A}\" \\n B: \"{B}\"'\n",
        "    return [\n",
        "        {'role': 'system', 'content': system_msg},\n",
        "        {'role': 'user', 'content': user_msg}\n",
        "    ]\n",
        "\n",
        "# Apply the UDF to create a new column\n",
        "t['message'] = prompt(t.sm_type, t.transcription_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxDsHFwRRhet",
        "outputId": "d300a398-4ccc-4c99-8ea3-fa77142213f3"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 0 column values with 0 errors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Responses with OpenAI's GPT Model"
      ],
      "metadata": {
        "id": "Dc13C-KqMJfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Generate responses using OpenAI's chat completion API\n",
        "t['response'] = openai.chat_completions(messages=t.message, model='gpt-4o-mini-2024-07-18', max_tokens=500)\n",
        "\n",
        "## Extract the content of the response\n",
        "t['answer'] = t.response.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oCtS09xbEyC",
        "outputId": "7e656e03-b9ad-4939-a5b0-16bbf11b651e"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 0 column values with 0 errors.\n",
            "Added 0 column values with 0 errors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_VIDEO_SIZE_MB = 35\n",
        "\n",
        "def process_and_generate_post(video_file, social_media_type):\n",
        "    if not video_file:\n",
        "        return \"Please upload a video file.\", None\n",
        "\n",
        "    try:\n",
        "        # Check video file size\n",
        "        video_size = os.path.getsize(video_file) / (1024 * 1024)  # Convert to MB\n",
        "        if video_size > MAX_VIDEO_SIZE_MB:\n",
        "            return f\"The video file is larger than {MAX_VIDEO_SIZE_MB} MB. Please upload a smaller file.\", None\n",
        "\n",
        "        # # Insert a video into the table. Pixeltable supports referencing external data sources like URLs\n",
        "        t.insert([{\n",
        "            \"video\": video_file,\n",
        "            \"sm_type\": social_media_type\n",
        "        }])\n",
        "\n",
        "        # Retrieve Social media posts\n",
        "        social_media_post = t.select(t.answer).tail(1)['answer'][0]\n",
        "\n",
        "        # Retrieve Audio\n",
        "        audio = t.select(t.audio).tail(1)['audio'][0]\n",
        "\n",
        "        # Retrieve thumbnails\n",
        "        thumbnails = frames_view.select(frames_view.frame).tail(4)['frame']\n",
        "\n",
        "        # Retrieve Pixeltable Table containing all videos and stored data\n",
        "        df_output = t.collect().to_pandas()\n",
        "\n",
        "        #Display content\n",
        "        return social_media_post, thumbnails, df_output, audio\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\", None\n",
        "\n",
        "# Gradio Interface\n",
        "import gradio as gr\n",
        "\n",
        "def gradio_interface():\n",
        "    with gr.Blocks(theme=gr.themes.Monochrome()) as demo:\n",
        "        gr.Markdown(\n",
        "            \"\"\"<p>\n",
        "            <img src=\"https://raw.githubusercontent.com/pixeltable/pixeltable/main/docs/source/data/pixeltable-logo-large.png\" alt=\"Pixeltable\" width=\"20%\" />\n",
        "            <h1>Video to Social Media Post Generator</h1>\n",
        "            <h3>Key functionalities demonstrated in this example:</h3>\n",
        "            </p>\n",
        "            <ul>\n",
        "  <li><strong>Video Data Management:</strong> Creating tables and views to store and organize video data.</li>\n",
        "  <li><strong>Automated Video Processing:</strong> Extracting frames and audio from videos.</li>\n",
        "  <li><strong>Data Transformation:</strong> Computing and storing metadata, transcriptions, and AI-generated content.</li>\n",
        "  <li><strong>AI Integration:</strong> Utilizing OpenAI's GPT and Whisper models for transcription and content generation.</li>\n",
        "  <li><strong>Custom Functions:</strong> Defining user-defined functions (UDFs) for specialized tasks like prompt construction.</li>\n",
        "  <li><strong>Data Persistence:</strong> Storing transformed data and AI outputs for easy retrieval and analysis.</li>\n",
        "  <li><strong>Gradio Integration:</strong> Creating an interactive web interface for easy user interaction with Pixeltable's functionalities.</li>\n",
        "  </ul>\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                video_input = gr.Video(\n",
        "                    label=f\"Upload Video File (max {MAX_VIDEO_SIZE_MB} MB):\",\n",
        "                    include_audio=True,\n",
        "                    max_length=300,\n",
        "                    height='400px',\n",
        "                    autoplay=False\n",
        "                )\n",
        "                social_media_type = gr.Dropdown(\n",
        "                    choices=[\"X (Twitter)\", \"Facebook\", \"LinkedIn\", \"Instagram\"],\n",
        "                    label=\"Select Social Media Platform:\",\n",
        "                    value=\"X (Twitter)\",\n",
        "                )\n",
        "                generate_btn = gr.Button(\"Generate Post\")\n",
        "\n",
        "                gr.Examples(\n",
        "            examples=[[\"example1.mp4\"], [\"example2.mp4\"], [\"example3.mp4\"]],\n",
        "            inputs=[video_input]\n",
        "        )\n",
        "            with gr.Column():\n",
        "                output = gr.Textbox(label=\"Generated Social Media Post\", show_copy_button=True)\n",
        "                thumbnail = gr.Gallery(\n",
        "                    label=\"Pick your favorite Post Thumbnail\",\n",
        "                    show_download_button=True,\n",
        "                    show_fullscreen_button=True,\n",
        "                    height='400px'\n",
        "                )\n",
        "                audio = gr.Audio()\n",
        "\n",
        "        df_output = gr.DataFrame(label=\"Pixeltable Table\")\n",
        "\n",
        "        generate_btn.click(\n",
        "            fn=process_and_generate_post,\n",
        "            inputs=[video_input, social_media_type],\n",
        "            outputs=[output, thumbnail, df_output, audio],\n",
        "        )\n",
        "\n",
        "        gr.HTML(\n",
        "            \"\"\"\n",
        "                <div class=\"footer\">\n",
        "                    <p>Pixeltable is a declarative interface for working with text, images, embeddings, and even video, enabling you to store, transform, index, and iterate on data. Powered solely by <a href=\"https://github.com/pixeltable/pixeltable\" style=\"text-decoration: underline;\" target=\"_blank\">Pixeltable</a> - running OpenAI (gpt-4o-mini-2024-07-18).</a></p>\n",
        "                <p><a href=\"https://colab.research.google.com/github/pixeltable/pixeltable/blob/release/docs/release/tutorials/pixeltable-basics.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Colab\"></a></p>\n",
        "                </div>\n",
        "           \"\"\"\n",
        "        )\n",
        "    return demo\n",
        "\n",
        "# Launch the Gradio interface\n",
        "if __name__ == \"__main__\":\n",
        "    gradio_interface().launch(show_api=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "igz5v44ee2lJ",
        "outputId": "9e89f4f2-be23-4a96-b967-dd2182eabe3e"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://01b04b6f6c9665579d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://01b04b6f6c9665579d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This example showcases how Pixeltable simplifies complex video processing workflows and integrates AI capabilities to create a powerful tool for generating social media content from video inputs."
      ],
      "metadata": {
        "id": "bsZbC8NJeF6y"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
