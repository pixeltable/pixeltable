---
title: 'What is Pixeltable?'
description: 'Pixeltable unifies storage and orchestration for multimodal AI applications, providing a declarative interface for incremental transforms, indexing, and orchestration.'
---

## Key Capabilities

<CardGroup cols={2}>
  <Card title="Persistent Storage" icon="database" iconType="duotone">
    All data and computed results are automatically stored and versioned.
  </Card>
  <Card title="Incremental Updates" icon="arrows-rotate" iconType="duotone">
    Data transformations run automatically on new data—no orchestration code needed.
  </Card>
  <Card title="Multimodal-Native" icon="photo-film" iconType="duotone">
    Images, video, audio, and documents integrate seamlessly with structured data.
  </Card>
  <Card title="AI Integration" icon="microchip-ai" iconType="duotone">
    Built-in support for OpenAI, Anthropic, Gemini, Hugging Face, and dozens more.
  </Card>
</CardGroup>

## Get started

<CardGroup cols={2}>
  <Card title="Quick Start" icon="bolt" iconType="duotone" href="/overview/quick-start">
    Install Pixeltable and run your first pipeline in 5 minutes.
  </Card>
  <Card title="10-Minute Tour" icon="play" iconType="duotone" href="/overview/ten-minute-tour">
    See Pixeltable in action with a hands-on image workflow.
  </Card>
  <Card title="Core Concepts" icon="cubes" iconType="duotone" href="/platform/type-system">
    Learn about tables, computed columns, views, and the type system.
  </Card>
  <Card title="SDK Reference" icon="code" iconType="duotone" href="/sdk/latest">
    Complete API reference for the Pixeltable Python SDK.
  </Card>
</CardGroup>

<Tip>
Many documentation pages are interactive notebooks (marked with <Icon icon="notebook" /> in the sidebar). Open them in Colab, Kaggle, or locally to follow along.
</Tip>

## Core Primitives

Pixeltable provides a small set of primitives that compose into any multimodal AI workflow:

<AccordionGroup>
  <Accordion title="Store" icon="database">
    **Create tables with native multimodal types**
    
    ```python
    t = pxt.create_table('myapp.media', {
        'video': pxt.Video,
        'image': pxt.Image,
        'audio': pxt.Audio,
        'document': pxt.Document,
        'metadata': pxt.Json
    })
    ```
    
    <CardGroup cols={2}>
      <Card title="Tables & Data" icon="table" href="/tutorials/tables-and-data-operations">
        Create, insert, update, delete
      </Card>
      <Card title="Type System" icon="shapes" href="/platform/type-system">
        All supported types
      </Card>
    </CardGroup>
  </Accordion>
  
  <Accordion title="Transform" icon="wand-magic-sparkles">
    **Define computed columns that run automatically on all data**
    
    ```python
    t.add_computed_column(transcript=openai.transcriptions(t.audio))
    t.add_computed_column(summary=openai.chat_completions(
        messages=[{'role': 'user', 'content': 'Summarize: ' + t.transcript}]
    ))
    ```
    
    <CardGroup cols={2}>
      <Card title="Computed Columns" icon="bolt" href="/tutorials/computed-columns">
        Incremental transforms
      </Card>
      <Card title="AI Integrations" icon="microchip-ai" href="/integrations/frameworks">
        OpenAI, Anthropic, Gemini...
      </Card>
    </CardGroup>
  </Accordion>
  
  <Accordion title="Split" icon="scissors">
    **Create views with iterators to expand rows**
    
    ```python
    # Extract frames from video at 1 fps
    frames = pxt.create_view('myapp.frames', t, iterator=FrameIterator(t.video, fps=1))
    
    # Chunk documents for RAG
    chunks = pxt.create_view('myapp.chunks', t, iterator=DocumentSplitter(t.document))
    ```
    
    <CardGroup cols={2}>
      <Card title="Views" icon="layer-group" href="/platform/views">
        Virtual tables
      </Card>
      <Card title="Iterators" icon="arrows-split-up-and-left" href="/platform/iterators">
        Frame, Document, Audio splitters
      </Card>
    </CardGroup>
  </Accordion>
  
  <Accordion title="Index" icon="magnifying-glass">
    **Add embedding indexes for semantic search**
    
    ```python
    t.add_embedding_index('text', embedding=openai.embeddings())
    
    # Search by similarity
    results = t.order_by(t.text.similarity('find relevant docs'), asc=False).limit(10)
    ```
    
    <Card title="Embedding Indexes" icon="vector-square" href="/platform/embedding-indexes">
      Vector search with automatic maintenance
    </Card>
  </Accordion>
  
  <Accordion title="Extend" icon="puzzle-piece">
    **Write custom functions with `@pxt.udf` and `@pxt.query`**
    
    ```python
    @pxt.udf
    def extract_entities(text: str) -> list[str]:
        # Your custom logic
        return entities
    
    @pxt.query
    def search_by_topic(topic: str):
        return t.where(t.category == topic).select(t.title, t.summary)
    ```
    
    <Card title="UDFs & Queries" icon="code" href="/platform/udfs-in-pixeltable">
      Custom Python functions
    </Card>
  </Accordion>
  
  <Accordion title="Query" icon="filter">
    **SQL-like queries with Python syntax**
    
    ```python
    results = (t
        .where(t.timestamp > '2024-01-01')
        .order_by(t.score, asc=False)
        .select(t.title, t.summary, t.score)
        .limit(100)
        .collect())
    ```
    
    <Card title="Queries & Expressions" icon="terminal" href="/tutorials/queries-and-expressions">
      Select, filter, aggregate
    </Card>
  </Accordion>
  
  <Accordion title="Version" icon="clock-rotate-left">
    **Time travel and automatic versioning**
    
    ```python
    t.history()                    # View all versions
    t.revert(version=5)            # Rollback changes
    old_data = pxt.get_table('myapp.media:3')  # Query past version
    ```
    
    <Card title="Version Control" icon="code-branch" href="/platform/version-control">
      History, snapshots, lineage
    </Card>
  </Accordion>
  
  <Accordion title="Share" icon="cloud-arrow-up">
    **Publish and replicate datasets via Pixeltable Cloud**
    
    ```python
    pxt.publish(t, 'my-dataset')              # Share publicly
    pxt.replicate('user/dataset', 'local')   # Pull to local
    ```
    
    <Card title="Data Sharing" icon="share-nodes" href="/platform/data-sharing">
      Publish, replicate, collaborate
    </Card>
  </Accordion>
</AccordionGroup>

<Note>
These primitives are **use-case agnostic by design**. We don't build vertical solutions—we build the infrastructure that makes vertical solutions trivial to build.
</Note>

## What can you build?

<CardGroup cols={2}>
  <Card title="Declarative Pipelines" icon="code" iconType="duotone">
    Replace complex orchestration with simple computed columns. Define transformations once—they run automatically on all data.
  </Card>
  <Card title="Multimodal Workloads" icon="photo-film" iconType="duotone">
    Production RAG with automatic embedding indexing. Find relevant scenes in video. Semantic search across text, images, and audio.
  </Card>
  <Card title="Version Control and Lineage" icon="code-branch" iconType="duotone">
    Automatic versioning on every change. Time travel queries to any point. Full data lineage for reproducibility.
  </Card>
  <Card title="AI Agents & MCP" icon="robot" iconType="duotone">
    Build tool-calling agents with persistent memory, MCP server integration, and automatic conversation history.
  </Card>
  <Card title="ML Feature Engineering" icon="download" iconType="duotone">
    Curate, augment, and export data to PyTorch, Parquet, COCO format, LanceDB, and pandas for training and analytics.
  </Card>
</CardGroup>

### Explore by use case

<Tabs>
  <Tab title="AI & LLMs">
    - [RAG Pipeline](/howto/cookbooks/agents/pattern-rag-pipeline) — Document retrieval & generation
    - [Vision Analysis](/howto/cookbooks/images/vision-batch-analysis) — GPT-4 Vision on images
    - [Audio Transcription](/howto/cookbooks/audio/audio-transcribe) — Speech-to-text with Whisper
    - [Document Chunking](/howto/cookbooks/text/doc-chunk-for-rag) — Split docs for RAG
  </Tab>
  <Tab title="Media Processing">
    - [Video Analysis](/howto/use-cases/object-detection-in-videos) — Object detection in video
    - [Semantic Search](/howto/cookbooks/search/search-similar-images) — Find similar images/text
    - [Image Processing](/howto/cookbooks/images/img-detect-objects) — Object detection
  </Tab>
  <Tab title="Data Management">
    - [Data Import](/howto/cookbooks/data/data-import-csv) — CSV, JSON, Parquet, S3
    - [PyTorch Export](/howto/cookbooks/data/data-export-pytorch) — DataLoader integration
    - [Version Control](/platform/version-control) — Time travel & lineage
  </Tab>
</Tabs>

## Next steps

<CardGroup cols={2}>
  <Card
    title="Join the Community"
    icon="discord"
    iconType="duotone"
    href="https://discord.com/invite/QPyqFYx2UN"
  >
    Get help, share projects, and connect with other developers
  </Card>
  <Card
    title="GitHub"
    icon="github"
    iconType="duotone"
    href="https://github.com/pixeltable/pixeltable"
  >
    Star the repo, report issues, and contribute
  </Card>
</CardGroup>
