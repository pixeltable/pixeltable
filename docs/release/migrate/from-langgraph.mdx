---
title: 'Coming from LangGraph / CrewAI'
description: 'How AI agent concepts map from LangGraph and CrewAI to Pixeltable'
---

If you've been building AI agents with LangGraph, CrewAI, or a similar agent framework, this guide shows how those concepts translate to Pixeltable's declarative approach where your agent *is* a table.

---

## Concept Mapping

| LangGraph / CrewAI | Pixeltable | Notes |
|---|---|---|
| `StateGraph` / `AgentExecutor` | `pxt.create_table()` with computed columns | Each computed column is a step in the pipeline |
| Graph nodes (functions) | Computed columns | Dependencies resolved automatically from column references |
| Graph edges / conditional routing | Column dependencies | Pixeltable infers the DAG; no explicit wiring needed |
| `ToolNode` / `@tool` | `pxt.tools()` + `invoke_tools()` | Register UDFs and queries as callable tools |
| `bind_tools()` on LLM | Pass `tools=` to `chat_completions()` | Same concept, different syntax |
| `should_continue()` routing | Computed column logic | Use `@pxt.udf` for conditional branching |
| `MemorySaver` / checkpointer | Tables are persistent by default | Every row, every column, automatically stored |
| Separate vector DB for RAG context | `add_embedding_index()` + `@pxt.query` | Built-in semantic search, no external service |
| `asyncio.gather` for parallelism | Independent computed columns | Pixeltable parallelizes automatically |
| LangSmith for observability | `t.select()` on any column | Every intermediate result is queryable |
| State resets between runs (CrewAI) | Persistent — data survives restarts | Tables are durable storage |

---

## Side by Side: Build a Tool-Calling Agent

### The LangGraph Approach

A tool-calling agent with memory requires defining a state graph, tool nodes, conditional edges, and a separate memory backend:

```python
# Requirements: langgraph, langchain-openai, langchain-core, tavily-python

from typing import Annotated, Sequence, TypedDict
from langchain_core.messages import BaseMessage, HumanMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END, add_messages
from langgraph.prebuilt import ToolNode
from langchain_core.tools import tool

# 1. Define state
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]

# 2. Define tools
@tool
def get_weather(city: str) -> str:
    """Get current weather for a city."""
    return f'Weather in {city}: 72°F, sunny'

@tool
def search_docs(query: str) -> str:
    """Search internal documents."""
    # Would need a separate vector DB setup here...
    return f'Results for: {query}'

tools = [get_weather, search_docs]
tool_node = ToolNode(tools)

# 3. Set up LLM with tools
model = ChatOpenAI(model='gpt-4o-mini').bind_tools(tools)

# 4. Define graph nodes
def call_model(state):
    response = model.invoke(state['messages'])
    return {'messages': [response]}

def should_continue(state):
    last = state['messages'][-1]
    return 'tools' if last.tool_calls else END

# 5. Build the graph
workflow = StateGraph(AgentState)
workflow.add_node('agent', call_model)
workflow.add_node('tools', tool_node)
workflow.set_entry_point('agent')
workflow.add_conditional_edges('agent', should_continue, {'tools': 'tools', END: END})
workflow.add_edge('tools', 'agent')
graph = workflow.compile()

# 6. Run
result = graph.invoke({'messages': [HumanMessage(content='What is the weather in SF?')]})
print(result['messages'][-1].content)

# ⚠️ State is ephemeral — lost when the process ends
# ⚠️ Adding RAG requires a separate vector DB integration
# ⚠️ No automatic caching of tool results
# ⚠️ Observability requires LangSmith (separate service)
```

**Packages involved:** `langgraph`, `langchain-openai`, `langchain-core`, plus a vector DB client for RAG

### The Same Thing in Pixeltable

```python
# Requirements: pixeltable, openai

import pixeltable as pxt
from pixeltable.functions.openai import chat_completions, invoke_tools

# 1. Define tools as UDFs
@pxt.udf
def get_weather(city: str) -> str:
    """Get current weather for a city."""
    return f'Weather in {city}: 72°F, sunny'

@pxt.udf
def search_docs(query: str) -> str:
    """Search internal documents."""
    return f'Results for: {query}'

tools = pxt.tools(get_weather, search_docs)

# 2. Create agent table — each row is a conversation turn
agent = pxt.create_table('agents.assistant', {'message': pxt.String})

# 3. Add computed columns — each is a step in the pipeline
# Step 1: LLM decides which tool to call
agent.add_computed_column(response=chat_completions(
    messages=[{'role': 'user', 'content': agent.message}],
    model='gpt-4o-mini',
    tools=tools,
    tool_choice=tools.choice(required=True),
))

# Step 2: Execute the selected tool
agent.add_computed_column(tool_output=invoke_tools(tools, agent.response))

# Step 3: Generate final answer with tool results
@pxt.udf
def build_followup(message: str, tool_output: str) -> list[dict]:
    return [
        {'role': 'user', 'content': message},
        {'role': 'assistant', 'content': tool_output},
        {'role': 'user', 'content': 'Now answer my original question using that information.'},
    ]

agent.add_computed_column(followup=build_followup(agent.message, agent.tool_output))
agent.add_computed_column(final=chat_completions(
    messages=agent.followup, model='gpt-4o-mini'))
agent.add_computed_column(answer=agent.final.choices[0].message.content)

# 4. Run — insert a row and the full pipeline executes
agent.insert([{'message': 'What is the weather in SF?'}])
agent.select(agent.message, agent.answer).collect()

# ✅ Every result is persistent — survives restarts
# ✅ Tool results are cached — same input never re-runs
# ✅ Every intermediate step is queryable: agent.select(agent.tool_output)
# ✅ No graph DSL to learn
```

**Packages involved:** `pixeltable`, `openai`

---

## What You Gain

- **No graph DSL.** Instead of defining nodes, edges, and conditional routing, you add computed columns. Pixeltable infers the dependency graph.
- **Persistent by default.** Every conversation turn, tool call, and intermediate result is stored in a table. No checkpointer configuration, no state that disappears between runs.
- **Built-in caching.** If the same tool is called with the same arguments, the cached result is returned. No manual memoization.
- **Observability for free.** Every column is queryable. Want to see what tool was selected? `agent.select(agent.response).collect()`. No separate tracing service needed.
- **RAG without extra infrastructure.** Add an `add_embedding_index()` and a `@pxt.query` retrieval function — no separate vector database.
- **Automatic parallelism.** Independent computed columns run in parallel without `asyncio.gather`.
- **MCP integration built-in.** Load tools from any MCP server with `pxt.mcp_udfs()` and combine them with local UDFs and query functions in a single `pxt.tools()` registry. No separate MCP adapter needed.
- **Test before you commit.** Preview any step on a sample before materializing it: `agent.select(agent.message, test=my_tool(agent.message)).head(3)`. Nothing is stored until you call `add_computed_column()`.
- **Swap providers freely.** The same agent pipeline works with OpenAI, Anthropic, Gemini, and [20+ other providers](/integrations/frameworks). Change `openai.chat_completions` to `anthropic.messages` — the tool calling and memory patterns stay the same.

---

## Common Patterns

### Adding persistent memory

<Tabs>
  <Tab title="LangGraph">
    ```python
    # Requires a separate memory backend
    from langgraph.checkpoint.memory import MemorySaver

    checkpointer = MemorySaver()
    graph = workflow.compile(checkpointer=checkpointer)
    # State persists during the process, but is lost on restart
    # For durable memory, need Redis/Postgres integration
    ```
  </Tab>
  <Tab title="Pixeltable">
    ```python
    # Tables are durable storage — memory is just another table
    memories = pxt.create_table('agents.memories', {
        'content': pxt.String,
        'timestamp': pxt.Timestamp,
    })
    memories.add_embedding_index('content',
        string_embed=embeddings.using(model='text-embedding-3-small'))

    @pxt.query
    def recall(query: str, top_k: int = 5):
        sim = memories.content.similarity(string=query)
        return memories.order_by(sim, asc=False).limit(top_k).select(memories.content)
    ```
  </Tab>
</Tabs>

### Adding RAG context retrieval

<Tabs>
  <Tab title="LangGraph">
    ```python
    # Requires separate vector DB setup
    from langchain_pinecone import PineconeVectorStore

    vector_store = PineconeVectorStore(index_name='docs', embedding=embeddings)
    retriever = vector_store.as_retriever()

    @tool
    def search_knowledge_base(query: str) -> str:
        """Search the knowledge base."""
        docs = retriever.get_relevant_documents(query)
        return '\n'.join(d.page_content for d in docs)

    # Must add this tool to the graph, re-compile...
    ```
  </Tab>
  <Tab title="Pixeltable">
    ```python
    # RAG is a query function — same system, no extra infrastructure
    @pxt.query
    def search_knowledge_base(query: str):
        """Search the knowledge base."""
        sim = chunks.text.similarity(string=query)
        return chunks.order_by(sim, asc=False).limit(5).select(chunks.text)

    # Register alongside other tools
    tools = pxt.tools(get_weather, search_knowledge_base)
    ```
  </Tab>
</Tabs>

### Inspecting agent behavior

<Tabs>
  <Tab title="LangGraph">
    ```python
    # Requires LangSmith integration
    # Set LANGSMITH_API_KEY, LANGSMITH_PROJECT, etc.
    # Then view traces in the LangSmith dashboard
    ```
  </Tab>
  <Tab title="Pixeltable">
    ```python
    # Every column is a first-class queryable field
    agent.select(
        agent.message,
        agent.response,      # raw LLM response with tool selection
        agent.tool_output,   # what the tool returned
        agent.answer          # final answer
    ).collect()
    ```
  </Tab>
</Tabs>

---

## Next Steps

<CardGroup cols={2}>
  <Card title="Agentic Patterns" icon="diagram-project" href="/howto/cookbooks/agents/agentic-patterns">
    All 8 agentic patterns implemented as Pixeltable tables
  </Card>
  <Card title="Agent Memory" icon="brain" href="/howto/cookbooks/agents/pattern-agent-memory">
    Persistent memory with semantic search
  </Card>
  <Card title="Tool Calling" icon="wrench" href="/howto/cookbooks/agents/llm-tool-calling">
    Register UDFs and queries as LLM tools
  </Card>
  <Card title="RAG Pipeline" icon="database" href="/howto/cookbooks/agents/pattern-rag-pipeline">
    Retrieval-augmented generation
  </Card>
  <Card title="Pixelagent" icon="microchip" href="https://github.com/pixeltable/pixelagent">
    Lightweight agent framework with built-in memory and tool orchestration
  </Card>
  <Card title="Pixelbot" icon="robot" href="https://github.com/pixeltable/pixelbot">
    Full multimodal AI agent with infinite memory — built on Pixeltable
  </Card>
</CardGroup>
