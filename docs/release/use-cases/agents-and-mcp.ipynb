{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Agents and MCP\"\n",
        "icon: \"notebook\"\n",
        "description: \"[Open in Kaggle](https://kaggle.com/kernels/welcome?src=https://github.com/pixeltable/pixeltable/blob/release/docs/notebooks/use-cases/agents-and-mcp.ipynb) | [Open in Colab](https://colab.research.google.com/github/pixeltable/pixeltable/blob/release/docs/notebooks/use-cases/agents-and-mcp.ipynb) | [View on GitHub](https://github.com/pixeltable/pixeltable/blob/release/docs/notebooks/use-cases/agents-and-mcp.ipynb)\"\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Build AI agents with tool calling, persistent memory, and MCP server integration — all defined declaratively as tables with computed columns.\n",
        "\n",
        "This notebook walks through the full lifecycle described in the [Agents & MCP](https://docs.pixeltable.com/use-cases/agents-mcp) use case:\n",
        "\n",
        "| Phase | What you'll build |\n",
        "|-------|-------------------|\n",
        "| **1. Tools** | UDF tools, query tools, tool registration |\n",
        "| **2. Workflow** | Agent table, tool selection, execution, context assembly, final response |\n",
        "| **3. MCP** | Connect to MCP servers, use external tools |\n",
        "| **4. Memory** | Chat history, memory bank, semantic recall |\n",
        "| **5. Deploy** | Flask/FastAPI integration with chat history |\n",
        "\n",
        "**Key idea:** Instead of imperative control flow, define your agent as a table. Each row is a user query; computed columns define the reasoning chain. Pixeltable handles orchestration, caching, and persistence.\n",
        "\n",
        "**Requirements:** `OPENAI_API_KEY` environment variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pip install -qU pixeltable openai sentence-transformers mcp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "vllm 0.14.1 requires torch==2.9.1; platform_system == \"Darwin\" or platform_machine == \"ppc64le\" or platform_machine == \"aarch64\", but you have torch 2.10.0 which is incompatible.\n",
            "fiftyone 1.13.0 requires sse-starlette<1,>=0.10.3, but you have sse-starlette 3.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if 'OPENAI_API_KEY' not in os.environ:\n",
        "    os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key: ')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import datetime\n",
        "\n",
        "import pixeltable as pxt\n",
        "from pixeltable.functions import openai\n",
        "from pixeltable.functions.huggingface import sentence_transformer\n",
        "\n",
        "pxt.drop_dir('agents', force=True)\n",
        "pxt.create_dir('agents')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/pierre/pixeltable/pixeltable/env.py:494: UserWarning: Progress reporting is disabled because ipywidgets is not installed. To fix this, run: `pip install ipywidgets`\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Connected to Pixeltable database at: postgresql+psycopg://postgres:@/pixeltable?host=/Users/pjlb/.pixeltable/pgdata\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "W0219 13:20:28.727000 87265 site-packages/torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "/Users/pierre/pixeltable/pixeltable/catalog/table_version.py:670: PixeltableWarning: The computed column 'document_text' in table 'collection' is no longer valid.\n",
            "The UDF 'functions.extract_document_text' cannot be located, because\n",
            "the symbol 'functions.extract_document_text' is no longer a UDF. (Was the `@pxt.udf` decorator removed?)\n",
            "You can continue to query existing data from this column, but evaluating it on new data will raise an error.\n",
            "  col.init_value_expr(tvp)\n",
            "/Users/pierre/pixeltable/pixeltable/catalog/table_version.py:670: PixeltableWarning: The computed column 'tool_output' in table 'tools' is no longer valid.\n",
            "The UDF 'functions.get_latest_news' cannot be located, because\n",
            "the symbol 'functions.get_latest_news' is no longer a UDF. (Was the `@pxt.udf` decorator removed?)\n",
            "You can continue to query existing data from this column, but evaluating it on new data will raise an error.\n",
            "  col.init_value_expr(tvp)\n",
            "/Users/pierre/pixeltable/pixeltable/catalog/table_version.py:670: PixeltableWarning: The computed column 'multimodal_context_summary' in table 'tools' is no longer valid.\n",
            "The UDF 'functions.assemble_multimodal_context' cannot be located, because\n",
            "the symbol 'functions.assemble_multimodal_context' is no longer a UDF. (Was the `@pxt.udf` decorator removed?)\n",
            "You can continue to query existing data from this column, but evaluating it on new data will raise an error.\n",
            "  col.init_value_expr(tvp)\n",
            "/Users/pierre/pixeltable/pixeltable/catalog/table_version.py:670: PixeltableWarning: The computed column 'final_prompt_messages' in table 'tools' is no longer valid.\n",
            "The UDF 'functions.assemble_final_messages' cannot be located, because\n",
            "the symbol 'functions.assemble_final_messages' is no longer a UDF. (Was the `@pxt.udf` decorator removed?)\n",
            "You can continue to query existing data from this column, but evaluating it on new data will raise an error.\n",
            "  col.init_value_expr(tvp)\n",
            "/Users/pierre/pixeltable/pixeltable/catalog/table_version.py:670: PixeltableWarning: The computed column 'follow_up_input_message' in table 'tools' is no longer valid.\n",
            "The UDF 'functions.assemble_follow_up_prompt' cannot be located, because\n",
            "the symbol 'functions.assemble_follow_up_prompt' is no longer a UDF. (Was the `@pxt.udf` decorator removed?)\n",
            "You can continue to query existing data from this column, but evaluating it on new data will raise an error.\n",
            "  col.init_value_expr(tvp)\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Created directory 'agents'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pixeltable.catalog.dir.Dir at 0x3ba5b5d50>"
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build a Knowledge Base (for Agentic RAG)\n",
        "\n",
        "Before building the agent, we need a knowledge base it can search. This mirrors the document pipeline from the [Backend for AI Apps](https://docs.pixeltable.com/use-cases/ai-applications) use case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pixeltable.functions.document import document_splitter\n",
        "\n",
        "docs = pxt.create_table('agents.docs', {'document': pxt.Document, 'title': pxt.String})\n",
        "\n",
        "base_url = 'https://raw.githubusercontent.com/pixeltable/pixeltable/main/docs/resources/rag-demo'\n",
        "docs.insert([\n",
        "    {'document': f'{base_url}/Argus-Market-Digest-June-2024.pdf', 'title': 'Argus Market Digest'},\n",
        "    {'document': f'{base_url}/Company-Research-Alphabet.pdf', 'title': 'Alphabet Research'},\n",
        "    {'document': f'{base_url}/Zacks-Nvidia-Report.pdf', 'title': 'Nvidia Report'},\n",
        "])\n",
        "\n",
        "chunks = pxt.create_view(\n",
        "    'agents.chunks', docs,\n",
        "    iterator=document_splitter(\n",
        "        docs.document, separators='sentence,token_limit',\n",
        "        limit=128, overlap=0, metadata='title,heading',\n",
        "    ),\n",
        ")\n",
        "\n",
        "chunks.add_embedding_index(\n",
        "    'text',\n",
        "    string_embed=sentence_transformer.using(model_id='all-MiniLM-L6-v2'),\n",
        ")\n",
        "\n",
        "print(f'Knowledge base ready: {docs.count()} docs, {chunks.count()} chunks')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created table 'docs'.\n",
            "Inserted 3 rows with 0 errors in 0.01 s (265.85 rows/s)\n",
            "Knowledge base ready: 3 docs, 527 chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 1 — Define Tools\n",
        "\n",
        "Agents need tools. In Pixeltable, any `@pxt.udf` (external API calls, computations) or `@pxt.query` (database searches) can be registered as a tool the LLM can call."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tool UDFs: External API Calls\n",
        "\n",
        "Wrap any Python code as a `@pxt.udf` tool. The LLM sees the function name, docstring, and parameter types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "@pxt.udf\n",
        "def stock_lookup(ticker: str) -> str:\n",
        "    \"\"\"Look up the current stock price, daily change, and key metrics for a given ticker symbol.\"\"\"\n",
        "    data = {\n",
        "        'GOOGL': 'Alphabet (GOOGL): $178.02 (+1.2%), P/E: 27.3, Market Cap: $2.2T',\n",
        "        'NVDA': 'NVIDIA (NVDA): $135.58 (+3.1%), P/E: 65.2, Market Cap: $3.3T',\n",
        "        'AAPL': 'Apple (AAPL): $213.25 (-0.4%), P/E: 33.1, Market Cap: $3.3T',\n",
        "        'MSFT': 'Microsoft (MSFT): $448.30 (+0.8%), P/E: 37.5, Market Cap: $3.3T',\n",
        "        'AMZN': 'Amazon (AMZN): $185.30 (+1.5%), P/E: 62.8, Market Cap: $1.9T',\n",
        "    }\n",
        "    return data.get(ticker.upper(), f'No data available for {ticker}')\n",
        "\n",
        "\n",
        "@pxt.udf\n",
        "def market_summary() -> str:\n",
        "    \"\"\"Get today's market summary including major index performance.\"\"\"\n",
        "    return (\n",
        "        'Market Summary (June 21, 2024): '\n",
        "        'DJIA 39,134.76 (+0.77%), S&P 500 5,482.87 (+0.25%), '\n",
        "        'Nasdaq 17,721.59 (-0.18%). '\n",
        "        'Tech rotation continued as Nvidia pulled back from highs. '\n",
        "        'Broad-market breadth improved with financials and healthcare leading.'\n",
        "    )"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Query Tools: Agentic RAG\n",
        "\n",
        "`@pxt.query` functions turn semantic search into callable tools. The agent can decide *when* to search, *what* to search for, and use the results in its reasoning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "@pxt.query\n",
        "def search_documents(query_text: str):\n",
        "    \"\"\"Search financial research documents by semantic similarity. Use this to find analysis, forecasts, and detailed company information.\"\"\"\n",
        "    sim = chunks.text.similarity(query_text)\n",
        "    return (\n",
        "        chunks\n",
        "        .order_by(sim, asc=False)\n",
        "        .select(text=chunks.text, source=chunks.title, score=sim)\n",
        "        .limit(5)\n",
        "    )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/var/folders/s4/0zdx499s6sv3_0jll6ccdbh00000gn/T/ipykernel_87265/1116462431.py:4: DeprecationWarning: Use of similarity() without specifying an explicit modality is deprecated -- since version 0.5.7. Please use one of the following instead:\n",
            "  .similarity(string=...)\n",
            "  .similarity(image=...)\n",
            "  .similarity(audio=...)\n",
            "  .similarity(video=...)\n",
            "  sim = chunks.text.similarity(query_text)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Verify the underlying search works\n",
        "sim = chunks.text.similarity('Nvidia earnings and revenue')\n",
        "chunks.order_by(sim, asc=False).select(chunks.text, source=chunks.title, sim=sim).limit(3).collect()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Error",
          "evalue": "() for an absolute path is invalid",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Verify the query tool works\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msearch_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNvidia earnings and revenue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Users/pierre/pixeltable/pixeltable/exprs/json_path.py:109\u001b[0m, in \u001b[0;36mJsonPath.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03mConstruct a relative path that references an ancestor of the immediately enclosing JsonMapper.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_relative_path():\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m excs\u001b[38;5;241m.\u001b[39mError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m() for an absolute path is invalid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m excs\u001b[38;5;241m.\u001b[39mError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR() requires a negative index\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mError\u001b[0m: () for an absolute path is invalid"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Register Tools\n",
        "\n",
        "`pxt.tools()` bundles UDFs and queries into a single registry that gets passed to the LLM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tools = pxt.tools(\n",
        "    stock_lookup,\n",
        "    market_summary,\n",
        "    search_documents,\n",
        ")\n",
        "\n",
        "print('Registered tools:', [t.name for t in tools])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 2 — Agent Workflow\n",
        "\n",
        "The agent is a table. Each row is a user prompt. Computed columns define a reasoning chain:\n",
        "\n",
        "```\n",
        "prompt → [LLM selects tool] → [execute tool] → [LLM generates answer]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Agent Table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "agent = pxt.create_table('agents.workflow', {\n",
        "    'prompt': pxt.String,\n",
        "    'system_prompt': pxt.String,\n",
        "})\n",
        "\n",
        "SYSTEM_PROMPT = (\n",
        "    'You are a financial research assistant. You have access to tools for '\n",
        "    'looking up stock prices, getting market summaries, and searching '\n",
        "    'through financial research documents. Always use the most appropriate '\n",
        "    'tool before answering. Use search_documents for analysis and forecasts, '\n",
        "    'stock_lookup for current prices, and market_summary for broad market data.'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Tool Selection\n",
        "\n",
        "The first LLM call sees the available tools and decides which one to call, with what arguments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "agent.add_computed_column(\n",
        "    tool_response=openai.chat_completions(\n",
        "        messages=[\n",
        "            {'role': 'system', 'content': agent.system_prompt},\n",
        "            {'role': 'user', 'content': agent.prompt},\n",
        "        ],\n",
        "        model='gpt-4o-mini',\n",
        "        tools=tools,\n",
        "        tool_choice=tools.choice(required=True),\n",
        "    )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Tool Execution\n",
        "\n",
        "`invoke_tools()` automatically executes whichever tool the LLM selected and returns the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "agent.add_computed_column(\n",
        "    tool_output=openai.invoke_tools(tools, agent.tool_response)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Final Response\n",
        "\n",
        "A second LLM call takes the tool output and generates a polished, grounded answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "@pxt.udf\n",
        "def assemble_context(prompt: str, tool_output: dict, system_prompt: str) -> list[dict]:\n",
        "    \"\"\"Combine the user prompt, tool output, and system prompt into final LLM messages.\"\"\"\n",
        "    tool_results = []\n",
        "    for name, result in tool_output.items():\n",
        "        if result is not None:\n",
        "            tool_results.append(f'[{name}]: {result}')\n",
        "    tool_str = '\\n'.join(tool_results)\n",
        "\n",
        "    return [\n",
        "        {\n",
        "            'role': 'system',\n",
        "            'content': f'{system_prompt}\\n\\nYou have already called tools and received results. Use them to answer concisely.',\n",
        "        },\n",
        "        {\n",
        "            'role': 'user',\n",
        "            'content': f'Tool results:\\n{tool_str}\\n\\nOriginal question: {prompt}',\n",
        "        },\n",
        "    ]\n",
        "\n",
        "agent.add_computed_column(\n",
        "    final_messages=assemble_context(agent.prompt, agent.tool_output, agent.system_prompt)\n",
        ")\n",
        "\n",
        "agent.add_computed_column(\n",
        "    answer=openai.chat_completions(\n",
        "        messages=agent.final_messages,\n",
        "        model='gpt-4o-mini',\n",
        "    ).choices[0].message.content\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run the Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "agent.insert([\n",
        "    {'prompt': 'What are analysts saying about Nvidia?', 'system_prompt': SYSTEM_PROMPT},\n",
        "    {'prompt': 'Get me the stock price for GOOGL', 'system_prompt': SYSTEM_PROMPT},\n",
        "    {'prompt': 'How did the market do today?', 'system_prompt': SYSTEM_PROMPT},\n",
        "])\n",
        "\n",
        "agent.select(agent.prompt, agent.answer).collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inspect Tool Usage\n",
        "\n",
        "See exactly which tool the LLM called and what it returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "agent.select(agent.prompt, agent.tool_output).collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 3 — MCP Integration\n",
        "\n",
        "The [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) is an open standard for connecting LLMs to external tools. Pixeltable can load tools from any MCP server and use them alongside local UDFs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Connect to an MCP Server\n",
        "\n",
        "`pxt.mcp_udfs()` connects to any MCP-compliant server and returns the tools as callable UDFs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Connect to the Pixeltable documentation MCP server\n",
        "mcp_tools = pxt.mcp_udfs('https://docs.pixeltable.com/mcp')\n",
        "\n",
        "for tool in mcp_tools:\n",
        "    print(f'  {tool.name}: {tool.comment()[:80]}...')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Bundle MCP tools for LLM use, alongside local tools\n",
        "mcp_toolset = pxt.tools(*mcp_tools)\n",
        "\n",
        "# Create a table with MCP tool-calling pipeline\n",
        "mcp_agent = pxt.create_table('agents.mcp_agent', {'query': pxt.String})\n",
        "\n",
        "mcp_agent.add_computed_column(\n",
        "    response=openai.chat_completions(\n",
        "        messages=[{'role': 'user', 'content': mcp_agent.query}],\n",
        "        model='gpt-4o-mini',\n",
        "        tools=mcp_toolset,\n",
        "    )\n",
        ")\n",
        "\n",
        "mcp_agent.add_computed_column(\n",
        "    tool_results=openai.invoke_tools(mcp_toolset, mcp_agent.response)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mcp_agent.insert([\n",
        "    {'query': 'How do I create an embedding index in Pixeltable?'},\n",
        "    {'query': 'What LLM providers does Pixeltable support?'},\n",
        "])\n",
        "\n",
        "mcp_agent.select(mcp_agent.query, mcp_agent.tool_results).collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Combine Local + MCP Tools\n",
        "\n",
        "Mix tools from any source — local UDFs, query functions, and MCP servers — in a single agent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "combined_tools = pxt.tools(\n",
        "    stock_lookup,\n",
        "    search_documents,\n",
        "    *mcp_tools,\n",
        ")\n",
        "\n",
        "print('Combined tools:', [t.name for t in combined_tools])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build Your Own MCP Server\n",
        "\n",
        "Expose Pixeltable tables as MCP tools for Claude Desktop, Cursor, or any MCP client.\n",
        "\n",
        "```python\n",
        "# Save as mcp_server.py and run: python mcp_server.py\n",
        "from mcp.server.fastmcp import FastMCP\n",
        "import pixeltable as pxt\n",
        "\n",
        "mcp = FastMCP('FinancialResearch', stateless_http=True)\n",
        "\n",
        "@mcp.tool()\n",
        "def search_financial_docs(query: str) -> str:\n",
        "    \"\"\"Search financial research documents.\"\"\"\n",
        "    chunks = pxt.get_table('agents.chunks')\n",
        "    sim = chunks.text.similarity(query)\n",
        "    results = chunks.order_by(sim, asc=False).limit(5).collect()\n",
        "    return '\\n---\\n'.join(r['text'] for r in results)\n",
        "\n",
        "@mcp.tool()\n",
        "def get_stock_price(ticker: str) -> str:\n",
        "    \"\"\"Get a stock price.\"\"\"\n",
        "    # Your implementation here\n",
        "    pass\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    mcp.run(transport='streamable-http')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 4 — Memory\n",
        "\n",
        "Agents need memory. Pixeltable tables with embedding indexes provide both recency-based and semantic recall — persisted across sessions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Chat History\n",
        "\n",
        "Store every conversation turn with timestamps and user IDs. An embedding index enables semantic search over all past conversations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "chat_history = pxt.create_table('agents.chat_history', {\n",
        "    'role': pxt.String,\n",
        "    'content': pxt.String,\n",
        "    'timestamp': pxt.Timestamp,\n",
        "    'user_id': pxt.String,\n",
        "})\n",
        "\n",
        "chat_history.add_embedding_index(\n",
        "    'content',\n",
        "    string_embed=sentence_transformer.using(model_id='all-MiniLM-L6-v2'),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "now = datetime.datetime.now\n",
        "\n",
        "chat_history.insert([\n",
        "    {'role': 'user', 'content': 'What is the Nvidia outlook?', 'timestamp': now(), 'user_id': 'alice'},\n",
        "    {'role': 'assistant', 'content': 'Analysts are bullish on NVDA due to strong AI chip demand. Revenue grew 262% YoY.', 'timestamp': now(), 'user_id': 'alice'},\n",
        "    {'role': 'user', 'content': 'How about Alphabet cloud revenue?', 'timestamp': now(), 'user_id': 'alice'},\n",
        "    {'role': 'assistant', 'content': 'Google Cloud grew 28% YoY to $9.57B in Q1 2024, driven by AI workloads.', 'timestamp': now(), 'user_id': 'alice'},\n",
        "    {'role': 'user', 'content': 'Compare AAPL and MSFT earnings.', 'timestamp': now(), 'user_id': 'bob'},\n",
        "    {'role': 'assistant', 'content': 'Apple reported $90.8B revenue (+5% YoY). Microsoft reported $61.9B (+17% YoY), led by Azure growth.', 'timestamp': now(), 'user_id': 'bob'},\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Recent History Query\n",
        "\n",
        "Retrieve the most recent turns for a given user — standard recency-based context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "@pxt.query\n",
        "def get_recent_history(user_id: str, limit: int = 4):\n",
        "    \"\"\"Get the most recent chat messages for a user.\"\"\"\n",
        "    return (\n",
        "        chat_history\n",
        "        .where(chat_history.user_id == user_id)\n",
        "        .order_by(chat_history.timestamp, asc=False)\n",
        "        .select(role=chat_history.role, content=chat_history.content)\n",
        "        .limit(limit)\n",
        "    )\n",
        "\n",
        "# Test recent history inline\n",
        "(\n",
        "    chat_history\n",
        "    .where(chat_history.user_id == 'alice')\n",
        "    .order_by(chat_history.timestamp, asc=False)\n",
        "    .select(chat_history.role, chat_history.content)\n",
        "    .limit(4)\n",
        "    .collect()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Semantic Recall\n",
        "\n",
        "Search past conversations by meaning — find relevant context even from old conversations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "@pxt.query\n",
        "def recall_memory(query_text: str, user_id: str, limit: int = 3):\n",
        "    \"\"\"Search past conversations by semantic similarity for a specific user.\"\"\"\n",
        "    sim = chat_history.content.similarity(query_text)\n",
        "    return (\n",
        "        chat_history\n",
        "        .where(chat_history.user_id == user_id)\n",
        "        .order_by(sim, asc=False)\n",
        "        .select(role=chat_history.role, content=chat_history.content, score=sim)\n",
        "        .limit(limit)\n",
        "    )\n",
        "\n",
        "# Alice asks about cloud — semantic search finds the Alphabet conversation\n",
        "sim = chat_history.content.similarity('cloud computing growth')\n",
        "(\n",
        "    chat_history\n",
        "    .where(chat_history.user_id == 'alice')\n",
        "    .order_by(sim, asc=False)\n",
        "    .select(chat_history.role, chat_history.content, score=sim)\n",
        "    .limit(3)\n",
        "    .collect()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Memory Bank\n",
        "\n",
        "Beyond chat history, store explicit facts, code snippets, or user preferences that the agent should remember."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "memory_bank = pxt.create_table('agents.memory_bank', {\n",
        "    'content': pxt.String,\n",
        "    'memory_type': pxt.String,\n",
        "    'context': pxt.String,\n",
        "    'timestamp': pxt.Timestamp,\n",
        "    'user_id': pxt.String,\n",
        "})\n",
        "\n",
        "memory_bank.add_embedding_index(\n",
        "    'content',\n",
        "    string_embed=sentence_transformer.using(model_id='all-MiniLM-L6-v2'),\n",
        ")\n",
        "\n",
        "memory_bank.insert([\n",
        "    {\n",
        "        'content': 'User prefers concise answers with specific numbers.',\n",
        "        'memory_type': 'preference',\n",
        "        'context': 'Inferred from interaction style',\n",
        "        'timestamp': now(),\n",
        "        'user_id': 'alice',\n",
        "    },\n",
        "    {\n",
        "        'content': 'User is tracking NVDA, GOOGL, and MSFT for a portfolio review.',\n",
        "        'memory_type': 'fact',\n",
        "        'context': 'User mentioned portfolio in earlier conversation',\n",
        "        'timestamp': now(),\n",
        "        'user_id': 'alice',\n",
        "    },\n",
        "    {\n",
        "        'content': 'User wants weekly market digests emailed every Friday.',\n",
        "        'memory_type': 'preference',\n",
        "        'context': 'User configuration request',\n",
        "        'timestamp': now(),\n",
        "        'user_id': 'bob',\n",
        "    },\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "@pxt.query\n",
        "def search_memory(query_text: str, user_id: str, limit: int = 3):\n",
        "    \"\"\"Search the memory bank for saved facts, preferences, and context about a user.\"\"\"\n",
        "    sim = memory_bank.content.similarity(query_text)\n",
        "    return (\n",
        "        memory_bank\n",
        "        .where(memory_bank.user_id == user_id)\n",
        "        .order_by(sim, asc=False)\n",
        "        .select(\n",
        "            content=memory_bank.content,\n",
        "            memory_type=memory_bank.memory_type,\n",
        "            score=sim,\n",
        "        )\n",
        "        .limit(limit)\n",
        "    )\n",
        "\n",
        "# Search Alice's memory bank for portfolio-related facts\n",
        "sim = memory_bank.content.similarity('portfolio stocks')\n",
        "(\n",
        "    memory_bank\n",
        "    .where(memory_bank.user_id == 'alice')\n",
        "    .order_by(sim, asc=False)\n",
        "    .select(memory_bank.content, memory_bank.memory_type, score=sim)\n",
        "    .limit(3)\n",
        "    .collect()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 5 — Deploy\n",
        "\n",
        "Wire the agent, memory, and tools together in an API endpoint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Flask Endpoint with Memory\n",
        "\n",
        "```python\n",
        "from flask import Flask, request, jsonify\n",
        "from datetime import datetime\n",
        "import pixeltable as pxt\n",
        "\n",
        "app = Flask(__name__)\n",
        "agent = pxt.get_table('agents.workflow')\n",
        "chat_history = pxt.get_table('agents.chat_history')\n",
        "\n",
        "SYSTEM_PROMPT = 'You are a financial research assistant with access to tools.'\n",
        "\n",
        "@app.route('/chat', methods=['POST'])\n",
        "def chat():\n",
        "    data = request.json\n",
        "    user_id = data['user_id']\n",
        "    prompt = data['message']\n",
        "\n",
        "    # 1. Store user message\n",
        "    chat_history.insert([{\n",
        "        'role': 'user',\n",
        "        'content': prompt,\n",
        "        'timestamp': datetime.now(),\n",
        "        'user_id': user_id,\n",
        "    }])\n",
        "\n",
        "    # 2. Trigger agent workflow (computed columns run automatically)\n",
        "    agent.insert([{\n",
        "        'prompt': prompt,\n",
        "        'system_prompt': SYSTEM_PROMPT,\n",
        "    }])\n",
        "\n",
        "    # 3. Get the answer\n",
        "    result = agent.order_by(agent._rowid, asc=False).select(agent.answer).limit(1).collect()\n",
        "    answer = result[0]['answer']\n",
        "\n",
        "    # 4. Store assistant response\n",
        "    chat_history.insert([{\n",
        "        'role': 'assistant',\n",
        "        'content': answer,\n",
        "        'timestamp': datetime.now(),\n",
        "        'user_id': user_id,\n",
        "    }])\n",
        "\n",
        "    return jsonify({'response': answer})\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Full Schema Overview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('=== Knowledge Base ===')\n",
        "print(f'docs: {docs.count()} rows')\n",
        "print(f'chunks: {chunks.count()} rows')\n",
        "\n",
        "print('\\n=== Agent Workflow ===')\n",
        "print(f'agent: {agent.count()} rows')\n",
        "agent.describe()\n",
        "\n",
        "print('\\n=== Memory ===')\n",
        "print(f'chat_history: {chat_history.count()} rows')\n",
        "print(f'memory_bank: {memory_bank.count()} rows')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "| Phase | What Pixeltable handled |\n",
        "|-------|------------------------|\n",
        "| **Tools** | `@pxt.udf` for API calls, `@pxt.query` for agentic RAG, `pxt.tools()` for registration |\n",
        "| **Workflow** | Agent as a table — tool selection, execution, and synthesis as computed columns |\n",
        "| **MCP** | `pxt.mcp_udfs()` to load external tools, mix with local tools |\n",
        "| **Memory** | Chat history + memory bank, both with embedding indexes for semantic recall |\n",
        "| **Deploy** | Flask endpoint — `insert()` triggers the full agent pipeline |\n",
        "\n",
        "### What you didn't need\n",
        "\n",
        "- An agent framework (LangChain, CrewAI, AutoGen) — computed columns are the orchestration\n",
        "- A separate memory store (Redis, Zep) — Pixeltable tables with embedding indexes\n",
        "- A vector database for RAG — built-in embedding indexes\n",
        "- Imperative control flow — the agent is declarative, each row triggers the full chain\n",
        "- Manual tool dispatch — `invoke_tools()` handles execution automatically\n",
        "\n",
        "### Next steps\n",
        "\n",
        "| Topic | Link |\n",
        "|-------|------|\n",
        "| Tool calling deep dive | [Tool Calling Cookbook](https://docs.pixeltable.com/howto/cookbooks/agents/llm-tool-calling) |\n",
        "| Agent memory patterns | [Agent Memory](https://docs.pixeltable.com/howto/cookbooks/agents/pattern-agent-memory) |\n",
        "| RAG pipeline patterns | [RAG Pipeline](https://docs.pixeltable.com/howto/cookbooks/agents/pattern-rag-pipeline) |\n",
        "| Pixelbot (full agent app) | [GitHub](https://github.com/pixeltable/pixelbot) |\n",
        "| Pixelagent framework | [GitHub](https://github.com/pixeltable/pixelagent) |\n",
        "| MCP server for AI IDEs | [GitHub](https://github.com/pixeltable/mcp-server-pixeltable-developer) |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pxt.drop_dir('agents', force=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pixeltable",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}