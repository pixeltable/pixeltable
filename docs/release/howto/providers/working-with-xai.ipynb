{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Working with xAI Grok in Pixeltable\n",
        "\n",
        "Pixeltable's xAI integration enables you to use Grok models for chat, reasoning, and image generation via the native xAI SDK.\n",
        "\n",
        "### Prerequisites\n",
        "- An xAI account with an API key (https://console.x.ai/)\n",
        "\n",
        "### Important notes\n",
        "\n",
        "- xAI API usage incurs costs based on your xAI plan\n",
        "- The native xAI SDK (`xai-sdk`) provides access to the latest features including reasoning models\n",
        "- The OpenAI-compatible endpoint is also supported for backward compatibility\n",
        "- Be mindful of sensitive data and consider security measures when integrating with external services\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First you'll need to install the xAI SDK and set up your xAI API key.\n",
        "\n",
        "```bash\n",
        "pip install xai-sdk\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For local development, use the local pixeltable path\n",
        "import sys\n",
        "sys.path.insert(0, '/Users/pierre/pixeltable')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "if 'XAI_API_KEY' not in os.environ:\n",
        "    os.environ['XAI_API_KEY'] = getpass.getpass('Enter your xAI API key: ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's create a Pixeltable directory to hold the tables for our demo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pixeltable as pxt\n",
        "\n",
        "# Remove the 'xai_demo' directory and its contents, if it exists\n",
        "pxt.drop_dir('xai_demo', force=True)\n",
        "pxt.create_dir('xai_demo')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chat with Grok\n",
        "\n",
        "Grok is xAI's flagship language model, designed to provide truthful, insightful answers. The `xai.chat` UDF uses the native xAI SDK which supports the latest features including the Responses API.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "from pixeltable.functions import xai\n",
        "\n",
        "# Create a table for chat conversations\n",
        "chat_t = pxt.create_table('xai_demo.chat', {'prompt': pxt.String})\n",
        "\n",
        "# Create message format for Grok\n",
        "messages = [\n",
        "    {'role': 'system', 'content': 'You are Grok, a helpful AI assistant created by xAI.'},\n",
        "    {'role': 'user', 'content': chat_t.prompt}\n",
        "]\n",
        "\n",
        "# Add computed column using the native xAI chat UDF\n",
        "chat_t.add_computed_column(\n",
        "    response=xai.chat(messages=messages, model='grok-4')\n",
        ")\n",
        "\n",
        "# Extract just the response text\n",
        "chat_t.add_computed_column(\n",
        "    answer=chat_t.response['content']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insert some prompts\n",
        "chat_t.insert([\n",
        "    {'prompt': 'What is the meaning of life, the universe, and everything?'},\n",
        "    {'prompt': 'Explain quantum computing in simple terms.'},\n",
        "    {'prompt': 'What makes a good cup of coffee?'},\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View the results\n",
        "chat_t.select(chat_t.prompt, chat_t.answer).collect()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reasoning Models\n",
        "\n",
        "The `grok-3-mini` model supports extended reasoning with the `reasoning_effort` parameter. This allows the model to \"think\" longer for complex problems.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a table for reasoning tasks\n",
        "reasoning_t = pxt.create_table('xai_demo.reasoning', {'problem': pxt.String})\n",
        "\n",
        "# Create message format\n",
        "messages = [\n",
        "    {'role': 'system', 'content': 'You are a math expert. Show your work step by step.'},\n",
        "    {'role': 'user', 'content': reasoning_t.problem}\n",
        "]\n",
        "\n",
        "# Use reasoning model with high effort for complex problems\n",
        "reasoning_t.add_computed_column(\n",
        "    response=xai.chat(\n",
        "        messages=messages,\n",
        "        model='grok-3-mini',\n",
        "        reasoning_effort='high'\n",
        "    )\n",
        ")\n",
        "\n",
        "# Extract answer and reasoning tokens used\n",
        "reasoning_t.add_computed_column(answer=reasoning_t.response['content'])\n",
        "reasoning_t.add_computed_column(reasoning_tokens=reasoning_t.response['usage']['reasoning_tokens'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insert math problems\n",
        "reasoning_t.insert([\n",
        "    {'problem': 'What is 101 * 3?'},\n",
        "    {'problem': 'If a train travels 120 miles in 2 hours, what is its average speed?'},\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View the results with reasoning tokens\n",
        "reasoning_t.select(reasoning_t.problem, reasoning_t.answer, reasoning_t.reasoning_tokens).collect()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Generation\n",
        "\n",
        "xAI also offers image generation capabilities with Grok models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create a table for image generation\n",
        "img_t = pxt.create_table('xai_demo.images', {'prompt': pxt.String})\n",
        "\n",
        "# Add computed column for image generation\n",
        "img_t.add_computed_column(\n",
        "    generated_image=xai.image_generations(img_t.prompt, model='grok-2-image')\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insert image prompts\n",
        "img_t.insert([\n",
        "    {'prompt': 'A futuristic cityscape at sunset with flying cars'},\n",
        "    {'prompt': 'A cute robot helping in a garden'},\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View the generated images\n",
        "img_t.select(img_t.prompt, img_t.generated_image).collect()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Available Models\n",
        "\n",
        "### Language Models\n",
        "\n",
        "| Model | Description |\n",
        "|-------|-------------|\n",
        "| `grok-4` | Latest and most capable Grok 4 model |\n",
        "| `grok-4-fast` | Faster Grok 4 variant |\n",
        "| `grok-3` | Grok 3 model |\n",
        "| `grok-3-fast` | Faster Grok 3 variant |\n",
        "| `grok-3-mini` | Reasoning model with `reasoning_effort` support |\n",
        "| `grok-2-vision-1212` | Grok 2 with vision capabilities |\n",
        "| `grok-code-fast-1` | Code-optimized model |\n",
        "\n",
        "### Image Generation Models\n",
        "\n",
        "| Model | Description |\n",
        "|-------|-------------|\n",
        "| `grok-2-image` | Image generation model |\n",
        "\n",
        "### Chat Parameters\n",
        "\n",
        "The `chat` function supports:\n",
        "\n",
        "- `model`: The Grok model to use\n",
        "- `reasoning_effort`: `'low'` or `'high'` (only for `grok-3-mini`)\n",
        "- `max_tokens`: Maximum tokens in the response\n",
        "- `temperature`: Sampling temperature (0-2)\n",
        "- `top_p`: Nucleus sampling parameter\n",
        "- `store_messages`: Enable stateful Responses API\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learn More\n",
        "\n",
        "- [xAI Documentation](https://docs.x.ai/)\n",
        "- [xAI Console](https://console.x.ai/)\n",
        "- [Grok Models](https://docs.x.ai/docs/models)\n",
        "- [Responses API Guide](https://docs.x.ai/docs/guides/responses-api)\n",
        "- [Reasoning Models Guide](https://docs.x.ai/docs/guides/reasoning)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
