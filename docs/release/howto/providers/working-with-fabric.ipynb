{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Working with Microsoft Fabric\"\n",
    "icon: \"notebook\"\n",
    "description: \"[Open in Kaggle](https://kaggle.com/kernels/welcome?src=https://github.com/pixeltable/pixeltable/blob/release/docs/release/howto/providers/working-with-fabric.ipynb) | [Open in Colab](https://colab.research.google.com/github/pixeltable/pixeltable/blob/release/docs/release/howto/providers/working-with-fabric.ipynb) | [View on GitHub](https://github.com/pixeltable/pixeltable/blob/release/docs/release/howto/providers/working-with-fabric.ipynb)\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pixeltable's Microsoft Fabric integration enables you to access Azure OpenAI models within Microsoft Fabric notebook environments with automatic authentication.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- A Microsoft Fabric workspace with access to AI services\n",
    "- Running in a Microsoft Fabric notebook environment\n",
    "\n",
    "## Important notes\n",
    "\n",
    "- This integration only works within Microsoft Fabric notebook environments\n",
    "- Authentication is handled automatically - no API keys required\n",
    "- Azure OpenAI usage in Fabric is subject to your organization's Fabric capacity and policies\n",
    "\n",
    "For more information about Fabric AI services, see the [Microsoft Fabric AI Services documentation](https://learn.microsoft.com/en-us/fabric/data-science/ai-services/ai-services-overview).\n",
    "\n",
    "First, install Pixeltable in your Fabric notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pixeltable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a Pixeltable directory to hold the tables for our demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixeltable as pxt\n",
    "\n",
    "# Remove the 'fabric_demo' directory and its contents, if it exists\n",
    "pxt.drop_dir('fabric_demo', force=True)\n",
    "pxt.create_dir('fabric_demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Completions with Standard Models\n",
    "\n",
    "Let's start by using a standard chat model (gpt-4.1) for a simple Q&A application.\n",
    "\n",
    "Create a table in Pixeltable with a computed column that calls Azure OpenAI via Fabric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixeltable.functions import fabric\n",
    "\n",
    "# Create a table for customer support tickets\n",
    "tickets = pxt.create_table('fabric_demo.support_tickets', {\n",
    "    'ticket_id': pxt.Int,\n",
    "    'customer_message': pxt.String,\n",
    "    'priority': pxt.String\n",
    "})\n",
    "\n",
    "# Add a computed column that automatically generates AI responses\n",
    "# No API keys needed - Fabric handles authentication!\n",
    "messages = [\n",
    "    {'role': 'system', 'content': 'You are a helpful customer support agent. Be concise and professional.'},\n",
    "    {'role': 'user', 'content': tickets.customer_message}\n",
    "]\n",
    "\n",
    "tickets.add_computed_column(\n",
    "    ai_response=fabric.chat_completions(\n",
    "        messages,\n",
    "        model='gpt-4.1',\n",
    "        model_kwargs={\n",
    "            'max_tokens': 200,\n",
    "            'temperature': 0.7\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the response to extract just the message content\n",
    "tickets.add_computed_column(\n",
    "    response_text=tickets.ai_response.choices[0].message.content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data - AI responses are generated automatically\n",
    "tickets.insert([\n",
    "    {'ticket_id': 1, 'customer_message': 'How do I reset my password?', 'priority': 'low'},\n",
    "    {'ticket_id': 2, 'customer_message': 'My order hasn\\'t arrived after 2 weeks', 'priority': 'high'},\n",
    "    {'ticket_id': 3, 'customer_message': 'Can I change my subscription plan?', 'priority': 'medium'}\n",
    "])\n",
    "\n",
    "# Query results with AI-generated responses\n",
    "tickets.select(\n",
    "    tickets.ticket_id,\n",
    "    tickets.customer_message,\n",
    "    tickets.response_text\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Completions with Reasoning Models\n",
    "\n",
    "Fabric also supports reasoning models like gpt-5, which are optimized for complex reasoning tasks.\n",
    "\n",
    "**Note:** Reasoning models have different parameter requirements:\n",
    "- Use `max_completion_tokens` instead of `max_tokens`\n",
    "- Don't support the `temperature` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table for complex reasoning tasks\n",
    "reasoning_tasks = pxt.create_table('fabric_demo.reasoning', {\n",
    "    'task_id': pxt.Int,\n",
    "    'problem': pxt.String\n",
    "})\n",
    "\n",
    "messages = [\n",
    "    {'role': 'user', 'content': reasoning_tasks.problem}\n",
    "]\n",
    "\n",
    "reasoning_tasks.add_computed_column(\n",
    "    reasoning_output=fabric.chat_completions(\n",
    "        messages,\n",
    "        model='gpt-5',  # Reasoning model\n",
    "        model_kwargs={\n",
    "            'max_completion_tokens': 1000  # Note: max_completion_tokens, not max_tokens\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "reasoning_tasks.add_computed_column(\n",
    "    solution=reasoning_tasks.reasoning_output.choices[0].message.content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a complex reasoning task\n",
    "reasoning_tasks.insert([\n",
    "    {\n",
    "        'task_id': 1,\n",
    "        'problem': 'Explain how to implement a binary search tree with self-balancing capabilities. Include time complexity analysis.'\n",
    "    }\n",
    "])\n",
    "\n",
    "reasoning_tasks.select(reasoning_tasks.problem, reasoning_tasks.solution).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings for Semantic Search\n",
    "\n",
    "Fabric also supports embedding models for semantic search and similarity operations.\n",
    "\n",
    "Let's create a knowledge base with semantic search capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a knowledge base table\n",
    "knowledge_base = pxt.create_table('fabric_demo.knowledge', {\n",
    "    'doc_id': pxt.Int,\n",
    "    'content': pxt.String,\n",
    "    'category': pxt.String\n",
    "})\n",
    "\n",
    "# Add embeddings column\n",
    "knowledge_base.add_computed_column(\n",
    "    embedding=fabric.embeddings(\n",
    "        knowledge_base.content,\n",
    "        model='text-embedding-ada-002'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Insert some documents\n",
    "knowledge_base.insert([\n",
    "    {\n",
    "        'doc_id': 1,\n",
    "        'content': 'Pixeltable is a Python library for AI data workflows with built-in versioning.',\n",
    "        'category': 'product'\n",
    "    },\n",
    "    {\n",
    "        'doc_id': 2,\n",
    "        'content': 'Microsoft Fabric provides a unified analytics platform for data engineering and AI.',\n",
    "        'category': 'platform'\n",
    "    },\n",
    "    {\n",
    "        'doc_id': 3,\n",
    "        'content': 'Azure OpenAI Service offers powerful language models through REST APIs.',\n",
    "        'category': 'service'\n",
    "    }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an embedding index for fast similarity search\n",
    "knowledge_base.add_embedding_index('content', embedding=fabric.embeddings.using(model='text-embedding-ada-002'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform similarity search\n",
    "sim = knowledge_base.content.similarity('AI platform for data science')\n",
    "knowledge_base.select(knowledge_base.content, knowledge_base.category, sim=sim).order_by(sim, asc=False).limit(2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Chat and Embeddings: RAG Pattern\n",
    "\n",
    "Let's combine embeddings and chat completions to build a simple Retrieval-Augmented Generation (RAG) system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table for questions\n",
    "questions = pxt.create_table('fabric_demo.questions', {\n",
    "    'question_id': pxt.Int,\n",
    "    'question': pxt.String\n",
    "})\n",
    "\n",
    "# Find similar documents using similarity search\n",
    "@pxt.query\n",
    "def retrieve_context(question: str, top_k: int = 2) -> list[dict]:\n",
    "    sim = knowledge_base.content.similarity(question)\n",
    "    return (\n",
    "        knowledge_base\n",
    "        .select(knowledge_base.content)\n",
    "        .order_by(sim, asc=False)\n",
    "        .limit(top_k)\n",
    "        .collect()['content']\n",
    "    )\n",
    "\n",
    "# Add context retrieval\n",
    "questions.add_computed_column(\n",
    "    context=retrieve_context(questions.question, top_k=2)\n",
    ")\n",
    "\n",
    "# Build RAG prompt with retrieved context\n",
    "questions.add_computed_column(\n",
    "    rag_messages=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': \"Answer the question based on the provided context. If the context doesn't contain relevant information, say so.\"\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': f'Context: {questions.context}\\n\\nQuestion: {questions.question}'\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Generate answer using gpt-4.1\n",
    "questions.add_computed_column(\n",
    "    answer_response=fabric.chat_completions(\n",
    "        questions.rag_messages,\n",
    "        model='gpt-4.1',\n",
    "        model_kwargs={'max_tokens': 300}\n",
    "    )\n",
    ")\n",
    "\n",
    "questions.add_computed_column(\n",
    "    answer=questions.answer_response.choices[0].message.content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "questions.insert([\n",
    "    {'question_id': 1, 'question': 'What is Microsoft Fabric used for?'}\n",
    "])\n",
    "\n",
    "questions.select(\n",
    "    questions.question,\n",
    "    questions.context,\n",
    "    questions.answer\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Models in Fabric\n",
    "\n",
    "The following models are currently available in Microsoft Fabric:\n",
    "\n",
    "**Chat Models:**\n",
    "- `gpt-5` (reasoning model)\n",
    "- `gpt-4.1`\n",
    "- `gpt-4.1-mini`\n",
    "\n",
    "**Embedding Models:**\n",
    "- `text-embedding-ada-002`\n",
    "- `text-embedding-3-small`\n",
    "- `text-embedding-3-large`\n",
    "\n",
    "For the latest information on available models, see the [Fabric AI Services documentation](https://learn.microsoft.com/en-us/fabric/data-science/ai-services/ai-services-overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Features\n",
    "\n",
    "- **Automatic Authentication**: No API keys required - authentication is handled by Fabric\n",
    "- **Rate Limiting**: Pixeltable automatically handles rate limiting based on Azure OpenAI response headers\n",
    "- **Batching**: Embedding requests are automatically batched for efficiency (up to 32 inputs per request)\n",
    "- **Incremental Processing**: Computed columns only run on new or updated data\n",
    "- **Versioning**: All data and transformations are automatically versioned\n",
    "\n",
    "### Learn More\n",
    "\n",
    "To learn more about advanced techniques in Pixeltable:\n",
    "- [RAG Operations in Pixeltable](https://docs.pixeltable.com/howto/use-cases/rag-operations)\n",
    "- [Working with Embeddings](https://docs.pixeltable.com/platform/embedding-indexes)\n",
    "- [Microsoft Fabric AI Services](https://learn.microsoft.com/en-us/fabric/data-science/ai-services/ai-services-overview)\n",
    "\n",
    "If you have any questions, don't hesitate to reach out on our [Discord community](https://discord.gg/QPyqFYx2UN)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
