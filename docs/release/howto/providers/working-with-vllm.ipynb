{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "title: \"Working with vLLM\"\n",
        "icon: \"notebook\"\n",
        "description: \"[Open in Kaggle](https://kaggle.com/kernels/welcome?src=https://github.com/pixeltable/pixeltable/blob/release/docs/notebooks/howto/providers/working-with-vllm.ipynb) | [Open in Colab](https://colab.research.google.com/github/pixeltable/pixeltable/blob/release/docs/notebooks/howto/providers/working-with-vllm.ipynb) | [View on GitHub](https://github.com/pixeltable/pixeltable/blob/release/docs/notebooks/howto/providers/working-with-vllm.ipynb)\"\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This tutorial demonstrates how to use Pixeltable's built-in `vLLM` integration to run local LLMs with high-throughput inference.\n",
        "\n",
        "<div class=\"alert alert-block alert-info\"><!-- mdx:none -->\n",
        "<b>If you are running this tutorial in Colab:</b>\n",
        "vLLM requires a GPU for efficient operation. Click on the <code>Runtime -> Change runtime type</code> menu item at the top, then select the <code>GPU</code> radio button and click on <code>Save</code>.\n",
        "</div>\n",
        "\n",
        "### Important notes\n",
        "\n",
        "- vLLM provides high-throughput inference with techniques like PagedAttention and continuous batching\n",
        "- Models are loaded from HuggingFace and cached in memory for reuse\n",
        "- vLLM currently requires a Linux environment with GPU support for best performance\n",
        "- Consider GPU memory when choosing model sizes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up environment\n",
        "\n",
        "First, let's install Pixeltable with vLLM support:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU pixeltable vllm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a table for chat completions\n",
        "\n",
        "Now let's create a table that will contain our inputs and responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created directory 'vllm_demo'.\n",
            "Created table 'chat'.\n"
          ]
        }
      ],
      "source": [
        "import pixeltable as pxt\n",
        "from pixeltable.functions import vllm\n",
        "\n",
        "pxt.drop_dir('vllm_demo', force=True)\n",
        "pxt.create_dir('vllm_demo')\n",
        "\n",
        "t = pxt.create_table('vllm_demo/chat', {'input': pxt.String})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we add a computed column that calls the Pixeltable `chat_completions` UDF, which uses vLLM's high-throughput inference engine under the hood. We specify a HuggingFace model identifier, and vLLM will download and cache the model automatically.\n",
        "\n",
        "(If this is your first time using Pixeltable, the <a href=\"https://docs.pixeltable.com/tutorials/tables-and-data-operations\">Pixeltable Fundamentals</a> tutorial contains more details about table creation, computed columns, and UDFs.)\n",
        "\n",
        "For this demo we'll use `Qwen2.5-0.5B-Instruct`, a very small (0.5-billion parameter) model that still produces decent results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added 0 column values with 0 errors in 0.01 s\n",
            "Added 0 column values with 0 errors in 0.00 s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "No rows affected."
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add a computed column that uses vLLM for chat completion\n",
        "# against the input.\n",
        "\n",
        "messages = [\n",
        "    {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
        "    {'role': 'user', 'content': t.input},\n",
        "]\n",
        "\n",
        "t.add_computed_column(\n",
        "    result=vllm.chat_completions(\n",
        "        messages,\n",
        "        model='Qwen/Qwen2.5-0.5B-Instruct',\n",
        "    )\n",
        ")\n",
        "\n",
        "# Extract the output content from the native vLLM response.\n",
        "\n",
        "t.add_computed_column(output=t.result.outputs[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test chat completion\n",
        "\n",
        "Let's try a few queries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inserted 3 rows with 0 errors in 1.74 s (1.72 rows/s)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "3 rows inserted."
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test with a few questions\n",
        "t.insert(\n",
        "    [\n",
        "        {'input': 'What is the capital of France?'},\n",
        "        {'input': 'What are some edible species of fish?'},\n",
        "        {'input': 'Who are the most prominent classical composers?'},\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>What is the capital of France?</td>\n",
              "      <td>The capital of France is Paris.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>What are some edible species of fish?</td>\n",
              "      <td>Some edible species of fish include:\n",
              "\n",
              "1. Salmon\n",
              "2. Trout \n",
              "3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Who are the most prominent classical composers?</td>\n",
              "      <td>There have been many notable classical composers throughout history, and their contributions to music have</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "                                             input  \\\n",
              "0                   What is the capital of France?   \n",
              "1            What are some edible species of fish?   \n",
              "2  Who are the most prominent classical composers?   \n",
              "\n",
              "                                              output  \n",
              "0                    The capital of France is Paris.  \n",
              "1  Some edible species of fish include:\\n\\n1. Sal...  \n",
              "2  There have been many notable classical compose...  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.select(t.input, t.output).collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing models\n",
        "\n",
        "vLLM makes it easy to compare the output of different models. Let's try comparing the output from `Qwen2.5-0.5B` against a somewhat larger model, `Qwen2.5-1.5B-Instruct`. As always, when we add a new computed column to our table, it's automatically evaluated against the existing table rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added 3 column values with 0 errors in 3.45 s (0.87 rows/s)\n",
            "Added 3 column values with 0 errors in 0.01 s (225.06 rows/s)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>output_qwen15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>What is the capital of France?</td>\n",
              "      <td>The capital of France is Paris.</td>\n",
              "      <td>The capital of France is Paris.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>What are some edible species of fish?</td>\n",
              "      <td>Some edible species of fish include:\n",
              "\n",
              "1. Salmon\n",
              "2. Trout \n",
              "3</td>\n",
              "      <td>Some edible species of fish include salmon, trout, cod, halibut,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Who are the most prominent classical composers?</td>\n",
              "      <td>There have been many notable classical composers throughout history, and their contributions to music have</td>\n",
              "      <td>There have been many influential classical composers throughout history, but some of the most prominent</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "                                             input  \\\n",
              "0                   What is the capital of France?   \n",
              "1            What are some edible species of fish?   \n",
              "2  Who are the most prominent classical composers?   \n",
              "\n",
              "                                              output  \\\n",
              "0                    The capital of France is Paris.   \n",
              "1  Some edible species of fish include:\\n\\n1. Sal...   \n",
              "2  There have been many notable classical compose...   \n",
              "\n",
              "                                       output_qwen15  \n",
              "0                    The capital of France is Paris.  \n",
              "1  Some edible species of fish include salmon, tr...  \n",
              "2  There have been many influential classical com...  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.add_computed_column(\n",
        "    result_qwen15=vllm.chat_completions(\n",
        "        messages,\n",
        "        model='Qwen/Qwen2.5-1.5B-Instruct',\n",
        "    )\n",
        ")\n",
        "\n",
        "t.add_computed_column(output_qwen15=t.result_qwen15.outputs[0].text)\n",
        "\n",
        "t.select(t.input, t.output, t.output_qwen15).collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using sampling parameters\n",
        "\n",
        "vLLM supports fine-grained control over generation through `sampling_params`. Parameters like `max_tokens`, `temperature`, `top_p`, and `top_k` control the decoding behavior. Engine-level settings (such as `max_model_len`) can be passed separately via `engine_kwargs`. Let's try running with a different system prompt and custom sampling settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added 3 column values with 0 errors in 14.16 s (0.21 rows/s)\n",
            "Added 3 column values with 0 errors in 0.01 s (271.08 rows/s)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>input</th>\n",
              "      <th>output_teacher</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>What is the capital of France?</td>\n",
              "      <td>The capital of France is Paris.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>What are some edible species of fish?</td>\n",
              "      <td>Edible species of fish are a fascinating group of aquatic creatures that can be enjoyed for their various flavors and nutritional benefits. Here are some examples:\n",
              "\n",
              "1. **Salmon**: These are a type of fish that is often caught for their rich, oily flesh. They are popular in many cuisines around the world.\n",
              "\n",
              "2. **Haddock**: A species of large, flat fish that can be used in many recipes, from fish tacos to fish puree.\n",
              "\n",
              "3. **Cod**: Another type of fish, cod is known for its rich, buttery flavor a ...... particularly in Canada and the United States. It is known for its mild flavor and can be used in soups, stews, and as a base for sauces.\n",
              "\n",
              "5. **Eel**: Eels are a type of fish that can be found in saltwater and freshwater environments. They are often smoked or boiled for a unique flavor.\n",
              "\n",
              "6. **Pufferfish**: Pufferfish is a species of fish that can be quite toxic. They are sometimes used in certain dishes for their unique flavor.\n",
              "\n",
              "7. **Flounder**: Flounders are a type of fish that can be caught</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Who are the most prominent classical composers?</td>\n",
              "      <td>The most prominent classical composers include:\n",
              "\n",
              "1. Mozart: He was a master of the symphonic form, known for his piano sonatas and operas.\n",
              "2. Beethoven: He was a pivotal figure in the development of symphonic structure and helped shape the classical era.\n",
              "3. Bach: He composed in a variety of styles, including cantatas and operas, and is considered the father of classical music.\n",
              "4. Haydn: He was a prolific composer who is often referred to as the &quot;father of the classical era.&quot;\n",
              "5. Beethoven&#x27;s son: Ludwig von Beethoven, who lived to be 56, was a prodigious composer who also wrote piano sonatas and other works.\n",
              "\n",
              "These composers, along with others, have had a profound influence on the development of classical music and have been celebrated for their mastery of the form and their contributions to the art of music.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "                                             input  \\\n",
              "0                   What is the capital of France?   \n",
              "1            What are some edible species of fish?   \n",
              "2  Who are the most prominent classical composers?   \n",
              "\n",
              "                                      output_teacher  \n",
              "0                    The capital of France is Paris.  \n",
              "1  Edible species of fish are a fascinating group...  \n",
              "2  The most prominent classical composers include...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages_teacher = [\n",
        "    {\n",
        "        'role': 'system',\n",
        "        'content': 'You are a patient school teacher. '\n",
        "        'Explain concepts simply and clearly.',\n",
        "    },\n",
        "    {'role': 'user', 'content': t.input},\n",
        "]\n",
        "\n",
        "t.add_computed_column(\n",
        "    result_teacher=vllm.chat_completions(\n",
        "        messages_teacher,\n",
        "        model='Qwen/Qwen2.5-0.5B-Instruct',\n",
        "        sampling_params={'max_tokens': 256, 'temperature': 0.7, 'top_p': 0.9},\n",
        "    )\n",
        ")\n",
        "\n",
        "t.add_computed_column(\n",
        "    output_teacher=t.result_teacher.outputs[0].text\n",
        ")\n",
        "\n",
        "t.select(t.input, t.output_teacher).collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text generation\n",
        "\n",
        "In addition to chat completions, vLLM also supports direct text generation with the `generate` UDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created table 'generation'.\n",
            "Added 0 column values with 0 errors in 0.00 s\n",
            "Added 0 column values with 0 errors in 0.00 s\n",
            "Inserted 2 rows with 0 errors in 5.88 s (0.34 rows/s)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>prompt</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>The capital of France is</td>\n",
              "      <td>Paris, the center of political, economic, cultural and social life. It is also found at the foot of the Montmartre hill under the exaggerated view of sculptor, Eug√®ne Balzac. What are the enlargements where you could observe Paris&#x27;s views?\n",
              "A: \n",
              "B: \n",
              "C: \n",
              "D:\n",
              "To determine which city has the capital, we need to understand the concept of capital. The capital of a country is a defined location where that country&#x27;s government is located. Therefore,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Once upon a time, there was a</td>\n",
              "      <td>very large tree. It had a very wide root, leaving it can not reach any further, and it had a fantastic friend named Frog who could keep the tree tree safe. One sunny day, a fox came to visit the tree. When it put down its cane, it hurt the tree root. The root was strong since it had been there for a very long time, so when the owner&#x27;s friend Frog got mad, he gave the fox a test.\n",
              "\n",
              "The next day, when the fox tried</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "                          prompt  \\\n",
              "0       The capital of France is   \n",
              "1  Once upon a time, there was a   \n",
              "\n",
              "                                              output  \n",
              "0   Paris, the center of political, economic, cul...  \n",
              "1   very large tree. It had a very wide root, lea...  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gen_t = pxt.create_table('vllm_demo/generation', {'prompt': pxt.String})\n",
        "\n",
        "gen_t.add_computed_column(\n",
        "    result=vllm.generate(\n",
        "        gen_t.prompt,\n",
        "        model='Qwen/Qwen2.5-0.5B-Instruct',\n",
        "        sampling_params={'max_tokens': 100},\n",
        "    )\n",
        ")\n",
        "\n",
        "gen_t.add_computed_column(output=gen_t.result.outputs[0].text)\n",
        "\n",
        "gen_t.insert(\n",
        "    [\n",
        "        {'prompt': 'The capital of France is'},\n",
        "        {'prompt': 'Once upon a time, there was a'},\n",
        "    ]\n",
        ")\n",
        "\n",
        "gen_t.select(gen_t.prompt, gen_t.output).collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional Resources\n",
        "\n",
        "- [Pixeltable Documentation](https://docs.pixeltable.com/)\n",
        "- [vLLM Documentation](https://docs.vllm.ai/)\n",
        "- [vLLM GitHub](https://github.com/vllm-project/vllm)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pixeltable",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
