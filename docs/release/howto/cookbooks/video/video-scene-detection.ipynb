{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect scene changes in videos\n",
    "\n",
    "Automatically find scene cuts, transitions, and fades in video files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "You have video files and need to identify scene boundaries for:\n",
    "\n",
    "| Use case | Goal |\n",
    "|----------|------|\n",
    "| Video editing | Find cut points automatically |\n",
    "| Content analysis | Segment videos into scenes |\n",
    "| Thumbnail generation | Extract one frame per scene |\n",
    "| Clip extraction | Split videos at scene boundaries |\n",
    "| Ad detection | Find commercial breaks |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "**What's in this recipe:**\n",
    "\n",
    "- Detect hard cuts with `scene_detect_content()`\n",
    "- Find fade transitions with `scene_detect_threshold()`\n",
    "- Use adaptive detection with `scene_detect_adaptive()`\n",
    "\n",
    "Three built-in detection methods handle different transition types using PySceneDetect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pixeltable scenedetect opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixeltable as pxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Pixeltable database at: postgresql+psycopg://postgres:@/pixeltable?host=/Users/pjlb/.pixeltable/pgdata\n",
      "Created directory 'scene_demo'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pixeltable.catalog.dir.Dir at 0x13f816bd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a fresh directory\n",
    "pxt.drop_dir('scene_demo', force=True)\n",
    "pxt.create_dir('scene_demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sample videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table 'videos'.\n",
      "Inserting rows into `videos`: 1 rows [00:00, 200.53 rows/s]\n",
      "Inserted 1 row with 0 errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1 row inserted, 3 values computed."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a video table\n",
    "videos = pxt.create_table(\n",
    "    'scene_demo.videos',\n",
    "    {'video': pxt.Video, 'title': pxt.String}\n",
    ")\n",
    "\n",
    "# Insert sample videos from S3\n",
    "videos.insert([\n",
    "    {\n",
    "        'video': 's3://multimedia-commons/data/videos/mp4/ffe/ffb/ffeffbef41bbc269810b2a1a888de.mp4',\n",
    "        'title': 'Sample video 1'\n",
    "    }\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect scenes with content-based detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1 column value with 0 errors.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>title</th>\n",
       "      <th>scenes_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Sample video 1</td>\n",
       "      <td>[{&quot;duration&quot;: 25.692, &quot;start_pts&quot;: 0, &quot;start_time&quot;: 0.}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "            title                                     scenes_content\n",
       "0  Sample video 1  [{'duration': 25.692333333333334, 'start_pts':..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detect scenes using content-based detection (best for hard cuts)\n",
    "videos.add_computed_column(\n",
    "    scenes_content=videos.video.scene_detect_content(\n",
    "        threshold=27.0,      # Lower = more sensitive\n",
    "        min_scene_len=15     # Minimum frames between cuts\n",
    "    )\n",
    ")\n",
    "\n",
    "# View detected scenes\n",
    "videos.select(videos.title, videos.scenes_content).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect fade transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1 column value with 0 errors.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>title</th>\n",
       "      <th>scenes_fade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Sample video 1</td>\n",
       "      <td>[{&quot;duration&quot;: 25.692, &quot;start_pts&quot;: 0, &quot;start_time&quot;: 0.}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "            title                                        scenes_fade\n",
       "0  Sample video 1  [{'duration': 25.692333333333334, 'start_pts':..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detect fade-to-black/white transitions\n",
    "videos.add_computed_column(\n",
    "    scenes_fade=videos.video.scene_detect_threshold(\n",
    "        threshold=12.0,      # Brightness threshold for fades\n",
    "        min_scene_len=15\n",
    "    )\n",
    ")\n",
    "\n",
    "# View fade-detected scenes\n",
    "videos.select(videos.title, videos.scenes_fade).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive detection for complex videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1 column value with 0 errors.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>title</th>\n",
       "      <th>scenes_adaptive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Sample video 1</td>\n",
       "      <td>[{&quot;duration&quot;: 25.526, &quot;start_pts&quot;: 0, &quot;start_time&quot;: 0.}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "            title                                    scenes_adaptive\n",
       "0  Sample video 1  [{'duration': 25.5255, 'start_pts': 0, 'start_..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adaptive detection adjusts to video content dynamically\n",
    "videos.add_computed_column(\n",
    "    scenes_adaptive=videos.video.scene_detect_adaptive(\n",
    "        adaptive_threshold=3.0,  # Lower = more scenes detected\n",
    "        min_scene_len=15,\n",
    "        fps=2.0                  # Analyze at 2 FPS for speed\n",
    "    )\n",
    ")\n",
    "\n",
    "# View adaptively-detected scenes\n",
    "videos.select(videos.title, videos.scenes_adaptive).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "**Detection methods:**\n",
    "\n",
    "| Method | Best for | Key parameter |\n",
    "|--------|----------|---------------|\n",
    "| `scene_detect_content()` | Hard cuts | `threshold` (27 default) |\n",
    "| `scene_detect_threshold()` | Fades | `threshold` (12 default) |\n",
    "| `scene_detect_adaptive()` | Mixed content | `adaptive_threshold` (3 default) |\n",
    "\n",
    "**Output format:**\n",
    "\n",
    "Each method returns a list of scene dictionaries:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'start_time': 5.2,    # Scene start in seconds\n",
    "    'start_pts': 156,     # Presentation timestamp\n",
    "    'duration': 3.8       # Scene duration in seconds\n",
    "}\n",
    "```\n",
    "\n",
    "**Tuning tips:**\n",
    "\n",
    "| Goal | Adjustment |\n",
    "|------|------------|\n",
    "| More scenes | Lower threshold values |\n",
    "| Fewer scenes | Higher threshold values |\n",
    "| Faster processing | Set `fps=1.0` or `fps=2.0` |\n",
    "| Ignore quick cuts | Increase `min_scene_len` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See also\n",
    "\n",
    "- [Extract frames from videos](https://docs.pixeltable.com/howto/cookbooks/video/video-extract-frames) - Get frames at scene boundaries\n",
    "- [Generate thumbnails](https://docs.pixeltable.com/howto/cookbooks/video/video-generate-thumbnails) - Create preview images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixeltable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
