{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data from Hugging Face datasets\n",
    "\n",
    "Load datasets from Hugging Face Hub into Pixeltable tables for processing with AI models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "You want to use a dataset from Hugging Face Hubâ€”for fine-tuning, evaluation, or analysis. You need to load it into a format where you can add computed columns, embeddings, or AI transformations.\n",
    "\n",
    "| Dataset | Size | Use case |\n",
    "|---------|------|----------|\n",
    "| imdb | 50K reviews | Sentiment analysis |\n",
    "| squad | 100K Q&A | RAG evaluation |\n",
    "| coco | 330K images | Vision model training |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "**What's in this recipe:**\n",
    "- Import Hugging Face datasets directly into tables\n",
    "- Handle datasets with multiple splits (train/test/validation)\n",
    "- Work with image datasets\n",
    "\n",
    "You use `pxt.create_table()` with a Hugging Face dataset as the `source` parameter. Pixeltable automatically maps HF types to Pixeltable column types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pixeltable datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixeltable as pxt\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fresh directory\n",
    "pxt.drop_dir('hf_demo', force=True)\n",
    "pxt.create_dir('hf_demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import a single split\n",
    "\n",
    "Load a specific split from a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a small subset for demo (first 100 rows of rotten_tomatoes)\n",
    "hf_dataset = load_dataset('rotten_tomatoes', split='train[:100]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import into Pixeltable\n",
    "reviews = pxt.create_table(\n",
    "    'hf_demo.reviews',\n",
    "    source=hf_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View imported data\n",
    "reviews.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import multiple splits\n",
    "\n",
    "Load a DatasetDict with multiple splits and track which split each row came from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with multiple splits (small subset for demo)\n",
    "hf_dataset_dict = load_dataset(\n",
    "    'rotten_tomatoes',\n",
    "    split={'train': 'train[:50]', 'test': 'test[:50]'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import each split separately for clarity\n",
    "train_data = pxt.create_table(\n",
    "    'hf_demo.reviews_train',\n",
    "    source=hf_dataset_dict['train']\n",
    ")\n",
    "test_data = pxt.create_table(\n",
    "    'hf_demo.reviews_test',\n",
    "    source=hf_dataset_dict['test']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View training data\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View test data\n",
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add AI-powered computed columns\n",
    "\n",
    "Enrich the dataset with AI models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a computed column for text length\n",
    "reviews.add_computed_column(text_length=reviews.text.apply(len, col_type=pxt.Int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View with computed column\n",
    "reviews.select(reviews.text, reviews.label, reviews.text_length).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type mapping\n",
    "\n",
    "Pixeltable automatically maps Hugging Face types to Pixeltable types:\n",
    "\n",
    "| Hugging Face Type | Pixeltable Type |\n",
    "|-------------------|-----------------|\n",
    "| `Value('string')` | `pxt.String` |\n",
    "| `Value('int64')` | `pxt.Int` |\n",
    "| `Value('float32')` | `pxt.Float` |\n",
    "| `ClassLabel` | `pxt.String` |\n",
    "| `Image` | `pxt.Image` |\n",
    "| `Sequence` | `pxt.Array` or `pxt.Json` |\n",
    "\n",
    "Use `schema_overrides` to customize type mapping when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "**Why import Hugging Face datasets into Pixeltable:**\n",
    "\n",
    "1. **Add computed columns** - Enrich data with embeddings, AI analysis, or transformations\n",
    "2. **Incremental processing** - Add new rows without reprocessing existing data\n",
    "3. **Persistent storage** - Keep processed results across sessions\n",
    "4. **Query capabilities** - Filter, aggregate, and join with other tables\n",
    "\n",
    "**Working with large datasets:**\n",
    "\n",
    "For very large datasets, consider loading in batches or using streaming mode in the `datasets` library before importing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See also\n",
    "\n",
    "- [Import CSV files](https://docs.pixeltable.com/howto/cookbooks/data/data-import-csv) - For CSV and Excel imports\n",
    "- [Semantic text search](https://docs.pixeltable.com/howto/cookbooks/search/search-semantic-text) - Add embeddings to text data\n",
    "- [Hugging Face integration notebook](https://docs.pixeltable.com/howto/providers/working-with-hugging-face) - Full integration guide"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixeltable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
