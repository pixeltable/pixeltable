{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data from Hugging Face datasets\n",
    "\n",
    "Load datasets from Hugging Face Hub into Pixeltable tables for processing with AI models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "You want to use a dataset from Hugging Face Hubâ€”for fine-tuning, evaluation, or analysis. You need to load it into a format where you can add computed columns, embeddings, or AI transformations.\n",
    "\n",
    "| Dataset | Size | Use case |\n",
    "|---------|------|----------|\n",
    "| imdb | 50K reviews | Sentiment analysis |\n",
    "| squad | 100K Q&A | RAG evaluation |\n",
    "| coco | 330K images | Vision model training |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "**What's in this recipe:**\n",
    "- Import Hugging Face datasets directly into tables\n",
    "- Handle datasets with multiple splits (train/test/validation)\n",
    "- Work with image datasets\n",
    "\n",
    "You use `pxt.create_table()` with a Hugging Face dataset as the `source` parameter. Pixeltable automatically maps HF types to Pixeltable column types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/opt/miniconda3/envs/pixeltable/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/opt/miniconda3/envs/pixeltable/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/opt/miniconda3/envs/pixeltable/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/opt/miniconda3/envs/pixeltable/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/opt/miniconda3/envs/pixeltable/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/opt/miniconda3/envs/pixeltable/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/opt/miniconda3/envs/pixeltable/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/opt/miniconda3/envs/pixeltable/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU pixeltable datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/pixeltable/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pixeltable as pxt\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Pixeltable database at: postgresql+psycopg://postgres:@/pixeltable?host=/Users/pjlb/.pixeltable/pgdata\n",
      "Created directory 'hf_demo'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pixeltable.catalog.dir.Dir at 0x3162f4150>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a fresh directory\n",
    "pxt.drop_dir('hf_demo', force=True)\n",
    "pxt.create_dir('hf_demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import a single split\n",
    "\n",
    "Load a specific split from a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a small subset for demo (first 100 rows of rotten_tomatoes)\n",
    "hf_dataset = load_dataset('rotten_tomatoes', split='train[:100]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table 'reviews'.\n",
      "Inserting rows into `reviews`: 100 rows [00:00, 13303.43 rows/s]\n",
      "Inserted 100 rows with 0 errors.\n"
     ]
    }
   ],
   "source": [
    "# Import into Pixeltable\n",
    "reviews = pxt.create_table(\n",
    "    'hf_demo.reviews',\n",
    "    source=hf_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>the rock is destined to be the 21st century&#x27;s new &quot; conan &quot; and that he&#x27;s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>the gorgeously elaborate continuation of &quot; the lord of the rings &quot; trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson&#x27;s expanded vision of j . r . r . tolkien&#x27;s middle-earth .</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>if you sometimes like to go to the movies to have fun , wasabi is a good place to start .</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>emerges as something rare , an issue movie that&#x27;s so honest and keenly observed that it doesn&#x27;t feel like one .</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  the rock is destined to be the 21st century's ...   pos\n",
       "1  the gorgeously elaborate continuation of \" the...   pos\n",
       "2                     effective but too-tepid biopic   pos\n",
       "3  if you sometimes like to go to the movies to h...   pos\n",
       "4  emerges as something rare , an issue movie tha...   pos"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View imported data\n",
    "reviews.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import multiple splits\n",
    "\n",
    "Load a DatasetDict with multiple splits and track which split each row came from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with multiple splits (small subset for demo)\n",
    "hf_dataset_dict = load_dataset(\n",
    "    'rotten_tomatoes',\n",
    "    split={'train': 'train[:50]', 'test': 'test[:50]'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table 'reviews_train'.\n",
      "Inserting rows into `reviews_train`: 50 rows [00:00, 11806.29 rows/s]\n",
      "Inserted 50 rows with 0 errors.\n",
      "Created table 'reviews_test'.\n",
      "Inserting rows into `reviews_test`: 50 rows [00:00, 11534.22 rows/s]\n",
      "Inserted 50 rows with 0 errors.\n"
     ]
    }
   ],
   "source": [
    "# Import each split separately for clarity\n",
    "train_data = pxt.create_table(\n",
    "    'hf_demo.reviews_train',\n",
    "    source=hf_dataset_dict['train']\n",
    ")\n",
    "test_data = pxt.create_table(\n",
    "    'hf_demo.reviews_test',\n",
    "    source=hf_dataset_dict['test']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>the rock is destined to be the 21st century&#x27;s new &quot; conan &quot; and that he&#x27;s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>the gorgeously elaborate continuation of &quot; the lord of the rings &quot; trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson&#x27;s expanded vision of j . r . r . tolkien&#x27;s middle-earth .</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>if you sometimes like to go to the movies to have fun , wasabi is a good place to start .</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>emerges as something rare , an issue movie that&#x27;s so honest and keenly observed that it doesn&#x27;t feel like one .</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  the rock is destined to be the 21st century's ...   pos\n",
       "1  the gorgeously elaborate continuation of \" the...   pos\n",
       "2                     effective but too-tepid biopic   pos\n",
       "3  if you sometimes like to go to the movies to h...   pos\n",
       "4  emerges as something rare , an issue movie tha...   pos"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View training data\n",
    "print(\"Training data:\")\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>consistently clever and suspenseful .</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>it&#x27;s like a &quot; big chill &quot; reunion of the baader-meinhof gang , only these guys are more harmless pranksters than political activists .</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  lovingly photographed in the manner of a golde...   pos\n",
       "1              consistently clever and suspenseful .   pos\n",
       "2  it's like a \" big chill \" reunion of the baade...   pos"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View test data\n",
    "print(\"Test data:\")\n",
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add AI-powered computed columns\n",
    "\n",
    "Enrich the dataset with AI models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Column type of `len` cannot be inferred. Use `.apply(len, col_type=...)` to specify.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Add a computed column for text length\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m reviews\u001b[38;5;241m.\u001b[39madd_computed_column(text_length\u001b[38;5;241m=\u001b[39m\u001b[43mreviews\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pixeltable/lib/python3.11/site-packages/pixeltable/exprs/expr.py:588\u001b[0m, in \u001b[0;36mExpr.apply\u001b[0;34m(self, fn, col_type)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m col_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    587\u001b[0m     col_type \u001b[38;5;241m=\u001b[39m ts\u001b[38;5;241m.\u001b[39mColumnType\u001b[38;5;241m.\u001b[39mnormalize_type(col_type)\n\u001b[0;32m--> 588\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_applicator_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;66;03m# Return a `FunctionCall` obtained by passing this `Expr` to the new `function`.\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pixeltable/lib/python3.11/site-packages/pixeltable/exprs/expr.py:842\u001b[0m, in \u001b[0;36mExpr._make_applicator_function\u001b[0;34m(self, fn, col_type)\u001b[0m\n\u001b[1;32m    839\u001b[0m     fn_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m excs\u001b[38;5;241m.\u001b[39mError(\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn type of `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` cannot be inferred. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    844\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse `.apply(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, col_type=...)` to specify.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    845\u001b[0m     )\n\u001b[1;32m    847\u001b[0m \u001b[38;5;66;03m# TODO(aaron-siegel) Currently we assume that `fn` has exactly one required parameter\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;66;03m# and all optional parameters take their default values. Should we provide a more\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;66;03m# flexible API? For example, by defining\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;66;03m# In the current implementation, a lambda is needed in order to specify this pattern:\u001b[39;00m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;66;03m# expr.apply(lambda x: fn(x, my_kw=my_arg))\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;66;03m# If `fn` is not a builtin, we can do some basic validation to ensure it's\u001b[39;00m\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;66;03m# compatible with `apply`.\u001b[39;00m\n",
      "\u001b[0;31mError\u001b[0m: Column type of `len` cannot be inferred. Use `.apply(len, col_type=...)` to specify."
     ]
    }
   ],
   "source": [
    "# Add a computed column for text length\n",
    "reviews.add_computed_column(text_length=reviews.text.apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View with computed column\n",
    "reviews.select(reviews.text, reviews.label, reviews.text_length).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type mapping\n",
    "\n",
    "Pixeltable automatically maps Hugging Face types to Pixeltable types:\n",
    "\n",
    "| Hugging Face Type | Pixeltable Type |\n",
    "|-------------------|-----------------|\n",
    "| `Value('string')` | `pxt.String` |\n",
    "| `Value('int64')` | `pxt.Int` |\n",
    "| `Value('float32')` | `pxt.Float` |\n",
    "| `ClassLabel` | `pxt.String` |\n",
    "| `Image` | `pxt.Image` |\n",
    "| `Sequence` | `pxt.Array` or `pxt.Json` |\n",
    "\n",
    "Use `schema_overrides` to customize type mapping when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "**Why import Hugging Face datasets into Pixeltable:**\n",
    "\n",
    "1. **Add computed columns** - Enrich data with embeddings, AI analysis, or transformations\n",
    "2. **Incremental processing** - Add new rows without reprocessing existing data\n",
    "3. **Persistent storage** - Keep processed results across sessions\n",
    "4. **Query capabilities** - Filter, aggregate, and join with other tables\n",
    "\n",
    "**Working with large datasets:**\n",
    "\n",
    "For very large datasets, consider loading in batches or using streaming mode in the `datasets` library before importing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See also\n",
    "\n",
    "- [Import CSV files](https://docs.pixeltable.com/howto/cookbooks/data/data-import-csv) - For CSV and Excel imports\n",
    "- [Semantic text search](https://docs.pixeltable.com/howto/cookbooks/search/search-semantic-text) - Add embeddings to text data\n",
    "- [Hugging Face integration notebook](https://docs.pixeltable.com/howto/providers/working-with-hugging-face) - Full integration guide"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixeltable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
