{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build an agent with memory\n",
    "\n",
    "Create an AI agent that remembers important information across conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "You want to build an AI agent that can store and recall important information—user preferences, key facts, or context from previous conversations.\n",
    "\n",
    "| Memory type | Example |\n",
    "|-------------|---------|\n",
    "| User preferences | \"I prefer Python over JavaScript\" |\n",
    "| Key facts | \"The project deadline is March 15\" |\n",
    "| Conversation context | \"We discussed the budget yesterday\" |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "**What's in this recipe:**\n",
    "- Store memories with embeddings for semantic search\n",
    "- Retrieve relevant memories based on conversation context\n",
    "- Use `@pxt.query` for retrieval functions\n",
    "\n",
    "This pattern is inspired by [Pixelbot](https://github.com/pixeltable/pixelbot) and [Pixelmemory](https://github.com/pixeltable/pixelmemory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pixeltable openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from datetime import datetime\n",
    "\n",
    "if 'OPENAI_API_KEY' not in os.environ:\n",
    "    os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixeltable as pxt\n",
    "from pixeltable.functions.openai import embeddings, chat_completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fresh directory\n",
    "pxt.drop_dir('agent_demo', force=True)\n",
    "pxt.create_dir('agent_demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create memory bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create memory bank table\n",
    "memories = pxt.create_table(\n",
    "    'agent_demo.memories',\n",
    "    {\n",
    "        'content': pxt.String,           # The memory content\n",
    "        'category': pxt.String,          # Optional category (preference, fact, etc.)\n",
    "        'created_at': pxt.Timestamp,     # When the memory was stored\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add embedding for semantic search\n",
    "memories.add_computed_column(\n",
    "    embedding=embeddings(memories.content, model='text-embedding-3-small')\n",
    ")\n",
    "\n",
    "# Create index for fast retrieval\n",
    "memories.add_embedding_index('embedding', metric='cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define retrieval function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query function to retrieve relevant memories\n",
    "@pxt.query\n",
    "def recall_memories(context: str, top_k: int = 3) -> list[dict]:\n",
    "    \"\"\"Retrieve memories relevant to the current context.\"\"\"\n",
    "    results = memories.order_by(\n",
    "        memories.embedding.similarity(context),\n",
    "        asc=False\n",
    "    ).limit(top_k).select(\n",
    "        memories.content,\n",
    "        memories.category\n",
    "    ).collect()\n",
    "    return [{'content': r['content'], 'category': r['category']} for r in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store some memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store some initial memories\n",
    "initial_memories = [\n",
    "    {'content': 'User prefers Python for data analysis', 'category': 'preference', 'created_at': datetime.now()},\n",
    "    {'content': 'The project deadline is March 15, 2024', 'category': 'fact', 'created_at': datetime.now()},\n",
    "    {'content': 'User works at a startup in San Francisco', 'category': 'fact', 'created_at': datetime.now()},\n",
    "    {'content': 'Budget for the ML project is $50,000', 'category': 'fact', 'created_at': datetime.now()},\n",
    "    {'content': 'User prefers concise explanations over detailed ones', 'category': 'preference', 'created_at': datetime.now()},\n",
    "]\n",
    "\n",
    "memories.insert(initial_memories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create conversation table with memory retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create conversation table\n",
    "conversations = pxt.create_table(\n",
    "    'agent_demo.conversations',\n",
    "    {'user_message': pxt.String}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add memory retrieval step\n",
    "conversations.add_computed_column(\n",
    "    relevant_memories=recall_memories(conversations.user_message, top_k=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prompt with memories\n",
    "@pxt.udf\n",
    "def build_memory_prompt(user_message: str, relevant_memories: list[dict]) -> str:\n",
    "    memory_text = '\\n'.join([f\"- {m['content']}\" for m in relevant_memories])\n",
    "    return f\"\"\"You are a helpful assistant with access to the following memories about the user:\n",
    "\n",
    "{memory_text}\n",
    "\n",
    "Use these memories to personalize your response when relevant.\n",
    "\n",
    "User: {user_message}\n",
    "Assistant:\"\"\"\n",
    "\n",
    "conversations.add_computed_column(\n",
    "    prompt=build_memory_prompt(conversations.user_message, conversations.relevant_memories)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate response with memory context\n",
    "conversations.add_computed_column(\n",
    "    response=chat_completions(\n",
    "        messages=[{'role': 'user', 'content': conversations.prompt}],\n",
    "        model='gpt-4o-mini'\n",
    "    )\n",
    ")\n",
    "conversations.add_computed_column(\n",
    "    assistant_reply=conversations.response.choices[0].message.content\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat with memory-aware agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the memory-aware agent\n",
    "test_messages = [\n",
    "    {'user_message': 'What programming language should I use for this project?'},\n",
    "    {'user_message': 'When do I need to finish this?'},\n",
    "    {'user_message': 'How much can I spend on cloud resources?'},\n",
    "]\n",
    "\n",
    "conversations.insert(test_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View conversations with memory\n",
    "conversations.select(\n",
    "    conversations.user_message,\n",
    "    conversations.relevant_memories,\n",
    "    conversations.assistant_reply\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "**Memory-aware agent architecture:**\n",
    "\n",
    "```\n",
    "User Message → Retrieve Memories → Build Prompt → LLM Response\n",
    "                    ↓\n",
    "            Memory Bank (with embeddings)\n",
    "```\n",
    "\n",
    "**Key components:**\n",
    "\n",
    "| Component | Purpose |\n",
    "|-----------|---------|\n",
    "| Memory table | Store facts, preferences, context |\n",
    "| Embedding index | Enable semantic memory search |\n",
    "| `@pxt.query` | Retrieval function for memories |\n",
    "| Prompt builder | Inject memories into LLM context |\n",
    "\n",
    "**Adding new memories:**\n",
    "\n",
    "```python\n",
    "memories.insert([{\n",
    "    'content': 'New information to remember',\n",
    "    'category': 'fact',\n",
    "    'created_at': datetime.now()\n",
    "}])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See also\n",
    "\n",
    "- [Build a RAG pipeline](https://docs.pixeltable.com/howto/cookbooks/agents/pattern-rag-pipeline) - Document retrieval\n",
    "- [Use tool calling](https://docs.pixeltable.com/howto/cookbooks/agents/llm-tool-calling) - Function calling with LLMs\n",
    "- [Pixelbot](https://github.com/pixeltable/pixelbot) - Full agent implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixeltable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
