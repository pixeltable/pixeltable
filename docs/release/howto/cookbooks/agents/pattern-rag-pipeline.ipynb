{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Build a RAG pipeline\n",
        "\n",
        "Create a retrieval-augmented generation system that answers questions using your documents as context.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem\n",
        "\n",
        "You want an LLM to answer questions using your specific documents\u2014not just its training data. You need to retrieve relevant context and include it in the prompt.\n",
        "\n",
        "| Use case | Documents | Questions |\n",
        "|----------|-----------|-----------|\n",
        "| Customer support | Help articles | \"How do I reset my password?\" |\n",
        "| Internal wiki | Company docs | \"What's our vacation policy?\" |\n",
        "| Research | Papers | \"What did the study find about X?\" |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solution\n",
        "\n",
        "**What's in this recipe:**\n",
        "- Embed and index documents for retrieval\n",
        "- Create a query function that retrieves context\n",
        "- Generate answers grounded in your documents\n",
        "\n",
        "You build a pipeline that: (1) embeds documents, (2) finds relevant chunks for a query, and (3) generates an answer using those chunks as context.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU pixeltable openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "if 'OPENAI_API_KEY' not in os.environ:\n",
        "    os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key: ')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pixeltable as pxt\n",
        "from pixeltable.functions.openai import embeddings, chat_completions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a fresh directory\n",
        "pxt.drop_dir('rag_demo', force=True)\n",
        "pxt.create_dir('rag_demo')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Create document store with embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create table for document chunks\n",
        "chunks = pxt.create_table(\n",
        "    'rag_demo.chunks',\n",
        "    {'doc_id': pxt.String, 'chunk_text': pxt.String}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add embedding column\n",
        "chunks.add_computed_column(\n",
        "    embedding=embeddings(chunks.chunk_text, model='text-embedding-3-small')\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create embedding index for fast retrieval\n",
        "chunks.add_embedding_index('embedding', metric='cosine')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Load documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample knowledge base (in production, load from files/database)\n",
        "documents = [\n",
        "    {\n",
        "        'doc_id': 'password-reset',\n",
        "        'chunk_text': 'To reset your password, go to the login page and click \"Forgot Password\". Enter your email address and you will receive a reset link within 5 minutes. The link expires after 24 hours.'\n",
        "    },\n",
        "    {\n",
        "        'doc_id': 'password-reset',\n",
        "        'chunk_text': 'Password requirements: minimum 8 characters, at least one uppercase letter, one number, and one special character. Passwords expire every 90 days for security.'\n",
        "    },\n",
        "    {\n",
        "        'doc_id': 'account-settings',\n",
        "        'chunk_text': 'To update your profile, navigate to Settings > Account. You can change your display name, email address, and notification preferences. Changes take effect immediately.'\n",
        "    },\n",
        "    {\n",
        "        'doc_id': 'billing',\n",
        "        'chunk_text': 'Billing occurs on the first of each month. You can view invoices under Settings > Billing. To change your payment method, click \"Update Payment\" and enter your new card details.'\n",
        "    },\n",
        "    {\n",
        "        'doc_id': 'api-access',\n",
        "        'chunk_text': 'API keys can be generated in Settings > Developer. Each key has configurable permissions. Rate limits are 1000 requests per minute for standard plans, 10000 for enterprise.'\n",
        "    },\n",
        "]\n",
        "\n",
        "chunks.insert(documents)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Create the RAG query function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a query function that retrieves context and generates answer\n",
        "@pxt.query\n",
        "def retrieve_context(query: str, top_k: int = 3) -> list[dict]:\n",
        "    \"\"\"Retrieve the most relevant chunks for a query.\"\"\"\n",
        "    results = chunks.order_by(\n",
        "        chunks.embedding.similarity(query),\n",
        "        asc=False\n",
        "    ).limit(top_k).select(chunks.doc_id, chunks.chunk_text).collect()\n",
        "    return [{'doc_id': r['doc_id'], 'text': r['chunk_text']} for r in results]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test retrieval\n",
        "query = \"How do I reset my password?\"\n",
        "context_chunks = retrieve_context(query)\n",
        "\n",
        "print(f\"Query: {query}\\n\")\n",
        "print(\"Retrieved context:\")\n",
        "for i, chunk in enumerate(context_chunks, 1):\n",
        "    print(f\"  {i}. [{chunk['doc_id']}] {chunk['text'][:80]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Generate answers with context\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a table for questions/answers\n",
        "qa = pxt.create_table(\n",
        "    'rag_demo.qa',\n",
        "    {'question': pxt.String}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add retrieval step\n",
        "qa.add_computed_column(context=retrieve_context(qa.question, top_k=3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the RAG prompt\n",
        "@pxt.udf\n",
        "def build_rag_prompt(question: str, context: list[dict]) -> str:\n",
        "    context_text = '\\n\\n'.join([f\"[{c['doc_id']}]: {c['text']}\" for c in context])\n",
        "    return f\"\"\"Answer the question based only on the provided context. If the context doesn't contain the answer, say \"I don't have information about that.\"\n",
        "\n",
        "Context:\n",
        "{context_text}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "qa.add_computed_column(prompt=build_rag_prompt(qa.question, qa.context))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate answer\n",
        "qa.add_computed_column(\n",
        "    response=chat_completions(\n",
        "        messages=[{'role': 'user', 'content': qa.prompt}],\n",
        "        model='gpt-4o-mini'\n",
        "    )\n",
        ")\n",
        "qa.add_computed_column(answer=qa.response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ask questions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insert questions\n",
        "questions = [\n",
        "    {'question': 'How do I reset my password?'},\n",
        "    {'question': 'What are the API rate limits?'},\n",
        "    {'question': 'When am I billed?'},\n",
        "]\n",
        "\n",
        "qa.insert(questions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View answers\n",
        "for row in qa.select(qa.question, qa.answer).collect():\n",
        "    print(f\"Q: {row['question']}\")\n",
        "    print(f\"A: {row['answer']}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explanation\n",
        "\n",
        "**RAG pipeline flow:**\n",
        "\n",
        "```\n",
        "Question \u2192 Embed \u2192 Retrieve similar chunks \u2192 Build prompt with context \u2192 Generate answer\n",
        "```\n",
        "\n",
        "**Key components:**\n",
        "\n",
        "| Component | Purpose |\n",
        "|-----------|---------|\n",
        "| Embedding index | Fast similarity search |\n",
        "| `@pxt.query` | Retrieve context from the database |\n",
        "| `@pxt.udf` | Build the augmented prompt |\n",
        "| Computed columns | Chain the pipeline together |\n",
        "\n",
        "**Scaling tips:**\n",
        "\n",
        "- Use `doc-chunk-for-rag` recipe to split long documents\n",
        "- Adjust `top_k` to balance context size vs. relevance\n",
        "- Consider metadata filtering for large knowledge bases\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## See also\n",
        "\n",
        "- [Chunk documents for RAG](https://docs.pixeltable.com/howto/cookbooks/text/doc-chunk-for-rag) - Split documents into chunks\n",
        "- [Create text embeddings](https://docs.pixeltable.com/howto/cookbooks/search/embed-text-openai) - Embedding fundamentals\n",
        "- [Semantic text search](https://docs.pixeltable.com/howto/cookbooks/search/search-semantic-text) - Search patterns\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}