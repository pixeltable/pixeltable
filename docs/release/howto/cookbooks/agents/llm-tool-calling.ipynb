{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use tool calling with LLMs\n",
    "\n",
    "Enable LLMs to call functions and tools, then execute the results automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "You want an LLM to decide which functions to call based on user queries—for agents, chatbots, or automated workflows.\n",
    "\n",
    "| Use case | Tools needed |\n",
    "|----------|--------------|\n",
    "| Data assistant | `get_data`, `run_query` |\n",
    "| Customer support | `lookup_order`, `check_status` |\n",
    "| Research agent | `search_web`, `fetch_article` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "**What's in this recipe:**\n",
    "- Define tools as Python functions\n",
    "- Let LLMs decide which tool to call\n",
    "- Automatically execute tool calls with `invoke_tools`\n",
    "\n",
    "You define tools with JSON schemas, pass them to the LLM, and use `invoke_tools` to execute the function calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pixeltable openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "if 'OPENAI_API_KEY' not in os.environ:\n",
    "    os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixeltable as pxt\n",
    "from pixeltable.functions import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fresh directory\n",
    "pxt.drop_dir('tools_demo', force=True)\n",
    "pxt.create_dir('tools_demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define tools as UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tool functions as Pixeltable UDFs\n",
    "@pxt.udf\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the current weather for a city.\"\"\"\n",
    "    # In production, call a real weather API\n",
    "    weather_data = {\n",
    "        'new york': 'Sunny, 72°F',\n",
    "        'london': 'Cloudy, 58°F',\n",
    "        'tokyo': 'Rainy, 65°F',\n",
    "        'paris': 'Partly cloudy, 68°F',\n",
    "    }\n",
    "    return weather_data.get(city.lower(), f'Weather data not available for {city}')\n",
    "\n",
    "@pxt.udf\n",
    "def get_stock_price(symbol: str) -> str:\n",
    "    \"\"\"Get the current stock price for a symbol.\"\"\"\n",
    "    # In production, call a real stock API\n",
    "    prices = {\n",
    "        'AAPL': '$178.50',\n",
    "        'GOOGL': '$141.25',\n",
    "        'MSFT': '$378.90',\n",
    "        'AMZN': '$185.30',\n",
    "    }\n",
    "    return prices.get(symbol.upper(), f'Price not available for {symbol}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Tools object with our functions\n",
    "tools = pxt.tools(get_weather, get_stock_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tool-calling pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table for queries\n",
    "queries = pxt.create_table(\n",
    "    'tools_demo.queries',\n",
    "    {'query': pxt.String}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add LLM call with tools\n",
    "queries.add_computed_column(\n",
    "    response=openai.chat_completions(\n",
    "        messages=[{'role': 'user', 'content': queries.query}],\n",
    "        model='gpt-4o-mini',\n",
    "        tools=tools  # Pass tools to the LLM\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically execute tool calls and get results\n",
    "queries.add_computed_column(\n",
    "    tool_results=openai.invoke_tools(tools, queries.response)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run tool-enabled queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert queries that require tool calls\n",
    "sample_queries = [\n",
    "    {'query': \"What's the weather in Tokyo?\"},\n",
    "    {'query': \"What's the stock price of Apple?\"},\n",
    "    {'query': \"What's the weather in Paris and the price of Microsoft stock?\"},\n",
    "]\n",
    "\n",
    "queries.insert(sample_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results\n",
    "for row in queries.select(queries.query, queries.tool_results).collect():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "**Tool calling flow:**\n",
    "\n",
    "```\n",
    "Query → LLM decides tool → invoke_tools executes → Results\n",
    "```\n",
    "\n",
    "**Key components:**\n",
    "\n",
    "| Component | Purpose |\n",
    "|-----------|---------|\n",
    "| `@pxt.udf` | Define tool functions |\n",
    "| `pxt.tools()` | Bundle functions into Tools object |\n",
    "| `tools=` parameter | Pass tools to LLM |\n",
    "| `invoke_tools()` | Execute tool calls from LLM response |\n",
    "\n",
    "**Supported providers:**\n",
    "\n",
    "| Provider | Function |\n",
    "|----------|----------|\n",
    "| OpenAI | `openai.invoke_tools()` |\n",
    "| Anthropic | `anthropic.invoke_tools()` |\n",
    "| Groq | `groq.invoke_tools()` |\n",
    "| Gemini | `gemini.invoke_tools()` |\n",
    "| Bedrock | `bedrock.invoke_tools()` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See also\n",
    "\n",
    "- [Build a RAG pipeline](https://docs.pixeltable.com/howto/cookbooks/agents/pattern-rag-pipeline) - Retrieval-augmented generation\n",
    "- [Run local LLMs](https://docs.pixeltable.com/howto/providers/working-with-ollama) - Local model inference"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
