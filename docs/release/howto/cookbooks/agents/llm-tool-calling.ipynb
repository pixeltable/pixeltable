{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use tool calling with LLMs\n",
    "\n",
    "Enable LLMs to call functions and tools, then execute the results automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "You want an LLM to decide which functions to call based on user queries—for agents, chatbots, or automated workflows.\n",
    "\n",
    "| Use case | Tools needed |\n",
    "|----------|--------------|\n",
    "| Data assistant | `get_data`, `run_query` |\n",
    "| Customer support | `lookup_order`, `check_status` |\n",
    "| Research agent | `search_web`, `fetch_article` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "**What's in this recipe:**\n",
    "\n",
    "- Define tools as Python functions\n",
    "- Let LLMs decide which tool to call\n",
    "- Automatically execute tool calls with `invoke_tools`\n",
    "\n",
    "You define tools with JSON schemas, pass them to the LLM, and use `invoke_tools` to execute the function calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pixeltable openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "if 'OPENAI_API_KEY' not in os.environ:\n",
    "    os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixeltable as pxt\n",
    "from pixeltable.functions import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Pixeltable database at: postgresql+psycopg://postgres:@/pixeltable?host=/Users/pjlb/.pixeltable/pgdata\n",
      "Created directory 'tools_demo'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pixeltable.catalog.dir.Dir at 0x17de70850>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a fresh directory\n",
    "pxt.drop_dir('tools_demo', force=True)\n",
    "pxt.create_dir('tools_demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define tools as UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tool functions as Pixeltable UDFs\n",
    "@pxt.udf\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the current weather for a city.\"\"\"\n",
    "    # In production, call a real weather API\n",
    "    weather_data = {\n",
    "        'new york': 'Sunny, 72°F',\n",
    "        'london': 'Cloudy, 58°F',\n",
    "        'tokyo': 'Rainy, 65°F',\n",
    "        'paris': 'Partly cloudy, 68°F',\n",
    "    }\n",
    "    return weather_data.get(city.lower(), f'Weather data not available for {city}')\n",
    "\n",
    "@pxt.udf\n",
    "def get_stock_price(symbol: str) -> str:\n",
    "    \"\"\"Get the current stock price for a symbol.\"\"\"\n",
    "    # In production, call a real stock API\n",
    "    prices = {\n",
    "        'AAPL': '$178.50',\n",
    "        'GOOGL': '$141.25',\n",
    "        'MSFT': '$378.90',\n",
    "        'AMZN': '$185.30',\n",
    "    }\n",
    "    return prices.get(symbol.upper(), f'Price not available for {symbol}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Tools object with our functions\n",
    "tools = pxt.tools(get_weather, get_stock_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tool-calling pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table 'queries'.\n"
     ]
    }
   ],
   "source": [
    "# Create table for queries\n",
    "queries = pxt.create_table(\n",
    "    'tools_demo.queries',\n",
    "    {'query': pxt.String}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 0 column values with 0 errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "No rows affected."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add LLM call with tools\n",
    "queries.add_computed_column(\n",
    "    response=openai.chat_completions(\n",
    "        messages=[{'role': 'user', 'content': queries.query}],\n",
    "        model='gpt-4o-mini',\n",
    "        tools=tools  # Pass tools to the LLM\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 0 column values with 0 errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "No rows affected."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automatically execute tool calls and get results\n",
    "queries.add_computed_column(\n",
    "    tool_results=openai.invoke_tools(tools, queries.response)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run tool-enabled queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting rows into `queries`: 3 rows [00:00, 330.87 rows/s]\n",
      "Inserted 3 rows with 0 errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3 rows inserted, 9 values computed."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert queries that require tool calls\n",
    "sample_queries = [\n",
    "    {'query': \"What's the weather in Tokyo?\"},\n",
    "    {'query': \"What's the stock price of Apple?\"},\n",
    "    {'query': \"What's the weather in Paris and the price of Microsoft stock?\"},\n",
    "]\n",
    "\n",
    "queries.insert(sample_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>query</th>\n",
       "      <th>tool_results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>What&#x27;s the weather in Tokyo?</td>\n",
       "      <td>{&quot;get_weather&quot;: [&quot;Rainy, 65\\u00b0F&quot;], &quot;get_stock_price&quot;: null}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>What&#x27;s the stock price of Apple?</td>\n",
       "      <td>{&quot;get_weather&quot;: null, &quot;get_stock_price&quot;: [&quot;\\$178.50&quot;]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>What&#x27;s the weather in Paris and the price of Microsoft stock?</td>\n",
       "      <td>{&quot;get_weather&quot;: [&quot;Partly cloudy, 68\\u00b0F&quot;], &quot;get_stock_price&quot;: [&quot;\\$378.90&quot;]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0                       What's the weather in Tokyo?   \n",
       "1                   What's the stock price of Apple?   \n",
       "2  What's the weather in Paris and the price of M...   \n",
       "\n",
       "                                        tool_results  \n",
       "0  {'get_weather': ['Rainy, 65°F'], 'get_stock_pr...  \n",
       "1  {'get_weather': None, 'get_stock_price': ['$17...  \n",
       "2  {'get_weather': ['Partly cloudy, 68°F'], 'get_...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View results\n",
    "queries.select(queries.query, queries.tool_results).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "**Tool calling flow:**\n",
    "\n",
    "```\n",
    "Query → LLM decides tool → invoke_tools executes → Results\n",
    "```\n",
    "\n",
    "**Key components:**\n",
    "\n",
    "| Component | Purpose |\n",
    "|-----------|---------|\n",
    "| `@pxt.udf` | Define tool functions |\n",
    "| `pxt.tools()` | Bundle functions into Tools object |\n",
    "| `tools=` parameter | Pass tools to LLM |\n",
    "| `invoke_tools()` | Execute tool calls from LLM response |\n",
    "\n",
    "**Supported providers:**\n",
    "\n",
    "| Provider | Function |\n",
    "|----------|----------|\n",
    "| OpenAI | `openai.invoke_tools()` |\n",
    "| Anthropic | `anthropic.invoke_tools()` |\n",
    "| Groq | `groq.invoke_tools()` |\n",
    "| Gemini | `gemini.invoke_tools()` |\n",
    "| Bedrock | `bedrock.invoke_tools()` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See also\n",
    "\n",
    "- [Build a RAG pipeline](https://docs.pixeltable.com/howto/cookbooks/agents/pattern-rag-pipeline) - Retrieval-augmented generation\n",
    "- [Run local LLMs](https://docs.pixeltable.com/howto/providers/working-with-ollama) - Local model inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixeltable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}