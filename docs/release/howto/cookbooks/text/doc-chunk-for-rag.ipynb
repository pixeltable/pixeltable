{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split documents into chunks for RAG\n",
    "\n",
    "Break PDFs and documents into searchable chunks for retrieval-augmented generation (RAG) pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "You have PDF documents or text files that you want to use for retrieval-augmented generation (RAG). Before you can search them, you need to:\n",
    "\n",
    "1. Split documents into smaller chunks\n",
    "2. Generate embeddings for each chunk\n",
    "3. Store everything in a searchable index\n",
    "\n",
    "| Document | Size | Chunks needed |\n",
    "|----------|------|---------------|\n",
    "| annual_report.pdf | 50 pages | ~100 chunks |\n",
    "| user_manual.pdf | 20 pages | ~40 chunks |\n",
    "| research_paper.pdf | 10 pages | ~20 chunks |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "**What's in this recipe:**\n",
    "- Split PDFs into paragraphs or sentences\n",
    "- Control chunk size with token limits\n",
    "- Add embeddings for semantic search\n",
    "\n",
    "You create a view with a DocumentSplitter iterator that automatically breaks documents into chunks. Then you add an embedding index for semantic search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pixeltable sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixeltable as pxt\n",
    "from pixeltable.iterators import DocumentSplitter\n",
    "from pixeltable.functions.huggingface import sentence_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fresh directory\n",
    "pxt.drop_dir('rag_demo', force=True)\n",
    "pxt.create_dir('rag_demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table for documents\n",
    "docs = pxt.create_table('rag_demo.documents', {'document': pxt.Document})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a sample PDF\n",
    "docs.insert([\n",
    "    {'document': 'https://raw.githubusercontent.com/pixeltable/pixeltable/main/docs/resources/rag-demo/Argus-Market-Digest-June-2024.pdf'}\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into chunks\n",
    "\n",
    "Create a view that splits each document into paragraphs with a token limit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a view that splits documents into chunks\n",
    "chunks = pxt.create_view(\n",
    "    'rag_demo.chunks',\n",
    "    docs,\n",
    "    iterator=DocumentSplitter.create(\n",
    "        document=docs.document,\n",
    "        separators='paragraph,token_limit',  # Split by paragraph with token limit\n",
    "        limit=300  # Max 300 tokens per chunk\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the chunks\n",
    "chunks.select(chunks.text).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add semantic search\n",
    "\n",
    "Create an embedding index on the chunks for similarity search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add embedding index for semantic search\n",
    "chunks.add_embedding_index(\n",
    "    column='text',\n",
    "    embed=sentence_transformer.using(model_id='all-MiniLM-L6-v2')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search your documents\n",
    "\n",
    "Use similarity search to find relevant chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for relevant chunks\n",
    "query = \"market trends\"\n",
    "sim = chunks.text.similarity(query)\n",
    "\n",
    "results = (\n",
    "    chunks\n",
    "    .order_by(sim, asc=False)\n",
    "    .select(chunks.text, score=sim)\n",
    "    .limit(3)\n",
    ")\n",
    "results.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "**Separator options:**\n",
    "\n",
    "| Separator | Description |\n",
    "|-----------|-------------|\n",
    "| `paragraph` | Split on paragraph breaks |\n",
    "| `sentence` | Split on sentence boundaries |\n",
    "| `heading` | Split on document headings |\n",
    "| `page` | Split on page breaks |\n",
    "| `token_limit` | Split at token count only |\n",
    "\n",
    "You can combine separators: `separators='paragraph,token_limit'`\n",
    "\n",
    "**Chunk sizing:**\n",
    "\n",
    "- `limit`: Maximum tokens per chunk (default: 500)\n",
    "- `overlap`: Tokens to overlap between chunks (default: 0)\n",
    "\n",
    "**New documents are processed automatically:**\n",
    "\n",
    "When you insert new documents, chunks and embeddings are generated without extra code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See also\n",
    "\n",
    "- [Iterators documentation](https://docs.pixeltable.com/platform/iterators)\n",
    "- [RAG demo notebook](https://docs.pixeltable.com/howto/use-cases/rag-demo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixeltable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
