{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extract named entities from text\n",
        "\n",
        "Identify and extract people, organizations, locations, dates, and other entities from text using LLMs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem\n",
        "\n",
        "You have unstructured text containing important information\u2014names, companies, dates, locations\u2014that you need to extract and structure for analysis, search, or integration with other systems.\n",
        "\n",
        "| Source | Extract |\n",
        "|--------|---------|\n",
        "| News articles | People, organizations, locations mentioned |\n",
        "| Customer feedback | Product names, feature requests |\n",
        "| Legal documents | Parties, dates, monetary amounts |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solution\n",
        "\n",
        "**What's in this recipe:**\n",
        "- Extract entities as structured JSON\n",
        "- Use OpenAI's structured output for reliable parsing\n",
        "- Access extracted entities as queryable columns\n",
        "\n",
        "You use structured output to get entities in a consistent JSON format. The entities are stored as JSON columns that you can query and filter.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU pixeltable openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "if 'OPENAI_API_KEY' not in os.environ:\n",
        "    os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key: ')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pixeltable as pxt\n",
        "from pixeltable.functions.openai import chat_completions\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a fresh directory\n",
        "pxt.drop_dir('entities_demo', force=True)\n",
        "pxt.create_dir('entities_demo')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define entity extraction schema\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the JSON schema for entity extraction\n",
        "entity_schema = {\n",
        "    \"type\": \"json_schema\",\n",
        "    \"json_schema\": {\n",
        "        \"name\": \"entities\",\n",
        "        \"strict\": True,\n",
        "        \"schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"people\": {\n",
        "                    \"type\": \"array\",\n",
        "                    \"items\": {\"type\": \"string\"},\n",
        "                    \"description\": \"Names of people mentioned\"\n",
        "                },\n",
        "                \"organizations\": {\n",
        "                    \"type\": \"array\",\n",
        "                    \"items\": {\"type\": \"string\"},\n",
        "                    \"description\": \"Names of companies, institutions, or groups\"\n",
        "                },\n",
        "                \"locations\": {\n",
        "                    \"type\": \"array\",\n",
        "                    \"items\": {\"type\": \"string\"},\n",
        "                    \"description\": \"Geographic locations (cities, countries, addresses)\"\n",
        "                },\n",
        "                \"dates\": {\n",
        "                    \"type\": \"array\",\n",
        "                    \"items\": {\"type\": \"string\"},\n",
        "                    \"description\": \"Dates or time references\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"people\", \"organizations\", \"locations\", \"dates\"],\n",
        "            \"additionalProperties\": False\n",
        "        }\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create extraction pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create table for articles\n",
        "articles = pxt.create_table(\n",
        "    'entities_demo.articles',\n",
        "    {'title': pxt.String, 'content': pxt.String}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add entity extraction column\n",
        "extraction_prompt = 'Extract all named entities from the following text:\\n\\n' + articles.content\n",
        "\n",
        "articles.add_computed_column(\n",
        "    extraction_response=chat_completions(\n",
        "        messages=[{'role': 'user', 'content': extraction_prompt}],\n",
        "        model='gpt-4o-mini',\n",
        "        response_format=entity_schema\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract the entities JSON\n",
        "articles.add_computed_column(\n",
        "    entities=articles.extraction_response.choices[0].message.content\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extract entities from text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insert sample articles\n",
        "sample_articles = [\n",
        "    {\n",
        "        'title': 'Tech Acquisition',\n",
        "        'content': 'Microsoft announced today that CEO Satya Nadella will lead the acquisition of a Seattle-based startup. The deal, expected to close in March 2024, is valued at $500 million.'\n",
        "    },\n",
        "    {\n",
        "        'title': 'Sports Update',\n",
        "        'content': 'LeBron James led the Los Angeles Lakers to victory against the Boston Celtics on Tuesday night at Staples Center. Coach Darvin Ham praised the teams performance.'\n",
        "    },\n",
        "    {\n",
        "        'title': 'Research Breakthrough',\n",
        "        'content': 'Dr. Sarah Chen at Stanford University published groundbreaking research on renewable energy. The study, funded by the National Science Foundation, was conducted in Palo Alto, California.'\n",
        "    },\n",
        "]\n",
        "\n",
        "articles.insert(sample_articles)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View extracted entities\n",
        "for row in articles.select(articles.title, articles.entities).collect():\n",
        "    print(f\"\\n{row['title']}:\")\n",
        "    entities = json.loads(row['entities'])\n",
        "    for entity_type, values in entities.items():\n",
        "        if values:\n",
        "            print(f\"  {entity_type}: {', '.join(values)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explanation\n",
        "\n",
        "**Structured output ensures reliable extraction:**\n",
        "\n",
        "By using OpenAI's structured output (`response_format`), the model always returns valid JSON matching the schema. No post-processing or error handling needed.\n",
        "\n",
        "**Common entity types:**\n",
        "\n",
        "| Entity Type | Examples |\n",
        "|-------------|----------|\n",
        "| People | Names, titles |\n",
        "| Organizations | Companies, institutions |\n",
        "| Locations | Cities, countries, addresses |\n",
        "| Dates | Specific dates, time periods |\n",
        "| Money | Amounts, currencies |\n",
        "| Products | Brand names, model numbers |\n",
        "\n",
        "**Customizing the schema:**\n",
        "\n",
        "Modify the `entity_schema` to extract domain-specific entities\u2014product SKUs, legal terms, medical conditions, etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## See also\n",
        "\n",
        "- [Extract structured data from images](https://docs.pixeltable.com/howto/cookbooks/images/vision-structured-output) - JSON extraction from images\n",
        "- [Extract fields from JSON](https://docs.pixeltable.com/howto/cookbooks/core/workflow-json-extraction) - Parse LLM response fields\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}