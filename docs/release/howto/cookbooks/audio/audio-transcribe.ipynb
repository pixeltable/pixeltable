{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcribe audio files with Whisper\n",
    "\n",
    "Convert speech to text locally using OpenAI's open-source Whisper model—no API key needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "You have audio or video files that need transcription. Long files are memory-intensive to process at once, so you need to split them into manageable chunks.\n",
    "\n",
    "| File | Duration | Challenge |\n",
    "|------|----------|-----------|\n",
    "| podcast.mp3 | 60 min | Too long to process at once |\n",
    "| interview.mp4 | 30 min | Need to extract audio first |\n",
    "| meeting.wav | 2 hours | Must chunk for memory efficiency |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "**What's in this recipe:**\n",
    "- Transcribe audio files locally with Whisper (no API key)\n",
    "- Automatically chunk long files\n",
    "- Extract and transcribe audio from videos\n",
    "\n",
    "You create a view with AudioSplitter to break long files into chunks, then add a computed column for transcription. Whisper runs locally on your machine—no API calls needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pixeltable openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixeltable as pxt\n",
    "from pixeltable.iterators import AudioSplitter\n",
    "from pixeltable.functions import whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fresh directory\n",
    "pxt.drop_dir('audio_demo', force=True)\n",
    "pxt.create_dir('audio_demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table for audio files\n",
    "audio = pxt.create_table('audio_demo.files', {'audio': pxt.Audio})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a sample audio file (video files also work - audio is extracted automatically)\n",
    "audio.insert([\n",
    "    {'audio': 'https://raw.githubusercontent.com/pixeltable/pixeltable/main/docs/resources/audio-transcription-demo/Lex-Fridman-Podcast-430-Excerpt-0.mp4'}\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into chunks\n",
    "\n",
    "Create a view that splits audio into 30-second chunks with overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split audio into chunks for transcription\n",
    "chunks = pxt.create_view(\n",
    "    'audio_demo.chunks',\n",
    "    audio,\n",
    "    iterator=AudioSplitter.create(\n",
    "        audio=audio.audio,\n",
    "        chunk_duration_sec=30.0,  # 30-second chunks\n",
    "        overlap_sec=2.0,          # 2-second overlap for context\n",
    "        min_chunk_duration_sec=5.0  # Drop chunks shorter than 5 seconds\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the chunks\n",
    "chunks.select(chunks.start_time_sec, chunks.end_time_sec).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe with Whisper\n\nAdd a computed column that transcribes each chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add transcription column (runs locally - no API key needed)\n",
    "chunks.add_computed_column(\n",
    "    transcription=whisper.transcribe(\n",
    "        audio=chunks.audio_chunk,\n",
    "        model='base.en'  # Options: tiny.en, base.en, small.en, medium.en, large\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract just the text\n",
    "chunks.add_computed_column(text=chunks.transcription.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View transcriptions with timestamps\n",
    "chunks.select(chunks.start_time_sec, chunks.end_time_sec, chunks.text).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n\n**Whisper models:**\n\n| Model | Speed | Quality | Best for |\n|-------|-------|---------|----------|\n| `tiny.en` | Fastest | Basic | Quick tests |\n| `base.en` | Fast | Good | General use |\n| `small.en` | Medium | Better | Higher accuracy |\n| `medium.en` | Slow | Great | Professional quality |\n| `large` | Slowest | Best | Maximum accuracy |\n\nModels ending in `.en` are English-only and faster. Remove `.en` for multilingual support.\n\n**AudioSplitter parameters:**\n\n| Parameter | Description |\n|-----------|-------------|\n| `chunk_duration_sec` | Duration of each chunk in seconds |\n| `overlap_sec` | Overlap between chunks (helps with word boundaries) |\n| `min_chunk_duration_sec` | Drop the last chunk if shorter than this |\n\n**Video files work too:**\n\nWhen you insert a video file, Pixeltable automatically extracts the audio track."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See also\n\n- [Iterators documentation](https://docs.pixeltable.com/platform/iterators)\n- [Whisper library](https://github.com/openai/whisper)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
