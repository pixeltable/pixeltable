{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract audio from video\n",
    "\n",
    "Extract the audio track from video files for transcription, analysis, or processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "You have video files but need to work with just the audio track—for transcription, speaker analysis, or audio processing. Extracting audio manually with ffmpeg is tedious and doesn't integrate with your data pipeline.\n",
    "\n",
    "| Source | Goal |\n",
    "|--------|------|\n",
    "| Lecture recordings | Transcribe for notes |\n",
    "| Meeting videos | Extract for speaker ID |\n",
    "| Video podcasts | Create audio-only version |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "**What's in this recipe:**\n",
    "- Extract audio from video as a computed column\n",
    "- Choose audio format (mp3, wav, flac)\n",
    "- Chain with transcription for automatic video-to-text\n",
    "\n",
    "You use the `extract_audio` function to create an audio column from video. This integrates seamlessly with transcription and other audio processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pixeltable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixeltable as pxt\n",
    "from pixeltable.functions.video import extract_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fresh directory\n",
    "pxt.drop_dir('audio_extract_demo', force=True)\n",
    "pxt.create_dir('audio_extract_demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract audio from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table for videos\n",
    "videos = pxt.create_table(\n",
    "    'audio_extract_demo.videos',\n",
    "    {'title': pxt.String, 'video': pxt.Video}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add computed column to extract audio as MP3\n",
    "videos.add_computed_column(\n",
    "    audio=extract_audio(videos.video, format='mp3')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a sample video (from multimedia-commons with audio)\n",
    "video_url = 's3://multimedia-commons/data/videos/mp4/ffe/ffb/ffeffbef41bbc269810b2a1a888de.mp4'\n",
    "\n",
    "videos.insert([{\n",
    "    'title': 'Sample Video',\n",
    "    'video': video_url\n",
    "}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results\n",
    "videos.select(videos.title, videos.audio).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain with transcription\n",
    "\n",
    "Add transcription as a follow-up computed column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install whisper for transcription\n",
    "%pip install -qU openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixeltable.functions import whisper\n",
    "\n",
    "# Add transcription of the extracted audio\n",
    "videos.add_computed_column(\n",
    "    transcription=whisper.transcribe(videos.audio, model='base.en')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the transcript text\n",
    "videos.add_computed_column(\n",
    "    transcript=videos.transcription.text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the full pipeline results\n",
    "videos.select(videos.title, videos.transcript).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "**Audio format options:**\n",
    "\n",
    "| Format | Use case |\n",
    "|--------|----------|\n",
    "| `mp3` | Compressed, widely compatible |\n",
    "| `wav` | Uncompressed, for processing |\n",
    "| `flac` | Lossless compression |\n",
    "\n",
    "**Pipeline flow:**\n",
    "\n",
    "```\n",
    "Video → extract_audio → Audio → whisper.transcribe → Transcript\n",
    "```\n",
    "\n",
    "Each step is a computed column. When you insert a new video:\n",
    "1. Audio is extracted automatically\n",
    "2. Whisper transcribes the audio\n",
    "3. All results are cached for future queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See also\n",
    "\n",
    "- [Transcribe audio](https://docs.pixeltable.com/howto/cookbooks/audio/audio-transcribe) - Audio-only transcription\n",
    "- [Summarize podcasts](https://docs.pixeltable.com/howto/cookbooks/audio/audio-summarize-podcast) - Transcribe and summarize\n",
    "- [Extract video frames](https://docs.pixeltable.com/howto/cookbooks/video/video-extract-frames) - Work with video frames"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixeltable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
