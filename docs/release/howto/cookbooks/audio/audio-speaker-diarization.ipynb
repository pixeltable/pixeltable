{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transcribe meetings with speaker identification\n",
        "\n",
        "Automatically transcribe audio and identify who said what using speaker diarization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem\n",
        "\n",
        "You have recordings of meetings, interviews, or podcasts and need transcripts that show who said what. Standard transcription only gives you text\u2014you lose track of speakers.\n",
        "\n",
        "| Recording type | Need |\n",
        "|----------------|------|\n",
        "| Meeting recordings | Attribute comments to participants |\n",
        "| Interview audio | Separate interviewer from interviewee |\n",
        "| Podcasts | Identify hosts vs guests |\n",
        "| Customer calls | Track agent vs customer |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solution\n",
        "\n",
        "**What's in this recipe:**\n",
        "- Transcribe audio with WhisperX\n",
        "- Enable speaker diarization to identify speakers\n",
        "- Extract speaker-labeled segments\n",
        "\n",
        "Use WhisperX's `transcribe()` with `diarize=True` to get transcripts with speaker labels.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU pixeltable whisperx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pixeltable as pxt\n",
        "from pixeltable.functions import whisperx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a fresh directory\n",
        "pxt.drop_dir('diarization_demo', force=True)\n",
        "pxt.create_dir('diarization_demo')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a meetings table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a table for meeting recordings\n",
        "meetings = pxt.create_table(\n",
        "    'diarization_demo.meetings',\n",
        "    {'audio': pxt.Audio, 'meeting_name': pxt.String}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insert a sample audio file (replace with your own recordings)\n",
        "meetings.insert([\n",
        "    {\n",
        "        'audio': 'https://github.com/pixeltable/pixeltable/raw/main/docs/resources/audio/short-clip.mp3',\n",
        "        'meeting_name': 'Sample Meeting'\n",
        "    }\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Add transcription with speaker diarization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add a computed column with speaker diarization\n",
        "# Note: Requires HF_TOKEN environment variable for pyannote models\n",
        "meetings.add_computed_column(\n",
        "    transcript=whisperx.transcribe(\n",
        "        meetings.audio,\n",
        "        model='tiny.en',       # Use 'large-v3' for production\n",
        "        diarize=True,          # Enable speaker identification\n",
        "        min_speakers=1,        # Minimum expected speakers\n",
        "        max_speakers=4         # Maximum expected speakers\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View the transcript with speaker labels\n",
        "result = meetings.select(meetings.meeting_name, meetings.transcript).collect()\n",
        "\n",
        "for row in result:\n",
        "    print(f\"Meeting: {row['meeting_name']}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Extract segments with speaker labels\n",
        "    segments = row['transcript'].get('segments', [])\n",
        "    for seg in segments:\n",
        "        speaker = seg.get('speaker', 'Unknown')\n",
        "        text = seg.get('text', '').strip()\n",
        "        start = seg.get('start', 0)\n",
        "        print(f\"[{start:.1f}s] {speaker}: {text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extract speaker-specific text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a UDF to extract text by speaker\n",
        "@pxt.udf\n",
        "def get_speaker_text(transcript: dict, speaker_id: str) -> str:\n",
        "    \"\"\"Extract all text from a specific speaker.\"\"\"\n",
        "    segments = transcript.get('segments', [])\n",
        "    speaker_text = [\n",
        "        seg.get('text', '').strip() \n",
        "        for seg in segments \n",
        "        if seg.get('speaker') == speaker_id\n",
        "    ]\n",
        "    return ' '.join(speaker_text)\n",
        "\n",
        "# Add columns for each speaker's contributions\n",
        "meetings.add_computed_column(speaker_0_text=get_speaker_text(meetings.transcript, 'SPEAKER_00'))\n",
        "meetings.add_computed_column(speaker_1_text=get_speaker_text(meetings.transcript, 'SPEAKER_01'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View speaker-separated text\n",
        "meetings.select(\n",
        "    meetings.meeting_name,\n",
        "    meetings.speaker_0_text,\n",
        "    meetings.speaker_1_text\n",
        ").collect()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explanation\n",
        "\n",
        "**WhisperX diarization parameters:**\n",
        "\n",
        "| Parameter | Description |\n",
        "|-----------|-------------|\n",
        "| `diarize=True` | Enable speaker identification |\n",
        "| `min_speakers` | Minimum expected speakers |\n",
        "| `max_speakers` | Maximum expected speakers |\n",
        "| `num_speakers` | Exact number if known |\n",
        "\n",
        "**Output structure:**\n",
        "\n",
        "The transcript contains `segments` with speaker labels:\n",
        "\n",
        "```python\n",
        "{\n",
        "    'segments': [\n",
        "        {'speaker': 'SPEAKER_00', 'text': '...', 'start': 0.0, 'end': 2.5},\n",
        "        {'speaker': 'SPEAKER_01', 'text': '...', 'start': 2.5, 'end': 5.0},\n",
        "    ]\n",
        "}\n",
        "```\n",
        "\n",
        "**Model selection:**\n",
        "\n",
        "| Model | Speed | Accuracy | Use case |\n",
        "|-------|-------|----------|----------|\n",
        "| `tiny.en` | Fast | Lower | Testing, English only |\n",
        "| `base.en` | Medium | Good | English production |\n",
        "| `large-v3` | Slow | Best | Multi-language, high accuracy |\n",
        "\n",
        "**Requirements:**\n",
        "- Set `HF_TOKEN` environment variable for pyannote diarization models\n",
        "- GPU recommended for larger models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## See also\n",
        "\n",
        "- [Transcribe audio files](https://docs.pixeltable.com/howto/cookbooks/audio/audio-transcribe) - Basic transcription without diarization\n",
        "- [Summarize podcasts](https://docs.pixeltable.com/howto/cookbooks/audio/audio-summarize-podcast) - Transcribe and summarize\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}