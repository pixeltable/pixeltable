---
title: "PDF"
description: "Build a PDF search system using smart chunking and vector embeddings"
icon: "file-pdf"
---

# Building a PDF Search Workflow

Pixeltable PDF search works in two phases:
1. Define your workflow structure (once)
2. Query your document database (anytime)

<Steps>
  <Step title="Install Dependencies">
    ```bash
    pip install pixeltable tiktoken sentence-transformers
    ```
  </Step>

  <Step title="Define Your Workflow" icon="diagram-project">
    Create `table.py`:
    ```python
    import pixeltable as pxt
    from pixeltable.iterators import DocumentSplitter
    from pixeltable.functions.huggingface import sentence_transformer

    # Initialize app structure
    pxt.drop_dir("pdf_search", force=True)
    pxt.create_dir("pdf_search")

    # Create documents table
    documents_t = pxt.create_table(
        "pdf_search.documents", 
        {"pdf": pxt.Document}
    )

    # Create chunked view for efficient processing
    documents_chunks = pxt.create_view(
        "pdf_search.document_chunks",
        documents_t,
        iterator=DocumentSplitter.create(
            document=documents_t.pdf,
            separators="token_limit",
            limit=300  # Tokens per chunk
        )
    )

    # Configure embedding model
    embed_model = sentence_transformer.using(
        model_id="intfloat/e5-large-v2"
    )

    # Add search capability
    documents_chunks.add_embedding_index(
        column="text",
        string_embed=embed_model
    )
    ```
  </Step>

  <Step title="Use Your Workflow" icon="play">
    Create `app.py`:
    ```python
    import pixeltable as pxt

    # Connect to your tables
    documents_t = pxt.get_table("pdf_search.documents")
    documents_chunks = pxt.get_table("pdf_search.document_chunks")

    # Sample document URLs
    DOCUMENT_URL = (
        "https://github.com/pixeltable/pixeltable/raw/release/docs/resources/rag-demo/"
    )
    
    document_urls = [
        DOCUMENT_URL + doc for doc in [
            "Argus-Market-Digest-June-2024.pdf",
            "Company-Research-Alphabet.pdf",
            "Zacks-Nvidia-Report.pdf",
        ]
    ]

    # Add documents to database
    documents_t.insert({"pdf": url} for url in document_urls)

    # Search documents
    query = "What are the growth projections for tech companies?"
    top_n = 3
    sim = documents_chunks.text.similarity(query)
    result = (
        documents_chunks.order_by(sim, asc=False)
        .select(documents_chunks.text, sim=sim)
        .collect()
    )

    # Print results
    for i in result:
        print(f"Similarity: {i['sim']:.3f}")
        print(f"Text: {i['text']}\n")
    ```
  </Step>
</Steps>

## What Makes This Different?

<CardGroup cols={1}>
  <Card title="Smart Chunking" icon="cut">
    Token-aware document splitting:
    ```python
    iterator=DocumentSplitter.create(
        document=documents_t.pdf,
        separators="token_limit",
        limit=300
    )
    ```
  </Card>

  <Card title="Vector Search" icon="magnifying-glass">
    Natural language document search:
    ```python
    documents_chunks.add_embedding_index(
        column="text",
        string_embed=embed_model
    )
    ```
  </Card>

  <Card title="Auto-updating" icon="arrows-rotate">
    Self-maintaining document database:
    ```python
    documents_t.insert([{"pdf": new_url}])
    # Chunking and embeddings update automatically
    ```
  </Card>
</CardGroup>

## Workflow Components

<AccordionGroup>
  <Accordion title="PDF Processing" icon="file-pdf">
    Advanced document handling:
    - Automatic text extraction
    - PDF parsing and cleaning
    - Structure preservation
    - Support for multiple PDF formats
  </Accordion>

  <Accordion title="Text Chunking" icon="puzzle-piece">
    Intelligent text splitting:
    - Token-aware chunking
    - Configurable chunk sizes
    - Context preservation
    - Multiple chunking strategies
  </Accordion>

  <Accordion title="Vector Search" icon="network-wired">
    High-quality search:
    - E5 text embeddings
    - Fast similarity search
    - Natural language queries
    - Configurable similarity thresholds
  </Accordion>
</AccordionGroup>

## Advanced Usage

### Custom Chunking Strategies

Configure different chunking approaches:

```python
# Chunk by paragraphs
chunks_by_para = pxt.create_view(
    "pdf_search.para_chunks",
    documents_t,
    iterator=DocumentSplitter.create(
        document=documents_t.pdf,
        separators="paragraph"
    )
)

# Chunk by fixed size
chunks_by_size = pxt.create_view(
    "pdf_search.size_chunks",
    documents_t,
    iterator=DocumentSplitter.create(
        document=documents_t.pdf,
        separators="fixed",
        size=1000  # characters
    )
)
```

### Batch Processing

Process multiple PDFs in batch:

```python
# Bulk document insertion
pdf_urls = [
    "https://example.com/doc1.pdf",
    "https://example.com/doc2.pdf",
    "https://example.com/doc3.pdf"
]

documents_t.insert({"pdf": url} for url in pdf_urls)
```

### Advanced Search Functions

Create specialized search functions:

```python
@pxt.query
def search_with_metadata(
    query: str,
    min_similarity: float,
    limit: int
):
    sim = documents_chunks.text.similarity(query)
    return (
        documents_chunks.where(sim >= min_similarity)
        .order_by(sim, asc=False)
        .select(
            documents_chunks.text,
            documents_chunks.pdf_name,
            documents_chunks.page_number,
            similarity=sim
        )
        .limit(limit)
    )
```