{
  "@context": "https://pixeltable.com/learn",
  "@type": "Tutorial",
  "@id": "018-fireworks-integration", 
  "github_url": "https://github.com/pixeltable/pixeltable/blob/release/docs/notebooks/integrations/working-with-fireworks.ipynb",
  "title": "Working with Fireworks AI in Pixeltable",
  "objective": "Learn to integrate Fireworks AI's hosted LLM models with advanced parameter control for optimal performance tuning",
  "difficulty": "intermediate",
  "categories": ["fireworks", "llm-integration", "model-parameters", "performance-tuning", "hosted-models"],
  "prerequisites": ["011-openai-integration", "017-deepseek-integration"],
  "imports_required": [
    "pixeltable",
    "pixeltable.functions.fireworks",
    "fireworks-ai",
    "os",
    "getpass"
  ],
  "performance_notes": {
    "typical_runtime": "45 seconds for setup with parameter tuning",
    "resource_requirements": "Fireworks API key, internet connection",
    "bottlenecks": ["API key setup", "model parameter optimization", "network latency"]
  },
  "key_learnings": [
    "Fireworks uses dedicated fireworks-ai SDK instead of OpenAI compatibility",
    "Model names include full account paths like 'accounts/fireworks/models/mixtral-8x22b-instruct'",
    "Extensive parameter control with model_kwargs for fine-tuning performance",
    "Supports advanced sampling parameters like top_k, top_p, temperature",
    "Response structure follows OpenAI pattern with choices[0].message.content",
    "Mixtral models offer strong performance for instruction following",
    "Parameter tuning critical for optimal results with different model architectures"
  ],
  "relationships": {
    "builds_on": ["basic_pixeltable_concepts", "openai_response_patterns"],
    "enables": ["parameter_optimized_workflows", "mixtral_model_usage", "advanced_sampling_control"],
    "see_also": ["011-openai-integration#parameter_control", "021-mistralai-integration#mixtral_comparison"],
    "contrasts_with": ["openai_simple_parameters", "anthropic_limited_parameters"]
  },
  "steps": [
    {
      "number": 1,
      "section_title": "Environment Setup and Dependencies",
      "intent": "Install Fireworks-specific SDK and configure API access",
      "code": "%pip install -qU pixeltable fireworks-ai\n\nimport os\nimport getpass\n\nif 'FIREWORKS_API_KEY' not in os.environ:\n    os.environ['FIREWORKS_API_KEY'] = getpass.getpass('Fireworks API Key:')",
      "imports_used": ["os", "getpass"],
      "explanation": "Fireworks uses dedicated fireworks-ai SDK, not the generic OpenAI client",
      "actual_output": "[Installation progress and API key prompt]",
      "output_summary": "Fireworks SDK installed and API key configured",
      "output_type": "text",
      "learns": ["fireworks_ai_sdk", "dedicated_client_libraries"],
      "reinforces": ["package_installation", "api_key_management"],
      "gotchas": ["Package name is 'fireworks-ai' with hyphen", "API key variable is FIREWORKS_API_KEY"],
      "performance": {
        "execution_time": "30-45s for installation",
        "scaling": "O(1) - one-time setup",
        "optimization": "demo"
      },
      "alternatives": {
        "description": "Use OpenAI-compatible endpoint if supported by Fireworks",
        "when_to_use": "When maintaining consistent API across multiple providers"
      },
      "state_after": {
        "tables": [],
        "views": [],
        "variables": ["FIREWORKS_API_KEY"],
        "models_loaded": []
      },
      "pattern_refs": ["api_key_setup", "dedicated_sdk_installation"]
    },
    {
      "number": 2,
      "section_title": "Create Demo Directory",
      "intent": "Initialize Pixeltable workspace for Fireworks experiments",
      "code": "import pixeltable as pxt\n\n# Remove the 'fireworks_demo' directory and its contents, if it exists\npxt.drop_dir('fireworks_demo', force=True)\npxt.create_dir('fireworks_demo')",
      "imports_used": ["pixeltable"],
      "explanation": "Standard Pixeltable pattern for creating isolated workspaces",
      "actual_output": "Connected to Pixeltable database at: postgresql+psycopg://postgres:@/pixeltable?host=/Users/asiegel/.pixeltable/pgdata\nCreated directory 'fireworks_demo'.\n\n<pixeltable.catalog.dir.Dir at 0x301799de0>",
      "output_summary": "Demo directory created with database connection confirmation",
      "output_type": "text",
      "learns": [],
      "reinforces": ["directory_management", "workspace_isolation"],
      "gotchas": [],
      "performance": {
        "execution_time": "<1s",
        "scaling": "O(1)",
        "optimization": "demo"
      },
      "alternatives": {
        "description": "Use existing directory or different naming convention", 
        "when_to_use": "When integrating into existing projects"
      },
      "state_after": {
        "tables": [],
        "views": [],
        "variables": [],
        "models_loaded": []
      },
      "pattern_refs": ["workspace_initialization", "directory_cleanup"]
    },
    {
      "number": 3,
      "section_title": "Fireworks Chat Setup with Advanced Parameters",
      "intent": "Create chat table with comprehensive parameter tuning for Mixtral model",
      "code": "from pixeltable.functions.fireworks import chat_completions\n\n# Create a table in Pixeltable and pick a model hosted on Fireworks with some parameters\n\nt = pxt.create_table('fireworks_demo.chat', {'input': pxt.String})\n\nmessages = [{'role': 'user', 'content': t.input}]\nt.add_computed_column(output=chat_completions(\n    messages=messages,\n    model='accounts/fireworks/models/mixtral-8x22b-instruct',\n    model_kwargs={\n        # Optional dict with parameters for the Fireworks API\n        'max_tokens': 300,\n        'top_k': 40,\n        'top_p': 0.9,\n        'temperature': 0.7\n    }\n))",
      "imports_used": ["pixeltable.functions.fireworks.chat_completions"],
      "explanation": "Fireworks excels at parameter control with model_kwargs for fine-tuning generation behavior",
      "actual_output": "Created table `chat`.\nAdded 0 column values with 0 errors.\n\nUpdateStatus(num_rows=0, num_computed_values=0, num_excs=0, updated_cols=[], cols_with_excs=[])",
      "output_summary": "Chat table created with Mixtral model and advanced sampling parameters",
      "output_type": "text",
      "learns": ["fireworks_chat_completions", "mixtral_model_paths", "model_kwargs_pattern", "advanced_sampling_parameters"],
      "reinforces": ["computed_column_creation", "message_list_pattern"],
      "gotchas": ["Model path includes full account path", "model_kwargs is separate from direct parameters", "Parameter names may differ from OpenAI"],
      "performance": {
        "execution_time": "1s",
        "scaling": "O(1) for setup",
        "optimization": "demo"
      },
      "alternatives": {
        "description": "Use different Fireworks models or parameter combinations",
        "when_to_use": "Different performance/quality trade-offs needed"
      },
      "state_after": {
        "tables": ["fireworks_demo.chat"],
        "views": [],
        "variables": ["t"],
        "models_loaded": ["accounts/fireworks/models/mixtral-8x22b-instruct"]
      },
      "pattern_refs": ["fireworks_model_setup", "advanced_parameter_tuning", "model_kwargs_pattern"]
    },
    {
      "number": 4,
      "section_title": "Response Parsing",
      "intent": "Extract readable text from Fireworks response using OpenAI-compatible structure",
      "code": "# Parse the bot_response into a new column\nt.add_computed_column(response=t.output.choices[0].message.content)",
      "imports_used": ["pixeltable.functions.fireworks"],
      "explanation": "Fireworks maintains OpenAI response compatibility despite using dedicated SDK",
      "actual_output": "Added 0 column values with 0 errors.\n\nUpdateStatus(num_rows=0, num_computed_values=0, num_excs=0, updated_cols=[], cols_with_excs=[])",
      "output_summary": "Response parsing column added successfully",
      "output_type": "text",
      "learns": ["fireworks_openai_compatibility"],
      "reinforces": ["response_field_extraction", "column_chaining"],
      "gotchas": [],
      "performance": {
        "execution_time": "<1s",
        "scaling": "O(1)",
        "optimization": "demo"
      },
      "alternatives": {
        "description": "Extract usage metrics for cost monitoring",
        "when_to_use": "Production environments requiring cost tracking"
      },
      "state_after": {
        "tables": ["fireworks_demo.chat"],
        "views": [],
        "variables": ["t"],
        "models_loaded": ["accounts/fireworks/models/mixtral-8x22b-instruct"]
      },
      "pattern_refs": ["openai_response_extraction"]
    },
    {
      "number": 5,
      "section_title": "First Chat Interaction with Parameter Testing",
      "intent": "Test Fireworks integration and parameter effectiveness with historical query",
      "code": "# Start a conversation\nt.insert(input=\"Can you tell me who was President of the US in 1961?\")\nt.select(t.input, t.response).show()",
      "imports_used": ["pixeltable.functions.fireworks"],
      "explanation": "Test query validates both integration and parameter tuning effectiveness",
      "actual_output": "Inserting rows into `chat`: 1 rows [00:00, 85.10 rows/s]\nInserted 1 row with 0 errors.\n\n                                               input  \\\n0  Can you tell me who was President of the US in...   \n\n                                            response  \n0  Yes, the President of the United States in 196...  ",
      "output_summary": "Successfully generated response using Fireworks with tuned parameters",
      "output_type": "table",
      "learns": [],
      "reinforces": ["table_insertion", "query_execution", "response_display"],
      "gotchas": [],
      "performance": {
        "execution_time": "3-4s with parameter processing",
        "scaling": "O(n) for n queries",
        "optimization": "demo"
      },
      "alternatives": {
        "description": "A/B test different parameter combinations",
        "when_to_use": "Optimizing parameters for specific use cases"
      },
      "state_after": {
        "tables": ["fireworks_demo.chat"],
        "views": [],
        "variables": ["t"],
        "models_loaded": ["accounts/fireworks/models/mixtral-8x22b-instruct"]
      },
      "pattern_refs": ["basic_chat_interaction", "parameter_validation_test"]
    }
  ],
  "patterns": [
    {
      "name": "dedicated_sdk_installation",
      "description": "Install provider-specific SDK instead of generic OpenAI client",
      "confidence": "high", 
      "frequency": 2,
      "first_seen": "018-fireworks-integration",
      "code_template": "%pip install -qU pixeltable provider-specific-sdk\n\nimport os\nimport getpass\n\nif 'PROVIDER_API_KEY' not in os.environ:\n    os.environ['PROVIDER_API_KEY'] = getpass.getpass('API Key:')",
      "parameters": {
        "provider-specific-sdk": "Dedicated SDK package name",
        "PROVIDER_API_KEY": "Provider-specific environment variable"
      },
      "variations": [
        {
          "name": "with_version_pinning",
          "difference": "Pin specific SDK version for stability",
          "code": "%pip install -qU pixeltable provider-sdk==1.2.3"
        }
      ],
      "prerequisites": ["provider_account"],
      "enables": ["native_provider_features", "advanced_parameter_access"],
      "performance_impact": "Better feature support vs. additional dependency",
      "reusable": true,
      "production_ready": true
    },
    {
      "name": "model_kwargs_pattern",
      "description": "Advanced parameter control through model_kwargs dictionary",
      "confidence": "high",
      "frequency": 1,
      "first_seen": "018-fireworks-integration",
      "code_template": "provider.chat_completions(\n    messages=messages,\n    model='model_name',\n    model_kwargs={\n        'max_tokens': 300,\n        'temperature': 0.7,\n        'top_p': 0.9,\n        'top_k': 40\n    }\n)",
      "parameters": {
        "model_kwargs": "Dictionary of model-specific parameters",
        "temperature": "Sampling randomness (0.0-2.0)",
        "top_p": "Nucleus sampling threshold",
        "top_k": "Top-k sampling limit",
        "max_tokens": "Response length limit"
      },
      "variations": [
        {
          "name": "minimal_params",
          "difference": "Use only essential parameters",
          "code": "model_kwargs={'temperature': 0.7, 'max_tokens': 150}"
        },
        {
          "name": "deterministic_params",
          "difference": "Parameters for consistent outputs",
          "code": "model_kwargs={'temperature': 0.0, 'top_p': 1.0}"
        }
      ],
      "prerequisites": ["provider_parameter_documentation"],
      "enables": ["fine_tuned_generation", "consistent_outputs", "performance_optimization"],
      "performance_impact": "Better control over quality/speed trade-offs",
      "reusable": true,
      "production_ready": true
    },
    {
      "name": "fireworks_model_setup",
      "description": "Fireworks-specific model configuration with full account paths",
      "confidence": "high",
      "frequency": 1,
      "first_seen": "018-fireworks-integration",
      "code_template": "from pixeltable.functions.fireworks import chat_completions\n\nt.add_computed_column(output=chat_completions(\n    messages=messages,\n    model='accounts/fireworks/models/model-name',\n    model_kwargs=parameters\n))",
      "parameters": {
        "model": "Full Fireworks model path including account",
        "model_kwargs": "Fireworks-specific parameter dictionary"
      },
      "variations": [
        {
          "name": "different_models",
          "difference": "Use various Fireworks-hosted models",
          "code": "model='accounts/fireworks/models/llama-v2-70b-chat'"
        }
      ],
      "prerequisites": ["fireworks_api_access", "model_availability"],
      "enables": ["fireworks_model_ecosystem", "mixtral_usage"],
      "performance_impact": "Model-dependent latency and cost",
      "reusable": true,
      "production_ready": true
    },
    {
      "name": "advanced_parameter_tuning",
      "description": "Comprehensive parameter optimization for generation quality",
      "confidence": "high",
      "frequency": 1,
      "first_seen": "018-fireworks-integration",
      "code_template": "model_kwargs={\n    'max_tokens': 300,     # Response length\n    'top_k': 40,          # Vocabulary filtering\n    'top_p': 0.9,         # Cumulative probability\n    'temperature': 0.7    # Creativity vs consistency\n}",
      "parameters": {
        "max_tokens": "Maximum response length (50-4000)",
        "top_k": "Top-k sampling limit (1-100)",
        "top_p": "Nucleus sampling threshold (0.1-1.0)",
        "temperature": "Randomness control (0.0-2.0)"
      },
      "variations": [
        {
          "name": "creative_params",
          "difference": "High creativity settings",
          "code": "{'temperature': 1.2, 'top_p': 0.95, 'top_k': 50}"
        },
        {
          "name": "precise_params",
          "difference": "Low variance for factual tasks",
          "code": "{'temperature': 0.2, 'top_p': 0.8, 'top_k': 20}"
        }
      ],
      "prerequisites": ["understanding_sampling_parameters"],
      "enables": ["optimized_generation", "task_specific_tuning"],
      "performance_impact": "Quality improvement vs. parameter complexity",
      "reusable": true,
      "production_ready": true
    }
  ],
  "common_errors": [
    {
      "error_type": "Invalid model path format",
      "frequency": "common",
      "cause": "Using simple model name instead of full Fireworks account path",
      "symptoms": ["Model not found", "Invalid model identifier"],
      "solution": {
        "quick_fix": "Use full path format: 'accounts/fireworks/models/model-name'",
        "proper_fix": "Check Fireworks documentation for correct model identifiers"
      },
      "prevention": "Always use complete model paths from Fireworks console",
      "example": "Using 'mixtral-8x22b' instead of 'accounts/fireworks/models/mixtral-8x22b-instruct'",
      "first_seen": "018-fireworks-integration#step3"
    },
    {
      "error_type": "Invalid parameter in model_kwargs",
      "frequency": "occasional",
      "cause": "Using parameter names from other providers that don't exist in Fireworks",
      "symptoms": ["Unknown parameter error", "API validation failed"],
      "solution": {
        "quick_fix": "Remove unsupported parameters from model_kwargs",
        "proper_fix": "Reference Fireworks API documentation for valid parameters"
      },
      "prevention": "Verify parameter names against Fireworks documentation",
      "example": "Using 'n' parameter (OpenAI) instead of supported Fireworks params",
      "first_seen": "018-fireworks-integration#step3"
    },
    {
      "error_type": "Missing fireworks-ai package",
      "frequency": "common",
      "cause": "Fireworks requires dedicated SDK, not OpenAI client",
      "symptoms": ["ModuleNotFoundError: No module named 'fireworks'"],
      "solution": {
        "quick_fix": "pip install fireworks-ai",
        "proper_fix": "Include fireworks-ai in requirements.txt"
      },
      "prevention": "Install Fireworks-specific SDK for proper integration",
      "example": "Trying to use Fireworks functions without fireworks-ai dependency",
      "first_seen": "018-fireworks-integration#step1"
    },
    {
      "error_type": "Parameter value out of range",
      "frequency": "occasional",
      "cause": "Fireworks has specific ranges for sampling parameters",
      "symptoms": ["Parameter validation error", "Value out of range"],
      "solution": {
        "quick_fix": "Adjust parameters to valid ranges (temperature: 0-2, top_p: 0-1)",
        "proper_fix": "Create parameter validation before API calls"
      },
      "prevention": "Validate parameter ranges before setting model_kwargs",
      "example": "temperature=3.0 when max is 2.0",
      "first_seen": "018-fireworks-integration#step3"
    }
  ],
  "test_questions": [
    {
      "question": "What SDK package does Fireworks require instead of the OpenAI client?",
      "type": "implementation",
      "answer": "fireworks-ai - Fireworks uses a dedicated SDK for optimal feature support",
      "difficulty": "beginner"
    },
    {
      "question": "What is the correct format for Fireworks model identifiers?",
      "type": "implementation",
      "answer": "'accounts/fireworks/models/model-name' - includes full account path",
      "difficulty": "intermediate"
    },
    {
      "question": "How do you specify advanced parameters like top_k and top_p in Fireworks?",
      "type": "implementation", 
      "answer": "Use model_kwargs dictionary: model_kwargs={'top_k': 40, 'top_p': 0.9}",
      "difficulty": "intermediate"
    },
    {
      "question": "What are the four key parameters for tuning Fireworks model behavior?",
      "type": "conceptual",
      "answer": "temperature (randomness), top_p (nucleus sampling), top_k (vocabulary filtering), max_tokens (length)",
      "difficulty": "advanced"
    },
    {
      "question": "Why might you choose Fireworks over OpenAI for a specific project?",
      "type": "conceptual",
      "answer": "Advanced parameter control, access to specific models like Mixtral, potentially better cost/performance for certain tasks",
      "difficulty": "intermediate"
    }
  ],
  "production_tips": [
    {
      "tip": "Optimize model_kwargs parameters for your specific use case",
      "impact": "Significant quality improvements and cost efficiency",
      "implementation": "A/B test different parameter combinations, measure output quality",
      "trade_offs": "Parameter tuning time vs. better results",
      "example": "Use low temperature (0.2) for factual Q&A, high (1.0) for creative writing"
    },
    {
      "tip": "Monitor token usage with different max_tokens settings",
      "impact": "Better cost control and response time optimization",
      "implementation": "Track actual vs. max tokens used, adjust based on use case",
      "trade_offs": "Truncated responses vs. cost savings",
      "example": "Set max_tokens=150 for summaries, 500 for detailed explanations"
    },
    {
      "tip": "Cache responses for repeated queries to reduce API costs",
      "impact": "Significant cost savings for frequently asked questions",
      "implementation": "Hash input+parameters as cache key, store responses with TTL",
      "trade_offs": "Storage overhead vs. API cost savings",
      "example": "Cache FAQ responses for 1 hour, dynamic queries for 10 minutes"
    },
    {
      "tip": "Use Fireworks' model variety for specialized tasks",
      "impact": "Better task-specific performance than general-purpose models",
      "implementation": "Match models to tasks: Mixtral for reasoning, specialized models for code",
      "trade_offs": "Model management complexity vs. optimized performance",
      "example": "Use code-specific models for programming, general models for chat"
    },
    {
      "tip": "Implement parameter validation before API calls",
      "impact": "Fewer API errors and more predictable behavior",
      "implementation": "Validate ranges: temperature (0-2), top_p (0-1), top_k (1-100)",
      "trade_offs": "Additional validation code vs. error prevention",
      "example": "assert 0 <= temperature <= 2, 'Temperature must be 0-2'"
    }
  ],
  "pattern_maturity": {
    "novel_patterns": 2,
    "established_patterns": 2,
    "total_patterns": 4
  },
  "cookies": "ðŸª Why do Fireworks AI models love precise parameters? Because they know the difference between a beautiful firework display and a random explosion is all in the top_k, top_p, and temperature settings! ðŸŽ†"
}