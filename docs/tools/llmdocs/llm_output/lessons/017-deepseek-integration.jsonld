{
  "@context": "https://pixeltable.com/learn",
  "@type": "Tutorial", 
  "@id": "017-deepseek-integration",
  "github_url": "https://github.com/pixeltable/pixeltable/blob/release/docs/notebooks/integrations/working-with-deepseek.ipynb",
  "title": "Working with DeepSeek in Pixeltable",
  "objective": "Learn to integrate DeepSeek's cost-effective LLM for basic chat completions using OpenAI-compatible API",
  "difficulty": "beginner",
  "categories": ["deepseek", "llm-integration", "cost-optimization", "openai-compatible"],
  "prerequisites": ["011-openai-integration"],
  "imports_required": [
    "pixeltable",
    "pixeltable.functions.deepseek",
    "openai",
    "os",
    "getpass"
  ],
  "performance_notes": {
    "typical_runtime": "30 seconds for basic setup",
    "resource_requirements": "DeepSeek API key, internet connection",
    "bottlenecks": ["API key setup", "network latency"]
  },
  "key_learnings": [
    "DeepSeek uses OpenAI SDK but with different API endpoint and models",
    "DeepSeek models offer strong cost-performance ratio for many tasks",
    "API integration follows standard OpenAI pattern with different model names",
    "Response structure identical to OpenAI with choices[0].message.content",
    "Simple integration requires minimal code changes from OpenAI",
    "DeepSeek chat model provides competitive performance for general tasks"
  ],
  "relationships": {
    "builds_on": ["basic_pixeltable_concepts", "openai_integration_patterns"],
    "enables": ["cost_effective_llm_workflows", "openai_alternative_strategies"],
    "see_also": ["011-openai-integration#basic_chat", "015-gemini-integration#cost_comparison"],
    "contrasts_with": ["anthropic_direct_api", "bedrock_converse_structure"]
  },
  "steps": [
    {
      "number": 1,
      "section_title": "Environment Setup and Dependencies",
      "intent": "Install required packages and configure DeepSeek API access",
      "code": "%pip install -qU pixeltable openai\n\nimport os\nimport getpass\n\nif 'DEEPSEEK_API_KEY' not in os.environ:\n    os.environ['DEEPSEEK_API_KEY'] = getpass.getpass('Deepseek API Key:')",
      "imports_used": ["os", "getpass"],
      "explanation": "DeepSeek uses OpenAI SDK for compatibility but requires separate API key",
      "actual_output": "[Installation progress and API key prompt]",
      "output_summary": "Dependencies installed and DeepSeek API key configured",
      "output_type": "text",
      "learns": ["deepseek_api_setup", "openai_sdk_compatibility"],
      "reinforces": ["package_installation", "api_key_management"],
      "gotchas": ["Must install openai package even though using DeepSeek", "API key variable name is DEEPSEEK_API_KEY not OPENAI_API_KEY"],
      "performance": {
        "execution_time": "20-30s for installation",
        "scaling": "O(1) - one-time setup",
        "optimization": "demo"
      },
      "alternatives": {
        "description": "Set API key as environment variable before running",
        "when_to_use": "Production environments with secure credential management"
      },
      "state_after": {
        "tables": [],
        "views": [],
        "variables": ["DEEPSEEK_API_KEY"],
        "models_loaded": []
      },
      "pattern_refs": ["api_key_setup", "openai_compatible_auth"]
    },
    {
      "number": 2,
      "section_title": "Create Demo Directory",
      "intent": "Initialize Pixeltable workspace for DeepSeek experiments",
      "code": "import pixeltable as pxt\n\n# Remove the 'deepseek_demo' directory and its contents, if it exists\npxt.drop_dir('deepseek_demo', force=True)\npxt.create_dir('deepseek_demo')",
      "imports_used": ["pixeltable"],
      "explanation": "Standard Pixeltable pattern for creating isolated workspaces",
      "actual_output": "Connected to Pixeltable database at: postgresql+psycopg://postgres:@/pixeltable?host=/Users/asiegel/.pixeltable/pgdata\nCreated directory 'deepseek_demo'.\n\n<pixeltable.catalog.dir.Dir at 0x16bcf2140>",
      "output_summary": "Demo directory created with database connection confirmation",
      "output_type": "text",
      "learns": [],
      "reinforces": ["directory_management", "workspace_isolation"],
      "gotchas": [],
      "performance": {
        "execution_time": "<1s",
        "scaling": "O(1)",
        "optimization": "demo"
      },
      "alternatives": {
        "description": "Use existing directory or different naming convention",
        "when_to_use": "When integrating into existing projects"
      },
      "state_after": {
        "tables": [],
        "views": [],
        "variables": [],
        "models_loaded": []
      },
      "pattern_refs": ["workspace_initialization", "directory_cleanup"]
    },
    {
      "number": 3,
      "section_title": "Basic DeepSeek Chat Setup",
      "intent": "Create a simple chat table using DeepSeek's chat completion model",
      "code": "from pixeltable.functions import deepseek\n\n# Create a table in Pixeltable and add a computed column that calls Deepseek\n\nt = pxt.create_table('deepseek_demo.chat', {'input': pxt.String})\n\nmsgs = [{'role': 'user', 'content': t.input}]\nt.add_computed_column(output=deepseek.chat_completions(\n    messages=msgs,\n    model='deepseek-chat',\n))",
      "imports_used": ["pixeltable.functions.deepseek"],
      "explanation": "DeepSeek integration follows OpenAI pattern but uses deepseek.chat_completions function",
      "actual_output": "Created table `chat`.\nAdded 0 column values with 0 errors.\n\nUpdateStatus(num_rows=0, num_computed_values=0, num_excs=0, updated_cols=[], cols_with_excs=[])",
      "output_summary": "Chat table created with DeepSeek chat completion column",
      "output_type": "text",
      "learns": ["deepseek_chat_completions_api", "deepseek_chat_model"],
      "reinforces": ["computed_column_creation", "message_list_pattern"],
      "gotchas": ["Model name is 'deepseek-chat' not 'gpt-3.5-turbo'", "Function is chat_completions not completions"],
      "performance": {
        "execution_time": "1s",
        "scaling": "O(1) for setup",
        "optimization": "demo"
      },
      "alternatives": {
        "description": "Use different DeepSeek models if available (deepseek-coder, etc.)",
        "when_to_use": "Specialized tasks like code generation"
      },
      "state_after": {
        "tables": ["deepseek_demo.chat"],
        "views": [],
        "variables": ["t"],
        "models_loaded": ["deepseek-chat"]
      },
      "pattern_refs": ["openai_compatible_setup", "basic_chat_table"]
    },
    {
      "number": 4,
      "section_title": "Response Parsing",
      "intent": "Extract readable text from DeepSeek's OpenAI-compatible response structure",
      "code": "# Parse the response into a new column\nt.add_computed_column(response=t.output.choices[0].message.content)",
      "imports_used": ["pixeltable.functions.deepseek"],
      "explanation": "DeepSeek uses identical response structure to OpenAI with choices[0].message.content",
      "actual_output": "Added 0 column values with 0 errors.\n\nUpdateStatus(num_rows=0, num_computed_values=0, num_excs=0, updated_cols=[], cols_with_excs=[])",
      "output_summary": "Response parsing column added successfully",
      "output_type": "text",
      "learns": ["openai_response_compatibility"],
      "reinforces": ["response_field_extraction", "column_chaining"],
      "gotchas": [],
      "performance": {
        "execution_time": "<1s",
        "scaling": "O(1)",
        "optimization": "demo"
      },
      "alternatives": {
        "description": "Extract additional metadata like usage tokens",
        "when_to_use": "When monitoring costs or performance metrics"
      },
      "state_after": {
        "tables": ["deepseek_demo.chat"],
        "views": [],
        "variables": ["t"],
        "models_loaded": ["deepseek-chat"]
      },
      "pattern_refs": ["openai_response_extraction"]
    },
    {
      "number": 5,
      "section_title": "First Chat Interaction",
      "intent": "Test DeepSeek integration with a historical knowledge question",
      "code": "# Start a conversation\nt.insert(input=\"What was the outcome of the 1904 US Presidential election?\")\nt.select(t.input, t.response).show()",
      "imports_used": ["pixeltable.functions.deepseek"],
      "explanation": "Simple test to verify DeepSeek integration and response quality",
      "actual_output": "Inserting rows into `chat`: 1 rows [00:00, 105.11 rows/s]\nInserted 1 row with 0 errors.\n\n                                               input  \\\n0  What was the outcome of the 1904 US Presidenti...   \n\n                                            response  \n0  The **1904 U.S. Presidential election** result...  ",
      "output_summary": "Successfully generated historical response using DeepSeek",
      "output_type": "table",
      "learns": [],
      "reinforces": ["table_insertion", "query_execution", "response_display"],
      "gotchas": [],
      "performance": {
        "execution_time": "2-3s for API call",
        "scaling": "O(n) for n queries",
        "optimization": "demo"
      },
      "alternatives": {
        "description": "Batch multiple questions for efficiency testing",
        "when_to_use": "Performance comparison with other providers"
      },
      "state_after": {
        "tables": ["deepseek_demo.chat"],
        "views": [],
        "variables": ["t"],
        "models_loaded": ["deepseek-chat"]
      },
      "pattern_refs": ["basic_chat_interaction", "single_query_test"]
    }
  ],
  "patterns": [
    {
      "name": "openai_compatible_auth",
      "description": "API key authentication for OpenAI-compatible services like DeepSeek",
      "confidence": "high",
      "frequency": 2,
      "first_seen": "017-deepseek-integration",
      "code_template": "import os\nimport getpass\n\nif 'SERVICE_API_KEY' not in os.environ:\n    os.environ['SERVICE_API_KEY'] = getpass.getpass('API Key:')",
      "parameters": {
        "SERVICE_API_KEY": "Service-specific API key environment variable name"
      },
      "variations": [
        {
          "name": "with_base_url",
          "difference": "Some services require custom base URL configuration",
          "code": "client = OpenAI(api_key=api_key, base_url='https://api.service.com/v1')"
        }
      ],
      "prerequisites": ["openai_sdk_installed"],
      "enables": ["openai_compatible_llm_access"],
      "performance_impact": "Minimal - one-time setup",
      "reusable": true,
      "production_ready": true
    },
    {
      "name": "openai_compatible_setup",
      "description": "Table setup for OpenAI-compatible LLM services",
      "confidence": "high",
      "frequency": 2,
      "first_seen": "011-openai-integration",
      "code_template": "from pixeltable.functions import service_name\n\nt = pxt.create_table('demo.chat', {'input': pxt.String})\nmsgs = [{'role': 'user', 'content': t.input}]\nt.add_computed_column(output=service_name.chat_completions(\n    messages=msgs,\n    model='model-name',\n))",
      "parameters": {
        "service_name": "Pixeltable integration module (openai, deepseek, etc.)",
        "model": "Service-specific model name"
      },
      "variations": [
        {
          "name": "with_parameters",
          "difference": "Add temperature, max_tokens, etc.",
          "code": "chat_completions(messages=msgs, model='model', temperature=0.7)"
        }
      ],
      "prerequisites": ["api_authentication"],
      "enables": ["llm_chat_workflows"],
      "performance_impact": "Varies by service pricing and speed",
      "reusable": true,
      "production_ready": true
    }
  ],
  "common_errors": [
    {
      "error_type": "Invalid API key or authentication failure",
      "frequency": "common",
      "cause": "Missing, incorrect, or expired DeepSeek API key",
      "symptoms": ["401 Unauthorized", "Authentication failed errors"],
      "solution": {
        "quick_fix": "Verify API key is correct and set in DEEPSEEK_API_KEY environment variable",
        "proper_fix": "Generate new API key from DeepSeek dashboard if needed"
      },
      "prevention": "Test API key with simple request before integration",
      "example": "Missing or invalid key in environment variable",
      "first_seen": "017-deepseek-integration#step1"
    },
    {
      "error_type": "Model not found",
      "frequency": "occasional",
      "cause": "Using incorrect model name or model not available in region",
      "symptoms": ["Model not found", "Invalid model specified"],
      "solution": {
        "quick_fix": "Check DeepSeek documentation for correct model names",
        "proper_fix": "Use 'deepseek-chat' as the standard model name"
      },
      "prevention": "Reference official DeepSeek model documentation",
      "example": "Using 'gpt-3.5-turbo' instead of 'deepseek-chat'",
      "first_seen": "017-deepseek-integration#step3"
    },
    {
      "error_type": "Missing openai package",
      "frequency": "common",
      "cause": "DeepSeek requires openai SDK but it's not installed",
      "symptoms": ["ModuleNotFoundError: No module named 'openai'"],
      "solution": {
        "quick_fix": "pip install openai",
        "proper_fix": "Include openai in requirements.txt for DeepSeek integrations"
      },
      "prevention": "Always install openai package for OpenAI-compatible services",
      "example": "Trying to use DeepSeek without openai dependency",
      "first_seen": "017-deepseek-integration#step1"
    }
  ],
  "test_questions": [
    {
      "question": "What Python package does DeepSeek require besides Pixeltable?",
      "type": "implementation",
      "answer": "openai - DeepSeek uses the OpenAI SDK for compatibility",
      "difficulty": "beginner"
    },
    {
      "question": "How does DeepSeek's response structure compare to OpenAI?",
      "type": "conceptual",
      "answer": "Identical - both use choices[0].message.content for text extraction",
      "difficulty": "beginner"
    },
    {
      "question": "What is the correct model name for DeepSeek's main chat model?",
      "type": "implementation", 
      "answer": "'deepseek-chat'",
      "difficulty": "beginner"
    },
    {
      "question": "What environment variable should store the DeepSeek API key?",
      "type": "implementation",
      "answer": "DEEPSEEK_API_KEY",
      "difficulty": "beginner"
    },
    {
      "question": "Why might you choose DeepSeek over OpenAI for a project?",
      "type": "conceptual",
      "answer": "Cost optimization - DeepSeek often provides competitive performance at lower costs",
      "difficulty": "intermediate"
    }
  ],
  "production_tips": [
    {
      "tip": "Compare costs between DeepSeek and OpenAI for your specific use case",
      "impact": "Potential significant cost savings for high-volume applications",
      "implementation": "Run A/B tests with same prompts on both services, measure cost per token",
      "trade_offs": "Possible slight quality differences vs. cost savings",
      "example": "Use DeepSeek for summarization, OpenAI for creative writing"
    },
    {
      "tip": "Monitor response quality when switching from OpenAI to DeepSeek",
      "impact": "Ensure consistent user experience during migration",
      "implementation": "Set up quality metrics and A/B testing framework",
      "trade_offs": "Additional monitoring complexity vs. cost benefits",
      "example": "Track BLEU scores, user satisfaction, task completion rates"
    },
    {
      "tip": "Use DeepSeek for development and testing environments",
      "impact": "Reduce development costs without affecting production quality",
      "implementation": "Environment-based model selection in configuration",
      "trade_offs": "Different model behavior in dev vs prod",
      "example": "if env == 'development': use deepseek-chat else: use gpt-4"
    },
    {
      "tip": "Implement fallback to OpenAI if DeepSeek is unavailable",
      "impact": "Better reliability and uptime for critical applications",
      "implementation": "Try-catch blocks with automatic failover logic",
      "trade_offs": "Increased complexity and cost during failover",
      "example": "Catch DeepSeek API errors and automatically retry with OpenAI"
    }
  ],
  "pattern_maturity": {
    "novel_patterns": 0,
    "established_patterns": 2,
    "total_patterns": 2
  },
  "cookies": "ðŸª Why did the developer choose DeepSeek over OpenAI? Because they wanted deep thoughts without deep pockets! Plus, it uses the same OpenAI SDK - it's like getting a luxury car with economy pricing! ðŸ’°"
}