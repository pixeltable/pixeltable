---
title: 'Quick Start'
description: 'Build your first AI-powered application with Pixeltable in 5 minutes'
icon: 'wand-magic-sparkles'
---

<Note>
This guide gets you from zero to a working AI application quickly. For deeper learning, see [Pixeltable Basics](/notebooks/pixeltable-basics) and [Tables & Data Operations](/notebooks/fundamentals/tables-and-data-operations).
</Note>

## Installation

```bash
pip install pixeltable torch transformers
```

<Tip>
Add `openai` to the install if you want to use OpenAI Vision in Step 3.
</Tip>

## Build an Image Analysis App

<Steps>
  <Step title="Create a Table">
    ```python
    import pixeltable as pxt

    # Create a namespace and table
    pxt.drop_dir('quickstart', force=True)
    pxt.create_dir('quickstart')

    t = pxt.create_table('quickstart.images', {'image': pxt.Image})
    ```

    Tables are persistent—your data survives restarts and can be queried anytime.
  </Step>

  <Step title="Add AI Object Detection">
    ```python
    from pixeltable.functions import huggingface

    # Add DETR object detection as a computed column
    t.add_computed_column(
        detections=huggingface.detr_for_object_detection(
            t.image,
            model_id='facebook/detr-resnet-50'
        )
    )

    # Extract labels from detections
    t.add_computed_column(labels=t.detections.label_text)
    ```

    Computed columns run automatically whenever new data is inserted.
  </Step>

  <Step title="Insert Data and See Results">
    ```python
    # Insert an image
    t.insert(image='https://raw.githubusercontent.com/pixeltable/pixeltable/release/docs/resources/images/000000000025.jpg')

    # View results
    t.select(t.image, t.labels).collect()
    ```

    **Expected output:**
    ```
    | image      | labels              |
    |------------|---------------------|
    | [Image]    | ['giraffe', 'giraffe'] |
    ```
  </Step>

  <Step title="Add Custom Logic with UDFs">
    ```python
    @pxt.udf
    def top_label(detections: dict) -> str:
        """Return the highest-confidence detection label."""
        if not detections['scores']:
            return 'none'
        best_idx = detections['scores'].index(max(detections['scores']))
        return detections['label_text'][best_idx]

    t.add_computed_column(best=top_label(t.detections))

    # Now every row has the top detection
    t.select(t.image, t.best).collect()
    ```

    UDFs let you add any Python logic as computed columns.
  </Step>

  <Step title="(Optional) Add LLM Vision">
    ```python
    import os
    from pixeltable.functions import openai

    # Set your API key (or use config.toml)
    os.environ['OPENAI_API_KEY'] = 'your-key-here'

    t.add_computed_column(
        description=openai.vision(
            prompt="Describe this image in one sentence.",
            image=t.image,
            model='gpt-4o-mini'
        )
    )

    t.select(t.image, t.best, t.description).collect()
    ```

    Pixeltable handles rate limiting, retries, and caching automatically.
  </Step>
</Steps>

<Accordion title="What happened behind the scenes?">
Pixeltable automatically:
1. Created a persistent multimodal table
2. Downloaded and cached the DETR model
3. Ran inference on your image
4. Stored all results (including computed columns) for instant retrieval
5. Will incrementally process any new images you insert
</Accordion>

## Key Concepts

<CardGroup cols={2}>
  <Card title="Tables" icon="table" href="/datastore/tables-and-operations">
    Persistent storage for any data type—images, video, audio, text, JSON.
  </Card>
  <Card title="Computed Columns" icon="calculator" href="/datastore/computed-columns">
    Define transformations once; they run automatically on new data.
  </Card>
  <Card title="Built-in AI Functions" icon="brain" href="/integrations/frameworks">
    Pre-built integrations for OpenAI, Anthropic, Hugging Face, and more.
  </Card>
  <Card title="Custom Functions (UDFs)" icon="code" href="/datastore/custom-functions">
    Extend Pixeltable with your own Python functions.
  </Card>
</CardGroup>

## Next Steps

<CardGroup cols={3}>
  <Card title="RAG Tutorial" icon="books" href="/notebooks/use-cases/rag-demo">
    Build a document Q&A system
  </Card>
  <Card title="Video Analysis" icon="video" href="/notebooks/use-cases/object-detection-in-videos">
    Process video with object detection
  </Card>
  <Card title="Vector Search" icon="magnifying-glass" href="/datastore/vector-database">
    Add semantic search to your app
  </Card>
</CardGroup>