---
title: Memory
description: Memory is a crucial component of building reliable and scalable AI agents.
mode: "wide"
---

<Icon icon="Github"/> [View Examples on GitHub](https://github.com/pixeltable/pixeltable/tree/release/docs/examples/memory)

Pixeltable AI infrastructure allows you to quickly build agents with memory.

In this example, we will create a Pixeltable Agent that maintains memory of conversations.

## Pixeltable Agent with Memory

Memory is a crucial component of building reliable and scalable AI agents.

Pixeltable handles the storage, orchestration, and retrieval of memory.

<Steps>
  <Step title="Create Agent">
    ```python
    from typing import Dict, List

    import pixeltable as pxt

    DIRECTORY = 'agent'
    OPENAI_MODEL = 'gpt-4o-mini'

    memory = pxt.create_table(
        path_str=f'{DIRECTORY}.memory',
        schema_or_df={
            'role': pxt.String,
            'content': pxt.String,
            'timestamp': pxt.Timestamp,
        },
        if_exists='replace',
    )

    chat_session = pxt.create_table(
        path_str=f'{DIRECTORY}.chat_session',
        schema_or_df={
            'user_message': pxt.String, 
            'timestamp': pxt.Timestamp
        },
        if_exists='replace',
    )

    @pxt.query
    def get_recent_memory():
        return (
            memory
            .order_by(memory.timestamp)
            .select(role=memory.role, content=memory.content)
        )

    @pxt.udf
    def create_messages(
        past_context: List[Dict], 
        current_message: str
    ) -> List[Dict]:
        messages = [
            {
            'role': 'system',
            'content': "You are a helpful assistant.",
            }
        ]

        messages.extend(
            [{'role': msg['role'], 'content': msg['content']} for msg in past_context]
        )

        messages.append({'role': 'user', 'content': current_message})

        return messages

    chat_session.add_computed_column(
        memory_context=get_recent_memory()
    )
    chat_session.add_computed_column(
        prompt=create_messages(
            chat_session.memory_context, chat_session.user_message
        )
    )
    chat_session.add_computed_column(
        llm_response=pxt.functions.openai.chat_completions(
            messages=chat_session.prompt, model=OPENAI_MODEL
        )
    )
    chat_session.add_computed_column(
        assistant_response=chat_session.llm_response.choices[0].message.content
    )


    ```
    This creates two tables: 
    - `memory`: to store the conversation history
    - `chat_session`: to process the responses with context

  </Step>
  <Step title="Putting it all together">
    ```python Chat
    from datetime import datetime

    import pixeltable as pxt

    DIRECTORY = 'agent'
    OPENAI_MODEL = 'gpt-4o-mini'

    memory = pxt.get_table(f'{DIRECTORY}.memory')
    agent = pxt.get_table(f'{DIRECTORY}.chat_session')


    def chat(message: str):
        memory.insert([{'role': 'user', 'content': message, 'timestamp': datetime.now()}])

        agent.insert([{'user_message': message, 'timestamp': datetime.now()}])

        result = (
            agent.select(agent.assistant_response)
            .where(agent.user_message == message)
            .collect()
        )

        response = result['assistant_response'][0]

        memory.insert(
            [{'role': 'assistant', 'content': response, 'timestamp': datetime.now()}]
        )
        return response


    responses = [
        chat('Hi! My name is Alice.'),
        chat("What's the weather like today?"),
        chat('Thanks! Can you remember my name?'),
        chat('What was the first thing I asked you about?'),
    ]

    for i, response in enumerate(responses, 1):
        print(f'\nExchange {i}:')
        print(f'Bot: {response}')
    ```
  </Step>
</Steps>