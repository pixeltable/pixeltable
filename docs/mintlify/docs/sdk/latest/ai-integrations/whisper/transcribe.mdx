---
title: "pixeltable.functions.whisper.transcribe"
sidebarTitle: "transcribe"
description: "Transcribe an audio file using Whisper."
icon: "circle-u"
---
## ⚠️ Documentation Issues

<Warning>
- Examples section exists in docstring but was not parsed by docstring_parser
</Warning>

This UDF runs a transcription model *locally* using the Whisper library, equivalent to the Whisper `transcribe` function, as described in the [Whisper library documentation](https://github.com/openai/whisper).

**Requirements:**

- `pip install openai-whisper`


## Signature

```python
pixeltable.functions.whisper.transcribe(audio: Audio, model: String, temperature: Optional[Json], compression_ratio_threshold: Optional[Float], logprob_threshold: Optional[Float], no_speech_threshold: Optional[Float], condition_on_previous_text: Bool, initial_prompt: Optional[String], word_timestamps: Bool, prepend_punctuations: String, append_punctuations: String, decode_options: Optional[Json]) -> Json
```

## Args

<Note>
Parameter optional/required status may not be accurate if docstring doesn't specify defaults.
</Note>

<ParamField path="audio" type="Audio" required>
  The audio file to transcribe.


</ParamField>

<ParamField path="model" type="String" required>
  The name of the model to use for transcription.


</ParamField>

## Returns

<ResponseField name="return" type="any" required>
  A dictionary containing the transcription and various other metadata.


</ResponseField>

## Examples

```python
Add a computed column that applies the model `base.en` to an existing Pixeltable column `tbl.audio`
of the table `tbl`:

>>> tbl.add_computed_column(result=transcribe(tbl.audio, model='base.en'))
```

