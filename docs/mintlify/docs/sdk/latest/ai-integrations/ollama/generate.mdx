---
title: "pixeltable.functions.ollama.generate"
sidebarTitle: "generate"
description: "Generate a response for a given prompt with a provided model."
icon: "circle-u"
---
## Signature

```python
pixeltable.functions.ollama.generate(*args: 'Any', **kwargs: 'Any') -> "'exprs.FunctionCall'"
```

## Args

<Note>
Parameter optional/required status may not be accurate if docstring doesn't specify defaults.
</Note>

<ParamField path="prompt" type="string" required>
  The prompt to generate a response for.


</ParamField>

<ParamField path="model" type="string" required>
  The model name.


</ParamField>

<ParamField path="suffix" type="string" required>
  The text after the model response.


</ParamField>

<ParamField path="format" type="string" required>
  The format of the response; must be one of `'json'` or `None`.


</ParamField>

<ParamField path="system" type="string" required>
  System message.


</ParamField>

<ParamField path="template" type="string" required>
  Prompt template to use.


</ParamField>

<ParamField path="context" type="string" required>
  The context parameter returned from a previous call to `generate()`.


</ParamField>

<ParamField path="raw" type="string" required>
  If `True`, no formatting will be applied to the prompt.


</ParamField>

<ParamField path="options" type="string" required>
  Additional options for the Ollama `chat` call, such as `max_tokens`, `temperature`, `top_p`, and `top_k`. For details, see the [Valid Parameters and Values](https://github.com/ollama/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values) section of the Ollama documentation.


</ParamField>

