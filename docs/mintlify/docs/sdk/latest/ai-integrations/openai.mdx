---
title: "pixeltable.functions.openai"
sidebarTitle: "openai"
description: "Pixeltable [UDFs](https://pixeltable.readme.io/docs/user-defined-functions-udfs)"
icon: "square-m"
---

that wrap various endpoints from the OpenAI API. In order to use them, you must first `pip install openai` and configure your OpenAI credentials, as described in the [Working with OpenAI](https://pixeltable.readme.io/docs/working-with-openai) tutorial.


## Module Contents

### Functions

### `chat_completions()`

Creates a model response for the given chat conversation.


Equivalent to the OpenAI `chat/completions` API endpoint. For additional details, see: [https://platform.openai.com/docs/guides/chat-completions](https://platform.openai.com/docs/guides/chat-completions)

Request throttling: Uses the rate limit-related headers returned by the API to throttle requests adaptively, based on available request and token capacity. No configuration is necessary.

**Requirements:**

- `pip install openai`


**Signature:**

```python
chat_completions(messages: Json, model: String, model_kwargs: Optional[Json], tools: Optional[Json], tool_choice: Optional[Json]) -> Json
```

**Parameters:**

- **`messages`** (*Json*): A list of messages to use for chat completion, as described in the OpenAI API documentation.

- **`model`** (*String*): The model to use for chat completion.

- **`model_kwargs`** (*Optional[Json]*): Additional keyword args for the OpenAI `chat/completions` API. For details on the available parameters, see: [https://platform.openai.com/docs/api-reference/chat/create](https://platform.openai.com/docs/api-reference/chat/create)


**Returns:**

- *Any*: A dictionary containing the response and other metadata.


### `embeddings()`

Creates an embedding vector representing the input text.


Equivalent to the OpenAI `embeddings` API endpoint. For additional details, see: [https://platform.openai.com/docs/guides/embeddings](https://platform.openai.com/docs/guides/embeddings)

Request throttling: Uses the rate limit-related headers returned by the API to throttle requests adaptively, based on available request and token capacity. No configuration is necessary.

**Requirements:**

- `pip install openai`


**Signature:**

```python
embeddings(input: String, model: String, model_kwargs: Optional[Json]) -> Array[(None,), Float]
```

**Parameters:**

- **`input`** (*String*): The text to embed.

- **`model`** (*String*): The model to use for the embedding.

- **`model_kwargs`** (*Optional[Json]*): Additional keyword args for the OpenAI `embeddings` API. For details on the available parameters, see: [https://platform.openai.com/docs/api-reference/embeddings](https://platform.openai.com/docs/api-reference/embeddings)


**Returns:**

- *Any*: An array representing the application of the given embedding to `input`.


### `image_generations()`

Creates an image given a prompt.


Equivalent to the OpenAI `images/generations` API endpoint. For additional details, see: [https://platform.openai.com/docs/guides/images](https://platform.openai.com/docs/guides/images)

Request throttling: Applies the rate limit set in the config (section `openai.rate_limits`; use the model id as the key). If no rate limit is configured, uses a default of 600 RPM.

**Requirements:**

- `pip install openai`


**Signature:**

```python
image_generations(prompt: String, model: String, model_kwargs: Optional[Json]) -> Image
```

**Parameters:**

- **`prompt`** (*String*): Prompt for the image.

- **`model`** (*String*): The model to use for the generations.

- **`model_kwargs`** (*Optional[Json]*): Additional keyword args for the OpenAI `images/generations` API. For details on the available parameters, see: [https://platform.openai.com/docs/api-reference/images/create](https://platform.openai.com/docs/api-reference/images/create)


**Returns:**

- *Any*: The generated image.


### `invoke_tools()`

Converts an OpenAI response dict to Pixeltable tool invocation format and calls `tools._invoke()`.


**Signature:**

```python
invoke_tools(tools: pixeltable.func.tools.Tools, response: pixeltable.exprs.expr.Expr) -> pixeltable.exprs.inline_expr.InlineDict
```

### `moderations()`

Classifies if text is potentially harmful.


Equivalent to the OpenAI `moderations` API endpoint. For additional details, see: [https://platform.openai.com/docs/guides/moderation](https://platform.openai.com/docs/guides/moderation)

Request throttling: Applies the rate limit set in the config (section `openai.rate_limits`; use the model id as the key). If no rate limit is configured, uses a default of 600 RPM.

**Requirements:**

- `pip install openai`


**Signature:**

```python
moderations(input: String, model: String) -> Json
```

**Parameters:**

- **`input`** (*String*): Text to analyze with the moderations model.

- **`model`** (*String*): The model to use for moderations.


**Returns:**

- *Any*: Details of the moderations results.


### `speech()`

Generates audio from the input text.


Equivalent to the OpenAI `audio/speech` API endpoint. For additional details, see: [https://platform.openai.com/docs/guides/text-to-speech](https://platform.openai.com/docs/guides/text-to-speech)

Request throttling: Applies the rate limit set in the config (section `openai.rate_limits`; use the model id as the key). If no rate limit is configured, uses a default of 600 RPM.

**Requirements:**

- `pip install openai`


**Signature:**

```python
speech(input: String, model: String, voice: String, model_kwargs: Optional[Json]) -> Audio
```

**Parameters:**

- **`input`** (*String*): The text to synthesize into speech.

- **`model`** (*String*): The model to use for speech synthesis.

- **`voice`** (*String*): The voice profile to use for speech synthesis. Supported options include: `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`.

- **`model_kwargs`** (*Optional[Json]*): Additional keyword args for the OpenAI `audio/speech` API. For details on the available parameters, see: [https://platform.openai.com/docs/api-reference/audio/createSpeech](https://platform.openai.com/docs/api-reference/audio/createSpeech)


**Returns:**

- *Any*: An audio file containing the synthesized speech.


### `transcriptions()`

Transcribes audio into the input language.


Equivalent to the OpenAI `audio/transcriptions` API endpoint. For additional details, see: [https://platform.openai.com/docs/guides/speech-to-text](https://platform.openai.com/docs/guides/speech-to-text)

Request throttling: Applies the rate limit set in the config (section `openai.rate_limits`; use the model id as the key). If no rate limit is configured, uses a default of 600 RPM.

**Requirements:**

- `pip install openai`


**Signature:**

```python
transcriptions(audio: Audio, model: String, model_kwargs: Optional[Json]) -> Json
```

**Parameters:**

- **`audio`** (*Audio*): The audio to transcribe.

- **`model`** (*String*): The model to use for speech transcription.

- **`model_kwargs`** (*Optional[Json]*): Additional keyword args for the OpenAI `audio/transcriptions` API. For details on the available parameters, see: [https://platform.openai.com/docs/api-reference/audio/createTranscription](https://platform.openai.com/docs/api-reference/audio/createTranscription)


**Returns:**

- *Any*: A dictionary containing the transcription and other metadata.


### `translations()`

Translates audio into English.


Equivalent to the OpenAI `audio/translations` API endpoint. For additional details, see: [https://platform.openai.com/docs/guides/speech-to-text](https://platform.openai.com/docs/guides/speech-to-text)

Request throttling: Applies the rate limit set in the config (section `openai.rate_limits`; use the model id as the key). If no rate limit is configured, uses a default of 600 RPM.

**Requirements:**

- `pip install openai`


**Signature:**

```python
translations(audio: Audio, model: String, model_kwargs: Optional[Json]) -> Json
```

**Parameters:**

- **`audio`** (*Audio*): The audio to translate.

- **`model`** (*String*): The model to use for speech transcription and translation.

- **`model_kwargs`** (*Optional[Json]*): Additional keyword args for the OpenAI `audio/translations` API. For details on the available parameters, see: [https://platform.openai.com/docs/api-reference/audio/createTranslation](https://platform.openai.com/docs/api-reference/audio/createTranslation)


**Returns:**

- *Any*: A dictionary containing the translation and other metadata.


### `vision()`

Analyzes an image with the OpenAI vision capability. This is a convenience function that takes an image and


prompt, and constructs a chat completion request that utilizes OpenAI vision.

For additional details, see: [https://platform.openai.com/docs/guides/vision](https://platform.openai.com/docs/guides/vision)

Request throttling: Uses the rate limit-related headers returned by the API to throttle requests adaptively, based on available request and token capacity. No configuration is necessary.

**Requirements:**

- `pip install openai`


**Signature:**

```python
vision(prompt: String, image: Image, model: String, model_kwargs: Optional[Json]) -> String
```

**Parameters:**

- **`prompt`** (*String*): A prompt for the OpenAI vision request.

- **`image`** (*Image*): The image to analyze.

- **`model`** (*String*): The model to use for OpenAI vision.


**Returns:**

- *Any*: The response from the OpenAI vision API.


